---
title: "![](IEO-logo2.png){width=10cm}"
output:
  bookdown::pdf_document2:
    includes:
      before_body: titulo.sty
    keep_tex: yes
    number_sections: no
    toc: true
    toc_depth: 3
bibliography: Donax.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
indent: no
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \lfoot[\thepage]{}
- \rfoot[]{\thepage}
- \fontsize{12}{22}
- \selectfont
---

\pagebreak


# Context

El objetivo de este documento es la implementación metodológica de la evaluación de stock de coquina *Donax trunculus* mediante un modelo integrado con datos en talla y dinamica en edad implemetnado en Stock Synthesis (SS3) (v.3.30.21) [@Methot2013; @Methot2023] para la zona del Golfo de Cádiz, España. Este trabajo está en el marco de la asesoría científica que lleva a cabo el Instituto Español de Oceanografía (IEO) realizado por el grupo de investigadores asociados al proyecto FEMP 04.

A su vez, se destaca la utilidad de los programas de monitoreo de la población y la pesquería que se ejecutan desde el año 2013 por parte del IEO Cádiz, y con el cual se ha levantado informacion biológica, pesquera y ambiental que ha sido vital para estea implementación metodológica, consitituyendo así el primer ejercicio de evaluación de stock de coquina.


# Methodology

El flujo de trabajo asociado a la modelación de stock, tanto componentes como fuentes de datos está representado de forma genérica en el siguiente diagrama de flujo (Figura \ref{fig:esq});


\begin{landscape}

```{r esq, echo=FALSE, out.width = "100%", fig.align='center', fig.cap="\\label{esq}Esquema de modelación de coquina"}
knitr::include_graphics("FIg/Diagrama_Modelo.png")
```

\end{landscape}



```{r, message=FALSE}
# ## Load packages
library(r4ss)
library(ss3diags)
library(mvtnorm)
#library(FLCore)
#library(ggplotFL)
#library(kobe)
require(plyr)
require(dplyr)
require(reshape2)
library(grid)
library(png)
library(kableExtra)
library(here)

```

```{r setup1, echo=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.pos = "H",
                      dev = 'jpeg',
                      dpi = 300)
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```

```{r lib, eval=TRUE, message=FALSE,  include=FALSE, echo=FALSE, warning=FALSE}
# install.packages("devtools")
# install.packages("caTools")
# library("caTools")
# # install.packages("r4ss")
paquetes <- c("stringr", 
              "tidyverse", 
              "kableExtra","ggplot2",
              "ggthemes",
               "patchwork",
              "dplyr","reshape","here","r4ss",
              "zoo","ss3diags","pdftools",
              "forcats","ggpubr")
lapply(paquetes, require, character.only = TRUE)
```


```{r echo=FALSE}
dir01<-here::here("s01")# Modelo test 
dir1<-here::here("s1")# Reference model 2.5 TML fixed
dir2<-here::here("s2") # 2.3 tml fixed
dir3<-here::here("s3") # 2.4 tml fixed
dir4<-here::here("s4") # 2.6 TML fixed
dir2.3<- here::here("s1_2.3") # 2.3 estimated
dir2.4<- here::here("s1_2.4") # 2.4 estimated
dir2.5<- here::here("s1_2.5") # 2.5 estimated
dir2.6<- here::here("s1_2.6") # 2.6 estimated

fig_path<-here::here("Fig")
```

run Model

```{r eval=FALSE, message=F, include=FALSE}
# Lista de directorios para correro tordos juntos
directorios <- c("s1",
                 "s2",
                 "s3",
                 "s4",
                 "s1_2.3",
                 "s1_2.4",
                 "s1_2.5",
                 "s1_2.6")  # Agrega aquí todos los nombres de las carpetas que deseas procesar

# Bucle para ejecutar el código en cada directorio
for (dir in directorios) {
  r4ss::run(
    dir = dir,
    exe = "../executable/ss3_opt_osx_arm64",
    skipfinished = FALSE,
    show_in_console = TRUE
  )
}
# Considerar que al correr el modelo dentro de cada `chunk` se cambia el directorio.
```

```{r eval= F}
# Corro escenario por separado 
r4ss::run(
  dir = dir4,
  exe = "../executable/ss3_opt_osx_arm64",
  skipfinished = FALSE,
  show_in_console = TRUE# change to true to watch the output go past
)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#dir1<-here("s1")
base.model1 <- SS_output(dir=dir1,
                         covar=T,
                         forecast=T)
#dir2<-here("s2")
base.model2 <- SS_output(dir=dir2,
                         covar=T,
                         forecast=T)
#dir3<-here("s3")
base.model3 <- SS_output(dir=dir3,
                         covar=T,
                         forecast=T)
#dir1<-here("s4")
base.model4 <- SS_output(dir=dir4,
                         covar=T,
                         forecast=T)


base.model2.3 <- SS_output(dir = dir2.3, 
                           covar = TRUE,
                           forecast = TRUE)

base.model2.4 <- SS_output(dir = dir2.4, 
                           covar = TRUE, 
                           forecast = TRUE)

base.model2.5 <- SS_output(dir = dir2.5, 
                           covar = TRUE, 
                           forecast = TRUE)

base.model2.6 <- SS_output(dir = dir2.6, 
                           covar = TRUE, 
                           forecast = TRUE)

```


```{r eval= F, message=FALSE, warning=FALSE, include=FALSE}
SS_plots(base.model1,
         uncertainty=T,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.40,
         minbthresh=0.20, 
         forecast=T)
```


```{r eval= F, message=FALSE, warning=FALSE, include=FALSE}
#Leo las salidas del modelo seleccionado. 

dir5<-here("s5")
base.model5 <- SS_output(dir=dir5,
                         covar=T,
                         forecast=T)

SS_plots(base.model5,
         uncertainty=T,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.40,
         minbthresh=0.20, 
         forecast=T)

```

```{r}
# leo archivos para plotear y hacer tablas
start1 <- SS_readstarter(file = file.path(dir1,
                                               "starter.ss"),
                              verbose = FALSE)
# note the data and control file names can vary, so are determined from the 
# starter file.
dat1 <- SS_readdat(file = file.path(dir1, start1$datfile),
                        verbose = FALSE)
# Read in ctl file. Note that the data fileR object is needed so that SS_readctl
# assumes the correct data structure
ctl1 <-  r4ss::SS_readctl(file = file.path(dir1,
                                    start1$ctlfil),
                        verbose = FALSE,
                        use_datlist = TRUE, 
                   datlist = dat1)
fore1 <- r4ss::SS_readforecast(file = file.path(dir1, 
                                                "forecast.ss"),
                              verbose = FALSE)
# can also read in wtatage.ss for an empirical wt at age model using
# r4ss::SS_readwtatage()
```



\pagebreak

## Dynamic population model to wedga clam

El modelo de dinámica poblacional de la coquina, corresponde a un enfoque de evaluación del tipo estadístico con estructura de edad, donde la dinámica progresa avanzando en el tiempo t, y las capturas son causantes de la mortalidad por pesca F, la mortalidad natural es constante `M = 0.99` (Tabla \ref{Tab1}). La relación entre la población y las capturas responde a la base de la ecuación de Baranov, y se consideran para el modelo y estimaciones el rango de edad entre 1 a 5+ (años). Sin embargo, las estimaciones del modelo tienen su origen en la edad cero sobre la base de una condición inicial estado estable. La dinámica esta modelada por un reclutamiento tipo Beverton y Holt.


De manera sencilla, un modelo de evaluación reproduce la dinámica poblacional de coquina a lo largo del tiempo. Este modelo incorpora parámetros biológicos clave como tasas de crecimiento, tasas de mortalidad, reclutamiento y biomasa desovante. Normalmente, el modelo se formula utilizando ecuaciones matemáticas que describen cómo estos parámetros interactúan para determinar la abundancia y distribución de coquina en el área de estudio. La ecuación de estado de creciiento poblacional de coquina puede representarse como:

\[
N_t = N_{t-1} \cdot e^{(r - M)} + R
\]

Donde:
- \(N_t\) es abundancia de coquina en el tiempo \(t\).
- \(N_{t-1}\) abundancia de coquina en pasos de tiempo previos.
- \(r\) es la tasa de crecimiento poblacional intrinseca.
- \(M\) es la tasa de mortalidad natural.
- \(R\) es el reclutamiento de nuevos individuos al stock.



## Model conditioning

La ecuación descrita en el punto `2.2` describe la dinámica básica de la población de coquina, con la abundancia cambiando con el tiempo debido al crecimiento, la mortalidad y el reclutamiento. Junto a esta ecuación, otros submodelos asociados como crecimiento individual, selectividad, madurez, captura a la edad entre otros estan configurados en SS3. Este plataforma de evaluación de stock está diseñada como un modelo estructurado con dinámica en edad y datos en talla, en la clase de modelo denominado *Modelo de análisis integrado*. SS3 tiene un sub-modelo poblacional de stock que simula crecimiento, madurez, fecundidad, reclutamiento, movimiento, y procesos de mortalidad, y sub-modelos de observation y valores esperados para diferentes tipos de datos. El modelo es codificado en C++ con parámetros de estimación activados por diferenciación automática (ADMB) [@Methot2013]. El análisis de resultados y salidas emplea herramientas de R e interfase gráfica de la librería `r4ss` (<https://github.com/r4ss/r4ss>) [@Taylor2019] y `ss3diags`  [@Henning2023].


Las rutinas y datos de este proceso metodologico de evaluaciónpueden ser encontrados en el repositorio de [SA_Donax_trunculus](https://github.com/MauroMardones/SA_Donax_trunculus)



La estimación de la biomasa desovante se realizó a inicios de año, mientras que el reclutamiento se consideró como un evento doble que ocurre hacia junio y fines de año.  En el proceso de estimación del reclutamiento, se incorporó una relación stock-recluta difusa (steepness 0.7), y las variaciones en el reclutamiento se modelaron como desviaciones del reclutamiento virginal `R0`, asumiendo 2004 como año inicial (Tabla \ref{Tab1}).

La mortalidad por pesca se estimó como el promedio simple de la `F` de las clases de edad 1 y 2, lo que en el modelo corresponde a la opción 5 del método `F híbrido` recomendado en SS3 [@Methot2013]. Se asume que la densidad es un proxi de las biomasas estimadas [@Caddy2004] obtenida desde los muestreos poblacionales y que son proporcionales a la biomasa vulnerable de la población, con la capturabilidad (`q`) estimada en el modelo. Los parámetros `q` fueron estimados a patir de parámetros iniciales especificados en la Tabla \ref{Tab1} para los datos del monitoreo poblacional , así como del comercial. Todos los patrones de selectividad, que relacionan las composiciones de tallas observadas de la flota comercial y poblacional con la dinámica, fueron estimados mediante una función logística. Los parámetros `p1` (talla en la inflexión de la curva) y `p2` (selección al 95%) son estimados por el modelo a partir de los valores iniciales especificados en la Tabla \ref{Tab1}.


```{r}
 parbio<-ctl1$MG_parms[1:10,c(1:3,7)]
 row.names( parbio)<-c("Nat M",
                       "Lmin", 
                       "Lmax",
                       "VonBert K",
                       "CV young",
                       "CV old", 
                       "Wt a", 
                       "Wt b",
                       "L50%", 
                       "Mat slope")

 SRpar<-ctl1$SR_parms[1:5,c(1:3,7)]
 Qpar<-ctl1$Q_parms[1:2,c(1:3,7)]
 Selpar<-ctl1$size_selex_parms[1:4,c(1:3,7)]
 parInit<-rbind(parbio,SRpar,Qpar,Selpar)

parInit %>%
  kbl(booktabs = T,
      format = "latex",
      position="ht!",
    caption = "\\label{Tab1}Parámetros de entrada al modelo inicial SS3 de coquina (S1). Cada línea de parámetro contiene un valor mínimo (LO), máximo (HI) e inicial (INIT). Si la fase (PHASE) para el parámetro es negativa, el parámetro es fijo de entrada") %>%
  kable_paper("hover", 
              full_width = F)%>%
  kable_styling(latex_options = c("striped",
                                  "condensed"),
                full_width = FALSE,
                font_size=9)%>% 
  pack_rows(index = c("Mortalidad natural" = 1,
                        "Crecimiento"= 5,
                        "Relación longitud-peso" = 2,
                        "Ojiva de madurez"=2,
                        "Relación stock-recluta"=5,
                        "Capturabilidad"=2,
                        "Selectividad"=4))

```


Por otro lado, y al existir dos tipos de muestreos, uno poblacional y otro comercial, se modelan las selectividades por separado como se identifica en la Figura \ref{fig:sel}

```{r sel, echo=FALSE, out.width = "80%", fig.cap="\\label{sel}selectivity at length in end year for all fleets shown together para coquina"}
SSplotSelex(base.model1, 
            subplots = 1)
```
## Scenarios

Para avanzar en la implementación metodológica, y considerando las fuentes de incertidumbre asociadas a la modelación de stock de coquina, se establecen una serie de modelos alternativo. Estos escenarios dicen relación con el subreporte de este tipo de pesquerias [@Ballesteros2024] en particular, con la coquina [@Sordo2023]. Estudios en pesca ilegal en coquina, si bien identifican el furtuvismo, no dimensionan cantidades ni magnitudes y que no son reflejados en las cifras oficiales. Por ello, este ejercicio contempló una corrección al alza de los desembarques oficiales provistos por la Junta a traves de IDEASPA. Esto tiene como objetivo identificar el impacto del subreporte en la estimación de variables poblacionales, así como en el status del recurso.  Estos escenarios estan descritos en la Tabla \ref{Tab2}.


```{r}
# Función logística para selectividad
logistic_selectivity <- function(length, L50, slope) {
  1 / (1 + exp(-slope * (length - L50)))
}

# Parámetros
lengths <- seq(10, 35, by = 0.1)  # Rango de longitudes en mm
L50_values <- c(23, 24, 25, 26)
slope <- 2

# Crear un data frame con todas las curvas
selectivity_data <- expand.grid(length = lengths, L50 = L50_values) %>%
  mutate(selectivity = logistic_selectivity(length, L50, slope),
         L50 = factor(L50, levels = L50_values))

# Graficar con ggplot2
ggplot(selectivity_data, aes(x = length, 
                             y = selectivity, 
                             color = L50)) +
  geom_line(size = 1.2) +
  labs(
    title = "",
    x = "Shell length (mm)",
    y = "Fishery Selectivity",
    color = expression(L[50])
  ) +
  theme_minimal(base_size = 14) +
  scale_color_brewer(palette = 5,
                     name ="Legal Minimal Size")+
  ylim(0, 1.05)

```


```{r}
esc <- c("s1", "s2", "s3", "s4", "s5", 
         "s1_2.3", "s1_2.4", "s1_2.5", "s1_2.6")

descripcion <- c(
  "S1 + Vector de desembarques desde 1990 asumido en 250 toneladas por año",
  "S1 + Vector de desembarques ponderado por 1.5",
  "S1 + Vector de desembarques ponderado por 2",
  "S1 + Vector de desembarques ponderado por 2.5",
  "S1 (estimando TML = 2.3)",
  "S1 (estimando TML = 2.4)",
  "S1 (estimando TML = 2.5)",
  "S1 (estimando TML = 2.6)"
)

ESC1 <- cbind(esc, descripcion)

ESC1 %>%
  kbl(booktabs = TRUE,
      format = "latex",
      position = "h!",
      align = "l",
      col.names = linebreak(c("Escenarios", "Descripción"), align = "c"),
      caption = "\\label{Tab2}Descripción de los escenarios alternativos y variantes del modelo base (S1).") %>%
  kable_paper("hover", full_width = FALSE) %>%
  kable_styling(latex_options = c("striped", "condensed"),
                full_width = FALSE,
                font_size = 10)

```

\pagebreak

# Results

## Fits 

En relación a los análisis de bondad de ajuste más clásicos, los ajustes a las tallas muestran un adecuado desempeño, siguiento las modas anuales de la estructura de tallas poblacional y comercial (Figura \ref{fig:fitpob}).


```{r fitpob, echo=FALSE,  fig.align='center', fig.cap="\\label{fig:fitpob}Fits Length comps whole catch COMERCIAL y POBLACIONAL para coquina"}
SSplotComps(base.model4,
            subplots=1,
            cols = 6,
            fleetnames = c("Comercial", "Poblacional"),
            maxrows = 5,
            maxcols = 2,
            linescol = 4)
```



\pagebreak

## Variables population

El modelo permite estimar diferentes variables poblacionales, las cuales se enlistan en la Tabla \ref{Tab4};

```{r message=FALSE, include=FALSE}
replist <- SS_output(dir=dir1,verbose=TRUE,printstats=TRUE)
summary <- read.table(here(dir1,
                           "ss_summary.sso"),
                      header=F,sep="",
                      na="NA",fill=T) 

#Saco los vectores requeridos. Pueden ser otros pero esto son los principales
years<-seq(2004,2023,1)
ssb<-replist$derived_quants[3:22,1:3]
recr<-replist$derived_quants[30:49,1:3]
ft<-replist$derived_quants[79:98,1:3]
catch<-summary[281:300,2]
data<-data.frame(yrs=years,
                 Rt=round(as.numeric(recr$Value),2),
                 BD=round(as.numeric(ssb$Value),2),
                 Catch=round(as.numeric(catch),2),
                 Ft=round(as.numeric(ft$Value),2))
```


```{r}
data%>% 
kbl(booktabs = T,format = "latex",position="ht!",align="c",escape = FALSE,
        col.names = linebreak(c('Año',
                                "Reclutamientos",
                                "Biomasa\ndesovante",
                                "Captura",
                                "Mortalidad\npor pesca"),
                              align="c"),
    caption = "\\label{Tab4}Series de tiempo estimados por el modelo inicial (S1). Reclutamiento (millones de ind.),  biomasa desovante (en toneladas), Captura (t) y mortalidad por pesca (año-1).") %>%
  kable_paper("hover", 
              full_width = F)%>%
  kable_styling(latex_options = c("striped",
                                  "condensed"),
                full_width = FALSE,
                font_size=9)

```

Los componentes de verosimilitud, además de los análisis de residuales permiten identificar entre los bloques de modelos cuales de las configuraciones presenta un desempeño adecuado en términos estadísticos de ajuste a la información.  Este modelo es el seleccionado como caso base y sirve para desplegar sus principales salidas para fines informativos de indicadores; como biomasa desovante y pronóstico (Figura \ref{fig:ssb}) y biomasa desovante relativa (Figura \ref{fig:ssb1}).

```{r ssb, echo=FALSE, fig.align='center', out.width = "80%", fig.cap="\\label{ssb}Total biomass with forecast to coquina"}
SSplotTimeseries(base.model3,
                 subplot = 7)
```


```{r ssb1, echo=FALSE, fig.align='center', out.width = "80%", fig.cap="\\label{ssb1}Spawning output with forecast with 95% asymptotic intervals and relative spawining biomass to coquina"}
SSplotTimeseries(base.model1,
                 subplot = 9)
```
Variables poblacionales unidas

SSB y F

```{r}
sspar(mfrow = c(2, 2), plot.cex =0.9)
SSplotEnsemble(mvln1$kb, 
               ylabs = mvln1$labels, 
               subplots = c("SSB", "F", "Recr", "Catch"),
               add = T, 
               verbose = F,
              legend = F,
              shadecol = "gray",
              col = "black")
```
```{r}
sspar(mfrow = c(1, 2), plot.cex = 0.9)
SSplotEnsemble(mvln1$kb, 
               ylabs = mvln1$labels, 
               subplots = c("stock", "harvest"),
               add = T, 
               verbose = F,
              legend = F,
              shadecol = "gray",
              col = "black")
```


## Retrospective

Se siguieron los procedimientos explicados en el objetivo 1 de este reporte, para evaluar la idoneidad
del modelo y dichos procedimientos se han probado en 6 implementaciones (escenarios) diferentes del
modelo inicial (S1). 

```{r eval=F}
# corro po r separado para no tener todo el rato el compu corriendo
#do retrospective model runs
retro(dir=dir5, 
      oldsubdir="", 
      newsubdir="Retrospective", 
      years= 0:-5,
      exe="ss_osx",
      extras = "-nox", 
      skipfinished = F)

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#s01
# retroModels01 <- SSgetoutput(dirvec=file.path(dir01,
#                                             "Retrospective",
#                                             paste("retro",0:-5,
#                                                   sep="")))

#retroSummary01 <- SSsummarize(retroModels01)
# s1
retroModels1 <- SSgetoutput(dirvec=file.path(dir1,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary1 <- SSsummarize(retroModels1)
#s2
retroModels2 <- SSgetoutput(dirvec=file.path(dir2,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary2 <- SSsummarize(retroModels2)
#s3
retroModels3 <- SSgetoutput(dirvec=file.path(dir3,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary3 <- SSsummarize(retroModels3)
#s4
retroModels4 <- SSgetoutput(dirvec=file.path(dir4,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary4 <- SSsummarize(retroModels4)
#s5
retroModels5 <- SSgetoutput(dirvec=file.path(dir5,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary5 <- SSsummarize(retroModels5)
```

Los resultados de el análisis de sesgo para cada escenario son represetados por el parámetro de Rho en la Figura \ref{fig:retro}.

```{r retro ,echo=FALSE, message=FALSE, warning=FALSE, fig.keep='all', fig.show="hold", fig.cap="\\label{retro}Patrón restrospectivo para cada esnario modelado en coquina"}
#save(retroSummary, retroModels, file="retro5.Rdata")

# retro01 <- SSplotRetro(retroSummary01,
#             add=T,
#             forecast = F,
#             legend = T,
#             verbose=F)
par(mfrow=c(2,2), mar=c(1.5,5,3,2) + 0.1)
retro1 <- SSplotRetro(retroSummary1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "SSB",
            tickEndYr=F,
            legendloc="left")
retro2 <- SSplotRetro(retroSummary2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F")
retro3 <- SSplotRetro(retroSummary3,
            add=T,
            forecast = F,
            legendloc = "topright",
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE)
retro4 <- SSplotRetro(retroSummary4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE)
retro5 <- SSplotRetro(retroSummary5,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE)
```

Dado que la variabilidad del índice rho de Mohn depende de la historia de vida (usualmente
mayor para especies de vida corta) y que el estadístico parece insensible a F, @Hurtado2014
propusieron que el patrón retrospectivo de alguna de las variables biológico-pesqueras indicadas es
preocupante si los valores del índice Mohn’s rho son superiores a 0,20 o inferiores a -0,15 para especies
de vida larga, o superiores a 0,30 o inferiores a -0,22 para especies de vida corta. Esto es un factor relevante al momento de hacer diagnosis con recursos como la coquina.
Por su parte, las Tablas  \ref{mod1}, \ref{mod2}, \ref{mod3} , \ref{mod4}y \ref{mod5} muestran el parametro Rho estimado para cada modelo y cada variable (`F`y `SSB`)

```{r echo=FALSE}

# model01
tablebias1 <- SShcbias(retroSummary1,quant="SSB",verbose=F)
tablebias1b <- SShcbias(retroSummary1,quant="F",verbose=F)
table1 <- rbind(tablebias1, tablebias1b)

kbl(table1, booktabs = T,format = "latex",
    caption = "\\label{mod1}Rho parameter in SSB and F model s1")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model2
tablebias2 <- SShcbias(retroSummary2,quant="SSB",verbose=F)
tablebias2b <- SShcbias(retroSummary2,quant="F",verbose=F)
table2 <- rbind(tablebias2, tablebias2b)

kbl(table2, booktabs = T,format = "latex",
    caption = "\\label{mod2}Rho parameter in SSB  and F model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model3
tablebias3 <- SShcbias(retroSummary3,quant="SSB",verbose=F)
tablebias3b <- SShcbias(retroSummary3,quant="F",verbose=F)
table3 <- rbind(tablebias3, tablebias3b)

kbl(table3, booktabs = T,format = "latex",
    caption = "\\label{mod3}Rho parameter in SSB  and F model s3")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model4
tablebias4 <- SShcbias(retroSummary4,quant="SSB",verbose=F)
tablebias4b <- SShcbias(retroSummary4,quant="F",verbose=F)
table4 <- rbind(tablebias4, tablebias4b)

kbl(table4, booktabs = T,format = "latex",
    caption = "\\label{mod4}Rho parameter in SSB  and F model s4")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model5
tablebias5 <- SShcbias(retroSummary5,quant="SSB",verbose=F)
tablebias5b <- SShcbias(retroSummary5,quant="F",verbose=F)
table5 <- rbind(tablebias5, tablebias5b)

kbl(table5, booktabs = T,format = "latex",
    caption = "\\label{mod5}Rho parameter in SSB  and F model s5")  %>% 
    kable_styling(latex_options = "HOLD_position")


```

```{r eval=FALSE, message=FALSE, warning=FALSE}
#En bulcle
# Definir el número de iteraciones
num_iteraciones <- 5

# Crear una lista para almacenar los resultados
retros <- list()

# Ejecutar el bucle for
for (i in 1:num_iteraciones) {
  # Llamar a la función con los diferentes resúmenes (retroSummary1, retroSummary2, ..., retroSummary7)
  retros[[i]] <- SSplotRetro(get(paste0("retroSummary", i)),
                              add = TRUE,
                              forecast = FALSE,
                              legend = TRUE,
                              verbose = FALSE)
}
```



## Hindcast Cross-Validation and prediction skill

Como una medida robusta de habilidad de predicción en la modelación de la población de coquina, implementamos el error medio absoluto escalado (MASE por sus siglas en inglés). En resumen, el puntaje MASE escala el error medio absoluto. En cuanto a un puntaje MASE > 1 indica que las predicciones promedio del modelo son peores que un movimiento aleatorio. Por el contrario, un puntaje MASE de 0.5 indica que las predicciones del modelo son el doble de precisas que una predicción de referencia ingenua; por lo tanto, el modelo tiene habilidad de predicción. En la Figura \ref{fig:hind}.

```{r hind ,echo=FALSE, message=FALSE, warning=FALSE, fig.keep='all', fig.show="hold", fig.cap="\\label{fig:hind}Error medio absoluto escalado para cada escenario de modelación de coquina"}
par(mfrow=c(3,2), mar=c(1.5,5,3,2) + 0.1)
hcl = SSplotHCxval(retroSummary1, 
                   add = T, 
                   verbose = F, 
                   ylimAdj = 1.3,
                   legendcex = 0.7, 
                   indexselect = 2)
hcl2 = SSplotHCxval(retroSummary2, 
                   add = T, 
                   verbose = F, 
                   ylimAdj = 1.3,
                   legendcex = 0.7, 
                   indexselect = 2)
hcl3 = SSplotHCxval(retroSummary3, 
                   add = T, 
                   verbose = F, 
                   ylimAdj = 1.3,
                   legendcex = 0.7, 
                   indexselect = 2)
hcl4 = SSplotHCxval(retroSummary4, 
                   add = T, 
                   verbose = F, 
                   ylimAdj = 1.3,
                   legendcex = 0.7, 
                   indexselect = 2)
hcl5 = SSplotHCxval(retroSummary5, 
                   add = T, 
                   verbose = F, 
                   ylimAdj = 1.3,
                   legendcex = 0.7, 
                   indexselect = 2)
```




\pagebreak

## Comparación de resultados entre modelos


```{r echo=FALSE, message=FALSE}
#PLOT labels, name of each model run
legend.labels <- c("s1",
                   "s2",
                   "s3",
                   "s4",
                 "s1_2.3",
                 "s1_2.4",
                 "s1_2.5",
                 "s1_2.6") 

#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL,
                       dirvec = c(#dir01,
                                  dir1,
                                  dir2,
                                  dir3,
                                  dir4,
                                  dir2.3,
                                  dir2.4,
                                  dir2.5,
                                  dir2.6),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput <- SSsummarize(biglist)
```
Lo analisis comparados, muestran las estimaciones de cada escenario propuesto para los casos de fraccion de biomasa virginal (Figura \ref{fig:biov}), desvio de los reclutamientos (Figura \ref{fig:devrec}) y mortalidad por pesca (Figura \ref{fig:ftotal}) y densidad de estimacion de SSB (Figura \ref{fig:denssb}).

```{r biov, echo=FALSE, out.width = "80%",fig.keep='all', fig.show="hold", fig.align='center', fig.cap="\\label{fig:biov}Comparación escenario de razon de Biomasa"}

SSplotComparisons(summaryoutput,
                  subplot = 4,
                  legendlabels = c("s1",
                                   "s2",
                                   "s3",
                                   "s4",
                                    "s1_2.3",
                                    "s1_2.4",
                                    "s1_2.5",
                                    "s1_2.6"),
                 pheight=4.5,
                 png=TRUE,
                 plotdir=fig_path)
```

```{r devrec, echo=FALSE, fig.keep='all', fig.show="hold", fig.align='center', fig.cap="\\label{fig:devrec}Comparación escenario de razon de Biomasa"}
par(mfrow=c(2,2), mar=c(1.5,5,3,2) + 0.1)
SSplotComparisons(summaryoutput,
                  subplot = c(4, 12, 1, 13),
                  legendlabels = c("s1",
                                   "s2",
                                   "s3",
                                   "s4",
                                    "s1_2.3",
                                    "s1_2.4",
                                    "s1_2.5",
                                    "s1_2.6"),
                 pheight=4.5,
                 png=TRUE,
                 plotdir=fig_path)
```






```{r eval=FALSE}
comtable <- SStableComparisons(summaryoutput,
                   likenames = c("TOTAL", 
                                 "Survey", 
                                 "Length_comp",
                                 "Age_comp", 
                                 "priors",
                                 "Size_at_age"), 
                   names = c("Recr_Virgin",
                             "R0", 
                             "steep",
                             "NatM",
                             "L_at_Amax", 
                             "VonBert_K", 
                             "SSB_Virg", 
                             "Bratio_2017",
                             "SPRratio_2016"),
                   digits = NULL,
                   modelnames = c("s1",
                                   "s2",
                                   "s3",
                                   "s4",
                                    "s1_2.3",
                                    "s1_2.4",
                                    "s1_2.5",
                                    "s1_2.6"),
                   csv = FALSE,
                   csvdir =~"/IEO/SA_Donax_trunculus",
                   csvfile = "parameter_comparison_table.csv",
                 verbose = TRUE,
                   mcmc = FALSE)
kbl(comtable, booktabs = T,format = "latex",
    caption = "Comparacion likelihood y parámetros s01, s1, s2, s3, s4, s5, s6 y s7")  %>% 
    kable_styling(latex_options = "scale_down")

```




## Population Variables by scenario

```{r eval=FALSE, message=F, include=FALSE}
# Definir la ruta de la carpeta
folder_path <- "s1.1/plots"
# Verificar si la carpeta existe y eliminarla
if (dir.exists(folder_path)) {
  unlink(folder_path, recursive = TRUE)
  message("La carpeta 'plots' ha sido eliminada.")
} else {
  message("La carpeta 'plots' no existe.")
}

SS_plots(base.model1.1, 
         uncertainty = TRUE,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.75, 
         minbthresh=0.2, 
         forecast=T)

# S 1.2

# Definir la ruta de la carpeta
folder_path2 <- "s1.2/plots"
# Verificar si la carpeta existe y eliminarla
if (dir.exists(folder_path2)) {
  unlink(folder_path2, 
         recursive = TRUE)
  message("La carpeta 'plots' ha sido eliminada.")
} else {
  message("La carpeta 'plots' no existe.")
}

SS_plots(base.model1.2, 
         uncertainty = TRUE,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.75, 
         minbthresh=0.2, 
         forecast=T)

# S 1.3

# Definir la ruta de la carpeta
folder_path3 <- "s1.3/plots"
# Verificar si la carpeta existe y eliminarla
if (dir.exists(folder_path3)) {
  unlink(folder_path3, 
         recursive = TRUE)
  message("La carpeta 'plots' ha sido eliminada.")
} else {
  message("La carpeta 'plots' no existe.")
}

SS_plots(base.model1.3, 
         uncertainty = TRUE,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.75, 
         minbthresh=0.2, 
         forecast=T)


# S 1.4

# Definir la ruta de la carpeta
folder_path4 <- "s1.4/plots"
# Verificar si la carpeta existe y eliminarla
if (dir.exists(folder_path4)) {
  unlink(folder_path4, 
         recursive = TRUE)
  message("La carpeta 'plots' ha sido eliminada.")
} else {
  message("La carpeta 'plots' no existe.")
}

SS_plots(base.model1.4, 
         uncertainty = TRUE,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.75, 
         minbthresh=0.2, 
         forecast=T)
```


Main Variables poulation in `s1.1` scenario (Figure \@ref(fig:scen1))

```{r scen1, fig.height=2, fig.width=7, fig.cap="Main variables scenario s1.1"}
par(mfrow=c(1,3), mar=c(5,4,1,1)) 
SSplotTimeseries(base.model1.1,
                 subplot = 1,
                 xlab = "")
SSplotTimeseries(base.model1.1,
                 subplot = 9,
                 xlab = "")
SSplotTimeseries(base.model1.1,
                 subplot = 7,
                 xlab = "")
```

Main Variables poulation in `s1.2` scenario (Figure \@ref(fig:scen2))

```{r scen2, fig.height=2, fig.width=7, fig.cap="Main variables scenario s1.2"}
par(mfrow=c(1,3), mar=c(5,4,1,1))
SSplotTimeseries(base.model1.2,
                 subplot = 1,
                 xlab = "")
SSplotTimeseries(base.model1.2,
                 subplot = 9,
                 xlab = "")
SSplotTimeseries(base.model1.2,
                 subplot = 7,
                 xlab = "")
```

Main Variables poulation in `s1.3` scenario (Figure \@ref(fig:scen3))

```{r scen3, fig.height=2, fig.width=7, fig.cap="Main variables scenario s1.3"}
par(mfrow=c(1,3), mar=c(5,4,1,1))
SSplotTimeseries(base.model1.3,
                 subplot = 1,
                 xlab = "")
SSplotTimeseries(base.model1.3,
                 subplot = 9,
                 xlab = "")
SSplotTimeseries(base.model1.3,
                 subplot = 7,
                 xlab = "")
```


Main Variables poulation in `s1.4` scenario (Figure \@ref(fig:scen4))

```{r scen4, fig.height=2, fig.width=7 , fig.cap="Main variables scenario s1.4"}
par(mfrow=c(1,3), mar=c(5,4,1,1))
SSplotTimeseries(base.model1.4,
                 subplot = 1,
                 xlab = "")
SSplotTimeseries(base.model1.4,
                 subplot = 9,
                 xlab = "")
SSplotTimeseries(base.model1.4,
                 subplot = 7,
                 xlab = "")
```

Selectivity estimated by scenario in Figure \@ref(fig:selectivity).

```{r selectivity, fig.height=8, fig.width=8, fig.cap="Selectivity by fleet in each scenario"}
par(mfrow=c(2,2), mar=c(5,4,1,1))
SSplotSelex(base.model1.1,
            subplots = 1,
            mainTitle = FALSE)
mtext("s1.1", side=3, line=0.5, cex=1.2)
SSplotSelex(base.model1.2,
            subplots = 1,
            mainTitle = FALSE)
mtext("s1.2", side=3, line=0.5, cex=1.2)
SSplotSelex(base.model1.3,
            subplots = 1,
            mainTitle = FALSE)
mtext("s1.3", side=3, line=0.5, cex=1.2)
SSplotSelex(base.model1.4,
            subplots = 1,
            mainTitle = FALSE)
mtext("s1.4", side=3, line=0.5, cex=1.2)
```

This Figure \@ref(fig:index2) shows standardized time series of input indices used in four different model scenarios (s1.1 to s1.4) for the stock assessment of Antarctic krill in Subarea 48.1. Each panel presents fishery-dependent (FISHERY) and fishery-independent (SURVEY) indices across five management strata: Bransfield Strait (BS), Elephant Island (EI), Gerlache Strait (GS), Joinville Island (JOIN), and South West (SW), from the mid-1990s to 2020. Scenario s1.4 additionally includes a predator index, highlighting the incorporation of ecosystem variables. The figure illustrates spatial and temporal variability in data availability and trends among sources.


```{r index2, fig.height=8, fig.width=8, fig.cap= "Standardized indices of krill abundance used as input in four model scenarios (s1.1 to s1.4), representing fishery-dependent (FISHERY) and fishery-independent (SURVEY) data across five spatial strata: Bransfield Strait (BS), Elephant Island (EI), Gerlache Strait (GS), Joinville Island (JOIN), and South West (SW). Scenario s1.4 also incorporates a predator index (PREDATOR), reflecting the integration of ecosystem variables into the assessment framework"}
par(mfrow=c(2,2), mar=c(5,4,2,1)) 
SSplotIndices(base.model1.1, subplots = 9)
mtext("s1.1", side=3, line=0.5, cex=1.2)
SSplotIndices(base.model1.2, subplots = 9)
mtext("s1.2", side=3, line=0.5, cex=1.2)
SSplotIndices(base.model1.3, subplots = 9)
mtext("s1.3", side=3, line=0.5, cex=1.2)
SSplotIndices(base.model1.4, subplots = 9)
mtext("s1.4", side=3, line=0.5, cex=1.2)
```

### Outputs Variables `s1.1`

```{r}
outps1 <- base.model1.1$timeseries[1:37, 2:8]

# addWorksheet(wb, "variable_s2")
# writeData(wb, "variable_s2", outps1)
# 
# # Guardar el workbook
# saveWorkbook(wb, "DataKrill.xlsx", overwrite = TRUE)
# 
# 
# out_s2 <- read_excel("DataKrill.xlsx", 
#     sheet = "variable_s2")
outps1 %>%
  kbl(booktabs = TRUE,
      format = "html",
    caption = "Main variables outputs from stock asssessment krill in WAP `s1.1`") %>%
 kable_styling(latex_options = c("scale_down",
                                    "striped"),# Expande la tabla al ancho completo
                font_size = 12)  #%>% 
  #pack_rows(index = c("Estimation" = 1,
   #                     "Prediction" = 45))
```

### Outputs Variables `s1.2`

```{r}
outps2 <- base.model1.2$timeseries[1:37, 2:8]

# addWorksheet(wb, "variable_s2")
# writeData(wb, "variable_s2", outps1)
# 
# # Guardar el workbook
# saveWorkbook(wb, "DataKrill.xlsx", overwrite = TRUE)
# 
# 
# out_s2 <- read_excel("DataKrill.xlsx", 
#     sheet = "variable_s2")
outps2 %>%
  kbl(booktabs = TRUE,
      format = "html",
    caption = "Main variables outputs from stock asssessment krill in WAP in `s1.2`") %>%
    kable_styling(latex_options = c("scale_down",
                                    "striped"),# Expande la tabla al ancho completo
                font_size = 12) #%>% 
  #pack_rows(index = c("Estimation" = 1,
   #                     "Prediction" = 45))
```



### Outputs Variables `s1.3`

```{r}
outps3 <- base.model1.3$timeseries[1:37, 2:8]

# addWorksheet(wb, "variable_s2")
# writeData(wb, "variable_s2", outps1)
# 
# # Guardar el workbook
# saveWorkbook(wb, "DataKrill.xlsx", overwrite = TRUE)
# 
# 
# out_s2 <- read_excel("DataKrill.xlsx", 
#     sheet = "variable_s2")
outps3 %>%
  kbl(booktabs = TRUE,
      format = "html",
    caption = "Main variables outputs from stock asssessment krill in WAP in `s1.3`") %>%
  kable_styling(latex_options = c("scale_down",
                                    "striped"),# Expande la tabla al ancho completo
                font_size = 12) #%>% 
  #pack_rows(index = c("Estimation" = 1,
   #                     "Prediction" = 45))
```

### Outputs Variables `s1.4`

```{r}
outps4 <- base.model1.4$timeseries[1:37, 2:8]

# addWorksheet(wb, "variable_s2")
# writeData(wb, "variable_s2", outps1)
# 
# # Guardar el workbook
# saveWorkbook(wb, "DataKrill.xlsx", overwrite = TRUE)
# 
# out_s2 <- read_excel("DataKrill.xlsx", 
#     sheet = "variable_s2")
outps4 %>%
  kbl(booktabs = TRUE,
      format = "html",
    caption = "Main variables outputs from stock asssessment krill in WAP in `s1.4`") %>%
 kable_styling(latex_options = c("scale_down",
                                    "striped"),# Expande la tabla al ancho completo
                font_size = 12) #%>% 
  #pack_rows(index = c("Estimation" = 1,
   #                     "Prediction" = 45))
```

### Comparision between variables

Main variables population by scenario (Figure \@ref(fig:popvar2))

```{r popvar2, fig.height=4, fig.width=9, fig.cap="Time series of different populations variables"}
# Unir los data frames en uno solo
outpsall <- rbind(outps1,  
                  outps2,
                  outps3,
                outps4)

# Crear una columna de modelo en cada data frame
outps1$Model <- "s1.1"
outps2$Model <- "s1.2"
outps3$Model <- "s1.3"
outps4$Model <- "s1.4"

# Unir los data frames en uno solo
outpsall <- rbind(outps1,  
                  outps2,
                  outps3,
                  outps4)


outpsall_long <- outpsall %>%
  pivot_longer(cols = c(Bio_all, Bio_smry, SpawnBio, Recruit_0), 
               names_to = "Variable", values_to = "Value") %>% 
  filter(Yr >= 1989, Yr <= 2020)



# Gráfico de líneas por variable y modelo
alloutput <- ggplot(outpsall_long, aes(x = Yr, y = Value, color = Model, group = Model)) +
  geom_point() +
  #geom_smooth(method = "lm")+
  facet_wrap(~Variable, 
             ncol = 4, 
             scales = "free_y") + 
  scale_color_manual(name = "Scenario",
                     values = c("s1.1" = "#ca0020", 
                                "s1.2" = "#f4a582", 
                                "s1.3" = "#bababa", 
                                "s1.4" = "#404040")) +
  labs(title = "", x = "", y = "") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "bottom")

alloutput


outpsall %>%
  filter(Model %in% c("s1.3", "s1.4")) %>%
  group_by(Model) %>%
  summarise(
    n = n(),
    Bio_all_sum = sum(Bio_all, na.rm = TRUE),
    Recruit_0_sum = sum(Recruit_0, na.rm = TRUE)
  )

```

Difference between scenarios regarding to summary in populations variables in Table \@ref(tab:var_compar) for details.

```{r var_compar}
prom_hist <-outpsall %>%
  group_by(Model) %>%
  summarise(
    Bio_all_hist = mean(Bio_all/1e6, na.rm = TRUE),
    Recruit_0_hist = mean(Recruit_0/1e6, na.rm = TRUE)
  )

ult_5 <-outpsall %>%
  group_by(Model) %>%
  filter(Yr %in% sort(unique(Yr), decreasing = TRUE)[1:5]) %>%
  summarise(
    Bio_all_5yr = mean(Bio_all/1e6, na.rm = TRUE),
    Recruit_0_5yr = mean(Recruit_0/1e6, na.rm = TRUE)
  )

resumen <- left_join(prom_hist, ult_5, by = "Model")

base <- resumen %>% filter(Model == "s1.1")

resumen <- resumen %>%
  mutate(
    Bio_all_hist_pct = 100 * (Bio_all_hist - base$Bio_all_hist) / base$Bio_all_hist,
    Recruit_0_hist_pct = 100 * (Recruit_0_hist - base$Recruit_0_hist) / base$Recruit_0_hist,
    Bio_all_5yr_pct = 100 * (Bio_all_5yr - base$Bio_all_5yr) / base$Bio_all_5yr,
    Recruit_0_5yr_pct = 100 * (Recruit_0_5yr - base$Recruit_0_5yr) / base$Recruit_0_5yr
  )

resumen %>%
  mutate(across(where(is.numeric), ~round(.x, 2))) %>%
  kbl(caption = "Resumen por modelo: promedios históricos, últimos 5 años y cambio porcentual respecto a s1.1") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

```


```{r eval=FALSE}
#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist1_4 <- SSgetoutput(keyvec = NULL,
                       dirvec = c(
                                  dir1.1,
                                  dir1.2,
                                  dir1.3,
                                  dir1.4),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput1_4 <- SSsummarize(biglist1_4)

SSplotComparisons(summaryoutput1_4,
                  legendlabels = c("s1.1 (Ref Model)",
                 "s1.2",
                 "s1.3",
                 "s1.4"),
                 filenameprefix = "COM1",
                 labels = c("Year", 
                            "Spawning biomass (t)",
                            "Relative spawning biomass", 
                            "Age-0 recruits (1,000s)",
                            "Recruitment deviations", 
                            "Index", "Log index", 
                            "1 - SPR", 
                            "Density",
                            "Management target", 
                            "Minimum stock size threshold",
                            "Spawning output",
                            "Harvest rate"),
                 png=TRUE,
                 plotdir=Figs)
```

```{r eval=FALSE}
#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist14 <- SSgetoutput(keyvec = NULL,
                       dirvec = c(
                                  dir1.1,
                                  dir1.4),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput14 <- SSsummarize(biglist14)

comp14 <- SSplotComparisons(summaryoutput14,
                  legendlabels = c("Ref Model: No Env-Predator",
                 "S1.1 w/ Env and Predator data"),
                  filenameprefix = "COM2",
                 labels = c("Year", 
                            "Spawning biomass (t)",
                            "Relative spawning biomass", 
                            "Age-0 recruits (1,000s)",
                            "Recruitment deviations", 
                            "Index", "Log index", 
                            "1 - SPR", 
                            "Density",
                            "Management target", 
                            "Minimum stock size threshold",
                            "Spawning output",
                            "Harvest rate"),
                 png=TRUE,plotdir=Figs)
```

Another comparison in `R0` (Natural log of virgin recruitment level)  (Figure \@ref(fig:r0))

```{r r0, fig.height=5, fig.width=8, warning=FALSE, message=FALSE, fig.cap="R0 probability predicted by scenario"}
r0_vals <- data.frame(
  model = c("s1.1", "s1.2", "s1.3", "s1.4"),
  value = c(base.model1.1$jitter_info[1,1],
            base.model1.2$jitter_info[2,1],
            base.model1.3$jitter_info[1,1],
            base.model1.4$jitter_info[2,1]),
  cv = c(base.model1.1$jitter_info[1,6],
         base.model1.2$jitter_info[2,6],
         base.model1.3$jitter_info[1,6],
         base.model1.4$jitter_info[2,6])
)

x_vals <- seq(10, 30, length.out = 1000)

dens_data <- r0_vals %>%
  rowwise() %>%
  mutate(sd =  cv,  
         density = list(data.frame(
           x = x_vals,
           y = dnorm(x_vals, mean = value, sd = sd),
           model = model
         ))) %>%
  select(density) %>%
  unnest(cols = c(density))

colores <- c("s1.1" = "#ca0020", 
             "s1.2" = "#f4a582", 
             "s1.3" = "#bababa", 
             "s1.4" = "#404040")

r0plot <- ggplot(dens_data, aes(x = x, y = y, color = model, fill = model)) +
  geom_area(alpha = 0.3, position = "identity", size = 0) +  # More transparent areas without borders
  geom_line(size = 1.2) +  # Thicker lines for better visibility
  scale_color_manual(values = colores, name = NULL) +  # Remove legend title for color
  scale_fill_manual(values = colores, name = NULL) +   # Remove legend title for fill
  labs(x = "ln(R0)", 
       y = "Density") +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "bottom",  # Legend at bottom
    legend.spacing.x = unit(0.5, 'cm'),  # Space between legend items
    panel.grid.major = element_line(color = "gray90"),
    panel.grid.minor = element_blank(),
    axis.title = element_text(size = 12),
    legend.text = element_text(size = 11)
  ) +
  xlim(16, 22) +
  guides(color = guide_legend(nrow = 1),  # Single row legend
         fill = guide_legend(nrow = 1))

r0plot
```
Comparsion in sd long term time series forecasting Figure \@ref(fig:cumsum)

```{r cumsum, fig.height=5, fig.width=8, fig.cap="Comparsion in sd long term time series forecasting"}
errt <- data.frame(
  Bio_all_1 = base.model1.1$timeseries$Bio_all,
  Bio_all_2 = base.model1.2$timeseries$Bio_all,
  Bio_all_3 = base.model1.3$timeseries$Bio_all,
  Bio_all_4 = base.model1.4$timeseries$Bio_all,
  
  Bio_smry_1 = base.model1.1$timeseries$Bio_smry,
  Bio_smry_2 = base.model1.2$timeseries$Bio_smry,
  Bio_smry_3 = base.model1.3$timeseries$Bio_smry,
  Bio_smry_4 = base.model1.4$timeseries$Bio_smry,
  
  SpawnBio_1 = base.model1.1$timeseries$SpawnBio,
  SpawnBio_2 = base.model1.2$timeseries$SpawnBio,
  SpawnBio_3 = base.model1.3$timeseries$SpawnBio,
  SpawnBio_4 = base.model1.4$timeseries$SpawnBio,
  
  Recruit_0_1 = base.model1.1$timeseries$Recruit_0,
  Recruit_0_2 = base.model1.2$timeseries$Recruit_0,
  Recruit_0_3 = base.model1.3$timeseries$Recruit_0,
  Recruit_0_4 = base.model1.4$timeseries$Recruit_0
)


err_long <- errt %>%
  pivot_longer(cols = everything(), 
               names_to = "Variable_Model",
               values_to = "Value")

err_long <- err_long %>%
  extract(Variable_Model, into = c("Variable", "Model"), 
          regex = "(.+?)_(\\d+)$")

err_long <- err_long %>%
  mutate(Model = case_when(
    Model == "1" ~ "s1.1",
    Model == "2" ~ "s1.2",
    Model == "3" ~ "s1.3",
    Model == "4" ~ "s1.4",
    TRUE ~ Model
  ))

comsum <- ggplot(err_long, aes(x = Model, y = Value, fill = Model)) +
  geom_boxplot(width = 0.5, outlier.shape = NA,
               outliers = F) +
  #geom_jitter(width = 0.2, alpha = 0.1) +
  facet_wrap(~Variable, ncol=4, 
             scales = "free_y") +
  scale_fill_manual(name = "Scenario",
                    values = c("#ca0020", "#f4a582", "#bababa", "#404040")) +
  labs(title = "",
       x = "",
       y = "") +
  theme_few() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "none")
comsum
```

## Autocorrelation in Recruit 

To evaluate the temporal correlation structure of krill recruitment under different model configurations, we performed an Autocorrelation Function (ACF) analysis (Figure \@ref(fig:acf)). The ACF measures the correlation between observations at different time lags, helping to assess whether recruitment estimates exhibit persistence or randomness across time.

The analysis was conducted on recruitment estimates derived from four model scenarios:

A reference model without environmental or predator influences (Ref Model: No Env-Predator).
A model incorporating predator data (S1.1 w/ Predator data).
A model incorporating environmental data (S1.1 w/ Env data).
A model incorporating both environmental and predator data (S1.1 w/ Env and Predator data).
Each model's residuals were extracted, and the autocorrelation function (ACF) was computed for a time lag range of up to 15 years. The dashed blue lines in the plots represent the 95% confidence intervals, indicating the threshold beyond which correlation values are statistically significant. If autocorrelation values remain within this range, it suggests that the recruitment estimates behave as a random process with no significant dependence on past values. Conversely, autocorrelation values exceeding these bounds indicate recruitment persistence or cyclic patterns.

```{r acf, fig.height=5, fig.width=8, fig.cap="Autocorrelation in Recruit by scenario"}
recs1 <- base.model1.1$recruit$pred_recr
recs2 <- base.model1.2$recruit$pred_recr
recs3 <- base.model1.3$recruit$pred_recr
recs4 <- base.model1.4$recruit$pred_recr

p1 <- ggAcf(base.model1.1$recruit$pred_recr) +
  ggtitle("s1.1") +
  theme_few()
p2 <- ggAcf(base.model1.2$recruit$pred_recr) +
  ggtitle("s1.2") +
  theme_few()
p3 <- ggAcf(base.model1.3$recruit$pred_recr) +
  ggtitle("s1.3") +
  theme_few()
p4 <- ggAcf(base.model1.4$recruit$pred_recr) +
  ggtitle("s1.4") +
  theme_few()

ggarrange(p1, p2,p3,p4, ncol=4, nrow = 1, common.legend = T)

```

The ACF plots indicate that the reference model (without environmental or predator data) exhibits weak but noticeable positive autocorrelation at certain lags, suggesting some degree of recruitment dependence over time. However, this autocorrelation does not appear strong or systematic.

The model incorporating only predator data shows a slight reduction in autocorrelation magnitude, suggesting that predator-driven recruitment variability may have captured part of the temporal structure in the data.

The model with only environmental data exhibits a further reduction in autocorrelation, implying that environmental variability explains a larger portion of recruitment trends than predator effects alone.

Finally, the model that includes both environmental and predator data presents the lowest autocorrelation values, with nearly all bars remaining within the confidence bounds. This suggests that incorporating both factors provides the most effective explanation of recruitment fluctuations, reducing unexplained temporal structure.

Overall, these results indicate that recruitment variability is at least partially driven by environmental and predator influences, and models integrating these factors provide more robust and independent recruitment estimates, minimizing systematic dependencies over time.

## Relationship Stock-Recruit

\[
R = \frac{R_0 \cdot S}{S_0 (1 - h) + S (5h - 1)}
\]

Where:  
- \( R \) is the predicted recruitment.  
- \( S \) is the spawning stock biomass.  
- \( R_0 \) is the recruitment at unfished equilibrium.  
- \( S_0 \) is the spawning biomass at unfished equilibrium.  
- \( h \) is the steepness parameter (the proportion of \( R_0 \) produced when \( S = 20\% \cdot S_0 \)).

The blue line represents the Beverton–Holt stock-recruitment relationship, commonly used in fisheries models to describe the compensatory response of recruitment to changes in spawning biomass.



```{r}
# Lista de modelos base
models <- list(
  s1.1 = base.model1.1,
  s1.2 = base.model1.2,
  s1.3 = base.model1.3,
  s1.4 = base.model1.4
)

colors <- c("s1.1" = "#ca0020", "s1.2" = "#f4a582", "s1.3" = "#bababa", "s1.4" = "#404040")
shapes <- c("s1.1" = 5, "s1.2" = 6, "s1.3" = 15, "s1.4" = 4)

plot_data <- list()
curve_data <- list()
label_data <- list()
params <- data.frame(Model = character(), a = numeric(), b = numeric(), stringsAsFactors = FALSE)
for (group in names(models)) {
  model <- models[[group]]
  l <- model$recruit$SpawnBio
  m <- model$recruit$pred_recr
  yr <- model$timeseries$Yr[1:35]
  
  # Filtrar valores válidos
  valid <- which(is.finite(l) & is.finite(m) & l > 0 & m > 0)
  l <- l[valid]
  m <- m[valid]
  yr <- yr[valid]
  
  plot_data[[group]] <- data.frame(l = l, m = m, yr = yr, Group = group)
  label_data[[group]] <- plot_data[[group]] %>% filter(yr %% 3 == 0)
  
  fit <- NULL
  tryCatch({
    fit <- nls(m ~ (a * l) / (1 + b * l),
               start = list(a = max(m), b = 1 / max(l)),
               data = data.frame(l, m))
    
    l_pred <- seq(min(l), max(l), length.out = 100)
    m_pred <- predict(fit, newdata = data.frame(l = l_pred))
    curve_data[[group]] <- data.frame(l = l_pred, m = m_pred, Group = group)
    
    coefs <- coef(fit)
    params <- rbind(params, data.frame(Model = group, a = coefs["a"], b = coefs["b"]))
    
  }, error = function(e) {
    message(paste("Model", group, ": Beverton-Holt fit failed ->", e$message))
  })
}

# Unir data frames
plot_data_all <- bind_rows(plot_data)
curve_data_all <- bind_rows(curve_data)
label_data_all <- bind_rows(label_data)

# Graficar
srr_sce <- ggplot() +
  geom_point(data = plot_data_all, aes(x = l, y = m, shape = Group), size = 2) +
  geom_line(data = curve_data_all, aes(x = l, y = m, color = Group), linewidth = 1.2) +
  ggrepel::geom_text_repel(data = label_data_all, aes(x = l, y = m, label = yr, color = Group),
                           size = 4, max.overlaps = 50) +
  scale_shape_manual(values = shapes) +
  scale_color_manual(values = colors) +
  theme_bw() +
  ylim(0, max(plot_data_all$m)) +
  labs(x = "Spawning Stock Biomass (SSB)", y = "Predicted Recruitment", shape = "Model", color = "Model") +
  theme(legend.position = "bottom")



```


## Productivity and Interannual Variability by Scenario

Estimating the productivity of Antarctic krill is critical for understanding the species’ capacity to replenish its population in response to varying levels of spawning biomass. Productivity, defined as the ratio of recruitment to spawning stock biomass, provides a standardized measure of reproductive success and population resilience under different ecological and fishing pressures. Comparing productivity across scenarios—each representing different assumptions about environmental drivers, fishing mortality, or predator dynamics—enables a robust evaluation of how krill populations reflect this changes.

For each scenario \( i \) and year \( t \), we computed the productivity as the ratio between recruitment and spawning stock biomass (SSB):

$$
\text{Productivity}_{i,t} = \frac{\text{Recruitment}_{i,t}}{\text{SSB}_{i,t}}
$$

We also calculated the **interannual percentage change** in recruitment and SSB as:

$$
\text{Change in Recruitment}_{i,t} = \left( \frac{\text{Recruitment}_{i,t} - \text{Recruitment}_{i,t-1}}{\text{Recruitment}_{i,t-1}} \right) \times 100
$$

$$
\text{Change in SSB}_{i,t} = \left( \frac{\text{SSB}_{i,t} - \text{SSB}_{i,t-1}}{\text{SSB}_{i,t-1}} \right) \times 100
$$

These metrics allow us to analyze both the productivity and the temporal dynamics of the population under each scenario \( i \).


```{r}
# Simular 4 dataframes por escenario (usa tus datos reales)
escenarios <- list(
  s1.1 = base.model1.1$SPAWN_RECR_CURVE,
  s1.2 = base.model1.2$SPAWN_RECR_CURVE,
  s1.3 = base.model1.3$SPAWN_RECR_CURVE,
  s1.4 = base.model1.4$SPAWN_RECR_CURVE
)

# Crea una tabla con productividad y cambios para cada escenario
resultados <- purrr::imap_dfr(escenarios, function(df, nombre) {
  df %>%
    mutate(
      Scenario = nombre,
      Productividad = Recruitment / SSB,
      Cambio_Recruit = c(NA, diff(Recruitment)) / lag(Recruitment) * 100,
      Cambio_SSB = c(NA, diff(SSB)) / lag(SSB) * 100
    )
})


prod <- ggplot(resultados, aes(x = `SSB/SSB_virgin`, y = Productividad, 
                       color = Scenario)) +
  geom_point(size = 1.1) +
  labs(title = "",
       y = "Recruitment / SSB",
       x = "SSB / SSB_virgin") +
  scale_color_manual(name= "",
                    values = c("s1.1" = "#ca0020", 
                               "s1.2" = "#f4a582", 
                               "s1.3" = "#bababa", 
                               "s1.4" = "#404040")) +
  theme_bw() +
  theme(legend.position = "bottom")
```


These two panels in Figure \@ref(fig:recpro) provide insight into the stock-recruitment dynamics of Antarctic krill under four assessment scenarios, each incorporating different levels of ecosystem complexity. Left panel compares the predicted recruitment across years with corresponding spawning biomass values for the four model scenarios (s1.1 to s1.4). Scenario s1.1 (red) shows a relatively flat and optimistic Beverton-Holt relationship, with high recruitment predicted even at low levels of SSB. The other scenarios, particularly s1.3 (gray) and s1.4 (black), show much more constrained recruitment estimates and a more saturating relationship, where recruitment increases only slightly with increasing SSB. This suggests that incorporating environmental (s1.3) and predator (s1.4) effects leads to a more conservative and ecologically realistic recruitment dynamic. Year labels illustrate how certain years (e.g., 2004, 2016, 2022) deviate between scenarios, especially at low biomass levels.

Right panel displays recruitment efficiency (Recruitment/SSB) as a function of relative spawning biomass (SSB / SSB₀). In all models, recruitment efficiency is highest at very low biomass levels and declines as SSB increases, consistent with compensatory dynamics. However, s1.3 and s1.4 (which include environmental effects) show significantly lower overall productivity across all SSB levels compared to s1.1 and s1.2. This indicates that the inclusion of ecosystem drivers reduces the per-capita productivity of the stock, especially under depleted conditions.

Together, these plots indicate that ecosystem-informed models (s1.3 and s1.4) produce more constrained and precautionary estimates of krill productivity. The more optimistic recruitment predicted by s1.1 (and to a lesser extent s1.2) may overestimate stock resilience, particularly in low SSB conditions. These findings emphasize the importance of accounting for environmental variability and predator dynamics in stock assessment models to avoid overoptimistic management advice and better reflect the biological limits of the krill population.

```{r recpro, fig.height=4, fig.width=6, fig.cap="Left panel: Stock–recruitment relationships for Antarctic krill under four assessment scenarios. Predicted recruitment as a function of spawning stock biomass (SSB), with fitted Beverton-Holt curves and annual labels for selected years. Right panel: Recruitment per unit of SSB plotted against relative SSB (SSB/SSBo), illustrating differences in per-capita productivity across models ( s1.1 (no ecosystem variables), s1.2 (with predator effects), s1.3 (with environmental variables), and s1.4 (with both predator and environmental effects))"}
ggarrange(srr_sce,
          prod,
          ncol = 2)
```





```{r eval=FALSE, warning=FALSE}
## Recruit deviation
dev1 <- base.model1.1$recruit[8:35,c(1,7)]%>% 
  mutate(Serie = "s1.1")
dev2 <- base.model1.2$recruit[8:35,c(1,7)] %>% 
  mutate(Serie = "s1.2")
dev3 <- base.model1.3$recruit[8:35,c(1,7)] %>% 
  mutate(Serie = "s1.3")
dev4 <- base.model1.4$recruit[8:35,c(1,7)] %>% 
  mutate(Serie = "s1.4")


data_list <- list(dev1, 
                  dev2,
                  dev3,
                  dev4)
titles <- c("Ref Model: No Env-Predator",
                 "S1.1 w/ Predator data",
                 "S1.1 w/ Env data",
                 "S1.1 w/ Env and Predator data")
# Lista para almacenar los gráficos
plots <- list()

for (i in 1:length(data_list)) {
  p <- ggplot(data_list[[i]], aes(x = Yr, y = dev)) +
    geom_point() +
    stat_smooth(method = "loess", 
                span = 0.15, 
                se = T) +
    geom_hline(yintercept = 0,
               col="red",
               linetype = "dotdash")+
    ggtitle(titles[i]) +
    theme(axis.text.x = element_text(angle = 90,
                                   hjust = 1))+
    ylim(-2,2)+
    theme_few()
  plots[[i]] <- p
}

# Organizar los gráficos con ggarrange
combined_plot <- ggarrange(plotlist = plots, ncol = 2, nrow = 2)

combined_plot
```


## Explotation Rate

Explotation rato (havest rate) in Figure \@ref(fig:hrate)

```{r hrate, warning=FALSE, message=FALSE, fig.cap="Harves rate by scenario in krill overtime"}
df1 <- base.model1.1$exploitation[, c(1, 4)] %>% mutate(model = "s1.1")
df2 <- base.model1.2$exploitation[, c(1, 4)] %>% mutate(model = "s1.2")
df3 <- base.model1.3$exploitation[, c(1, 4)] %>% mutate(model = "s1.3")
df4 <- base.model1.4$exploitation[, c(1, 4)] %>% mutate(model = "s1.4")


df_all <- bind_rows(df1, df2, df3, df4)
colnames(df_all) <- c("year", "exploitation_rate", "model")

colores <- c("s1.1" = "#ca0020", 
             "s1.2" = "#f4a582", 
             "s1.3" = "#bababa", 
             "s1.4" = "#404040")
ggplot(df_all, aes(x = year, y = exploitation_rate, color = model)) +
  geom_line() +
  geom_point(size = 3, shape = 16) +
  scale_color_manual(values = colores) +
  scale_x_continuous(
    breaks = seq(1998, 2020, by = 1)  # etiquetas cada 2 años
  ) +
  labs(
    title = "",
    x = "",
    y = "Exploitation Rate",
    color = "Model"
  ) +
  xlim(1997,2020)+
  theme_minimal()+
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)  # texto vertical
  )
```
```{r}
# Calcular promedio por modelo
summary_table <- df_all %>%
  group_by(model) %>%
  summarise(
    mean_exploitation = mean(exploitation_rate, na.rm = TRUE),
    exploitation_2020 = exploitation_rate[year == 2020]
  ) %>%
  mutate(
    pct_difference = (exploitation_2020 - exploitation_2020[model == "s1.1"]) / 
                     exploitation_2020[model == "s1.1"] * 100
  )

# Formatear y mostrar la tabla
summary_table %>%
  mutate(
    mean_exploitation = round(mean_exploitation, 4),
    exploitation_2020 = round(exploitation_2020, 4),
    pct_difference = ifelse(model == "s1.1", 0, round(pct_difference, 1))
  ) %>%
  kbl(
    col.names = c("Model", "Mean Exploitation Rate", "Exploitation Rate (2020)", "% Difference vs. s1.1")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

<!-- ### Platoons analisis -->

<!-- ```{r} -->
<!-- # Definir los valores del eje x -->
<!-- x_values <- seq(0, 7, by=0.1) -->

<!-- # Definir las medias y desviaciones estándar para los valores específicos -->
<!-- means <- c( 2.9,  3.5, 4.1) -->
<!-- std_devs <- c(0.65, 0.8, 0.65) -->


<!-- # Crear un dataframe que contenga los valores de x, la media y las desviaciones estándar -->
<!-- data <- data.frame( -->
<!--   x = rep(x_values, each = length(means)), -->
<!--   mean = rep(means, times = length(x_values)), -->
<!--   std_dev = rep(std_devs, times = length(x_values)) -->
<!-- ) -->

<!-- # Calcular las curvas de las desviaciones estándar -->
<!-- data <- data %>% -->
<!--   mutate(y = exp(-((x - mean)^2) / (2 * std_dev^2))) -->

<!-- # Graficar con ggplot -->
<!-- ggplot(data, aes(x = x, y = y, linetype = as.factor(mean))) + -->
<!--   geom_line(size = 1) + -->
<!--   scale_linetype_manual(values = means, -->
<!--                         name ="Platoon") + -->
<!--   labs(x = "", y = "growth increment") + -->
<!--   theme_minimal()+ -->
<!--   xlim(0,7) -->

<!-- ``` -->



## Diagnosis and robustness

A rigorous model diagnosis is essential to ensure the reliability and robustness of stock assessment models. The key steps for a good practice in model diagnosis include:  

1. Convergence Check: The model must reach a final convergence criterion of 1.0e-04 to ensure numerical stability and reliable parameter estimation.  

2. Residual Analysis: Both visual inspection and statistical metrics are used to evaluate model residuals, helping to detect patterns of bias or misfit.  

3. Retrospective Analysis: The Mohn’s rho parameter is used to assess the consistency of model estimates when sequentially removing recent years of data, identifying potential overestimation or underestimation trends.  

4. Likelihood Profile Analysis: This approach examines how the likelihood function behaves across a range of parameter values, providing insight into parameter uncertainty and model sensitivity.  

This framework follows the recommendations outlined by @Carvalho2021b, aiming to enhance transparency and reproducibility in model evaluation.

### Convergence Criteria

The convergence criterion used for model calibration is set to a final threshold of **0.0001** (or equivalently **1.0e-04**). This criterion defines the minimum acceptable difference between successive model iterations. Convergence is considered achieved when the absolute change in the objective function value or key parameters falls below this threshold. A smaller convergence value ensures that the model achieves a high degree of accuracy and stability in its final estimates, indicating that further iterations are unlikely to result in significant changes to the parameter estimates.


### Residuals 

Figure \@ref(fig:bubble1), \@ref(fig:bubble2), \@ref(fig:bubble3) and \@ref(fig:bubble4) displays bubble plots of krill length-frequency distributions across different spatial strata and years. Each panel corresponds to a fishery-dependent or independent data source (e.g., FISHERYBS, SURVEYBS), and shows the proportional abundance of krill in different length classes (y-axis) over time (x-axis). The size of each circle is proportional to the relative frequency or standardized number of individuals in a given length bin for a specific year, providing a visual summary of size structure dynamics across regions and time periods.


```{r bubble, fig.width=8, fig.height=6, fig.cap="Pearson residuals, comparing across fleets (plot 1 of 2) Closed bubbles are positive residuals (observed > expected) and open bubbles are negative residuals (observed < expected) s1.1"}
SSplotComps(base.model1.1,
            subplots = 24,
            maxrows = 9)
```


```{r bubble2,  fig.width=8, fig.height=6, fig.cap="Pearson residuals, comparing across fleets (plot 1 of 2) Closed bubbles are positive residuals (observed > expected) and open bubbles are negative residuals (observed < expected) s1.2"}
SSplotComps(base.model1.2,
            subplots = 24,
            maxrows = 10)
```


```{r bubble3,  fig.width=8, fig.height=6, fig.cap="Pearson residuals, comparing across fleets (plot 1 of 2) Closed bubbles are positive residuals (observed > expected) and open bubbles are negative residuals (observed < expected) s1.3"}
SSplotComps(base.model1.3,
            subplots = 24,
            maxrows = 9)
```


```{r bubble4,  fig.width=8, fig.height=6, fig.cap="Pearson residuals, comparing across fleets (plot 1 of 2) Closed bubbles are positive residuals (observed > expected) and open bubbles are negative residuals (observed < expected) s1.4"}
SSplotComps(base.model1.4,
            subplots = 24,
            maxrows = 10)
```


This Figure \@ref(fig:pearson) shows the Pearson residuals of predicted length distributions for krill across four modeling scenarios, each incorporating different levels of ecosystem complexity. The residuals are visualized by year and length bin, allowing an assessment of model fit over time and across the size structure of the population. In the "Without Ecosystem Variables" scenario (top left), substantial lack of fit is evident across multiple years and length classes, particularly in the late 1990s and early 2000s. Positive Pearson residuals indicate that the model tends to underestimate frequencies of certain length bins, especially among smaller and mid-sized individuals, suggesting poor representation of recruitment and growth dynamics in the absence of environmental and predator effects. The "With Predator" scenario (top right) shows some improvement in model fit, with slightly more balanced residuals. However, there are still consistent deviations in the mid-size ranges across multiple years, indicating that predation alone does not fully explain observed variability in length composition. In the "With Environment" scenario (bottom left), there is a noticeable reduction in residual magnitude across several years and size classes, implying that incorporating environmental covariates helps align the model more closely with observed size distributions. This is particularly apparent in the early 2000s, where the residuals are closer to zero across most bins. Finally, the "With Predator and Ecosystem" scenario (bottom right) shows the most consistent reduction in Pearson residuals across time and size structure. The distribution of residuals is more homogeneous and centered around zero, indicating that the combined inclusion of predator and environmental drivers leads to the best model fit among the four scenarios.

Overall, the results support the conclusion that ecosystem-informed models better capture the temporal and size-structured dynamics of krill, with the **joint inclusion of predator and environmental variables** yielding the most robust representation of observed length compositions.


```{r pearson, fig.cap="Pearson residual by scenario and fleet"}
create_heatmap_df <- function(df, model_name) {
  df %>%
    dplyr::filter(Pearson < 5) %>%
    dplyr::select(c(1, 6, 19, 16)) %>%
    dplyr::mutate(Fleet = dplyr::case_when(
      Fleet == 1 ~ "FISHERYBS",
      Fleet == 2 ~ "FISHERYEI",
      Fleet == 3 ~ "FISHERYGS",
      Fleet == 4 ~ "FISHERYJOIN",
      Fleet == 5 ~ "FISHERYSSIW",
      Fleet == 6 ~ "SURVEYBS",
      Fleet == 7 ~ "SURVEYEI",
      Fleet == 8 ~ "SURVEYGS",
      Fleet == 9 ~ "SURVEYJOIN",
      Fleet == 10 ~ "SURVEYSSIW",
      Fleet == 11 ~ "PREDATOR",
      TRUE ~ NA_character_
    )) %>%
    dplyr::mutate(Model = model_name)
}

# Unir los datasets en uno solo
df_all <- bind_rows(
  create_heatmap_df(base.model1.1$lendbase, "Model 1.1"),
  create_heatmap_df(base.model1.2$lendbase, "Model 1.2"),
  create_heatmap_df(base.model1.3$lendbase, "Model 1.3"),
  create_heatmap_df(base.model1.4$lendbase, "Model 1.4")
)

# # Plot combinado: facet_grid por Modelo y Fleet
# heatmapres <- ggplot(df_all, aes(x = Yr, y = Bin, fill = Pearson)) +
#   geom_tile() +
#   scale_fill_gradient2(low = "red", 
#                        mid = "white", 
#                        high = "blue",
#                        midpoint = 0) +
#   facet_grid(Model ~ Fleet) +
#   theme_few() +
#   theme(
#     axis.text.x = element_text(angle = 90, hjust = 1, size = 5),         
#     axis.text.y = element_text(size = 5),                               
#     strip.text = element_text(size = 8),                                 
#     legend.position = "none"
#   ) +
#   labs(x = "", y = "Length (cm)", fill = "Pearson")
# 
# heatmapres

circleplot_res <- ggplot(df_all, aes(x = Yr, y = Bin)) +
  geom_point(aes(fill = Pearson, size = abs(Pearson)),
             shape = 21, color = "grey30", stroke = 0.2, alpha = 0.25) +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue", midpoint = 0) +
  scale_alpha("none") +
  scale_size_continuous(range = c(0.5, 2.5)) +
  facet_grid(Model ~ Fleet) +
  theme_few() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 5),         
    axis.text.y = element_text(size = 5),                               
    strip.text = element_text(size = 8),
    legend.position = "bottom"
  ) +
  labs(x = "", y = "Length (cm)", fill = "Pearson") +
  guides(size = "none", alpha = "none")  # Esto oculta las leyendas de size y alpha

circleplot_res
```

```{r}
cpue_resid <- bind_rows(
  base.model1.1$cpue %>% mutate(model = "s1.1"),
  base.model1.2$cpue %>% mutate(model = "s1.2"),
  base.model1.3$cpue %>% mutate(model = "s1.3"),
  base.model1.4$cpue %>% mutate(model = "s1.4")
)


len_resid <- bind_rows(
  base.model1.1$lendbase %>% mutate(model = "s1.1"),
  base.model1.2$lendbase %>% mutate(model = "s1.2"),
  base.model1.3$lendbase %>% mutate(model = "s1.3"),
  base.model1.4$lendbase %>% mutate(model = "s1.4")
)

cpue_df <- cpue_resid %>%
  transmute(
    Yr = Yr,
    Obs = Obs,
    Exp = Exp,
    model = model,
    Fleet_name = as.character(Fleet_name),  # Asegura que es character
    type = "Index"
  )

len_df <- len_resid %>%
  transmute(
    Yr = Yr,
    Obs = Obs,
    Exp = Exp,
    model = model,
    Fleet_name = as.character(Fleet),  # Lo convertimos para que combine bien
    type = "Length"
  )

resid_all <- rbind(cpue_df,
                   len_df)

resid_all <- resid_all %>%
  mutate(Fleet_name = as.character(Fleet_name),
         Fleet_name = case_when(
           Fleet_name == "1"  ~ "FISHERYBS",
           Fleet_name == "2"  ~ "FISHERYEI",
           Fleet_name == "3"  ~ "FISHERYGS",
           Fleet_name == "4"  ~ "FISHERYJOIN",
           Fleet_name == "5"  ~ "FISHERYSSIW",
           Fleet_name == "6"  ~ "SURVEYBS",
           Fleet_name == "7"  ~ "SURVEYEI",
           Fleet_name == "8"  ~ "SURVEYGS",
           Fleet_name == "9"  ~ "SURVEYJOIN",
           Fleet_name == "10" ~ "SURVEYSSIW",
           Fleet_name == "11" ~ "PREDATOR",
           TRUE ~ Fleet_name  # mantiene los nombres ya correctos
         ))

```

Also, we can check density of residual distribution in Figure \@ref(fig:resldens)

```{r resldens, fig.width=10, fig.height=6, fig.cap="Density of residual distribution by scenarios in krill model"}
ggplot(resid_all, aes(x = Obs - Exp, color = model)) +
  geom_density(alpha = 0.5) +
  facet_wrap(Fleet_name~type, scales = "free") +
  labs(title = "Residual Distribution", 
       x = "Residual (Obs - Exp)", 
       y = "Density") +
  scale_color_manual(name = "",
                     values = c("s1.1" = "#ca0020",  
                                "s1.2" = "#f4a582",  
                                "s1.3" = "#bababa",  
                                "s1.4" = "#404040")) +
  theme_minimal()
```
### Residual consistency 

Residual analysis is a critical component of model diagnostics in stock assessments. It helps evaluate the fit of the model to observed data and detect potential biases or inconsistencies. This process is applied to both length composition data and abundance indices such as CPUE (Catch Per Unit Effort) and survey-derived estimates. For length composition data, residuals represent the difference between observed and model-predicted length distributions. The standardized residuals are calculated as the difference between observed and expected proportions at each length bin. These residuals are plotted by year to identify systematic trends, biases, or inconsistencies in the data. Ideally, they should be randomly distributed around zero, indicating no systematic over- or underestimation.  

For abundance indices such as CPUE and fishery-independent surveys, residuals are analyzed to assess model fit and potential sources of bias. Residuals are computed as the difference between observed index values and those predicted by the model, typically standardized by dividing by the standard error to facilitate comparison across years. These residuals are then plotted over time to evaluate trends. A shaded confidence region, like the green area in the provided plot, represents expected variability, with outliers highlighted in red or other distinct markers. Persistent positive or negative residuals may indicate systematic bias in the model or data collection process.  

Statistical diagnostics are also performed to check for autocorrelation in residuals, which can indicate potential model misspecifications. When mean residual values are close to zero, the model fit is considered unbiased. By integrating these residual analyses for both length and abundance indices, stock assessment models can be refined, improving their reliability and increasing confidence in the assessment results.

```{r}
par(mfrow=c(2,4), mar=c(5,4,2,1)) 
SSplotRunstest(base.model1.1,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = Figs)
par(mfrow=c(2,5), mar=c(5,4,2,1)) 
SSplotRunstest(base.model1.2,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = Figs)
par(mfrow=c(2,4), mar=c(5,4,2,1)) 
SSplotRunstest(base.model1.3,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = Figs)
par(mfrow=c(2,5), mar=c(5,4,2,1)) 
SSplotRunstest(base.model1.4,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = Figs)
```


```{r}
par(mfrow=c(2,5), mar=c(5,4,2,1))
SSplotRunstest(base.model1.1,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = Figs)
par(mfrow=c(2,5), mar=c(5,4,2,1))
SSplotRunstest(base.model1.2,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = Figs)
par(mfrow=c(2,5), mar=c(5,4,2,1))
SSplotRunstest(base.model1.3,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = Figs)
par(mfrow=c(2,5), mar=c(5,4,2,1))
SSplotRunstest(base.model1.4,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = Figs)
```


### Residual Analysis and RMSE 

Residual analysis of mean length data is a fundamental diagnostic tool in stock assessments. It helps evaluate whether the model provides an unbiased fit to the observed data and detects potential biases over time. In this figure, mean length residuals are plotted across years, differentiated by data source, including fishery-dependent (FISHERY) and fishery-independent (SURVEY) datasets, as well as predator-related observations (PREDATOR). The residuals represent the deviation of observed mean length from model-predicted values, standardized to facilitate interpretation.  

The black line represents a locally estimated scatterplot smoothing (Loess) curve, which provides a trend line to visualize systematic deviations over time. The presence of persistent positive or negative trends in the residuals may indicate biases in the growth model, selectivity assumptions, or misrepresentation of recruitment variability. The gray bars highlight periods where residual variability is particularly high, suggesting potential inconsistencies between observed and predicted size structures.  

RMSE quantifies the overall deviation between observed and predicted values, providing an aggregate measure of model fit. Lower RMSE values indicate better agreement between observed and predicted data. In fisheries stock assessment [@HurtadoF2015], RMSE thresholds for acceptable model performance typically range between *10% and 30%*, depending on the data quality and complexity of the population dynamics being modeled. Values exceeding this range suggest potential biases, requiring further investigation into the model structure, parameter estimation, or data sources.   

By analyzing residual patterns and RMSE values, the model can be refined to improve the accuracy of mean length predictions, ultimately enhancing the reliability of stock assessment outcomes and management recommendations (Figure \@ref(fig:rmse1)).

```{r rmse1, fig.height=8, fig.width=8, fig.cap="Time series of RMSE of length compositions by scenario"}
par(mfrow=c(2,2), mar=c(5,4,2,1))
rmse1l <- SSplotJABBAres(base.model1.1,
               subplots = "len",
               add=T)
rmse2l <- SSplotJABBAres(base.model1.2,
               subplots = "len",
               add=T)
rmse3l <- SSplotJABBAres(base.model1.3,
               subplots = "len",
               add=T)
rmse4l <- SSplotJABBAres(base.model1.4,
               subplots = "len",
               add=T)
```
Figure \@ref(fig:rmse2) show RMSE to index.

```{r rmse2, fig.height=8, fig.width=8, fig.cap="Time series of RMSE of CPUE compositions by scenario"}
par(mfrow=c(2,2), mar=c(5,4,2,1))
rmse1c <- SSplotJABBAres(base.model1.1,
               subplots = "cpue",
               add=T)
rmse2c <- SSplotJABBAres(base.model1.2,
               subplots = "cpue",
               add=T)
rmse3c <- SSplotJABBAres(base.model1.3,
               subplots = "cpue",
               add=T)
rmse4c <- SSplotJABBAres(base.model1.4,
               subplots = "cpue",
               add=T)
```
### Comparision RMSE

```{r}
dfpearson_long <- data.frame(
  Pearson = c(base.model1.1$lendbase$Pearson,
              base.model1.2$lendbase$Pearson,
              base.model1.3$lendbase$Pearson,
              base.model1.4$lendbase$Pearson),
  Scenario = factor(c(rep("s1.1", length(base.model1.1$lendbase$Pearson)),
                      rep("s1.2", length(base.model1.2$lendbase$Pearson)),
                      rep("s1.3", length(base.model1.3$lendbase$Pearson)),
                      rep("s1.4", length(base.model1.4$lendbase$Pearson))))
)

pearson_plot <- ggplot(dfpearson_long, aes(x = Scenario, 
                                            y = Pearson, 
                                            fill = Scenario)) +
  geom_boxplot(width = 0.2, alpha = 0.8,
               outliers = FALSE) +
  #geom_jitter(width = 0.01, alpha = 0.3) +
  theme_minimal() +
  scale_fill_manual(name = "Scenario",
                    values = c("s1.1" = "#ca0020", 
                               "s1.2" = "#f4a582", 
                               "s1.3" = "#bababa", 
                               "s1.4" = "#404040")) +
  labs(title = "", x = "", y = "Residual") +
  theme(legend.position = "none")

```


```{r}
dfrmse <- data.frame(
  s1.1 = as.numeric(base.model1.1$index_variance_tuning_check$RMSE),
  s1.2 = as.numeric(base.model1.2$index_variance_tuning_check$RMSE[1:10]),
  s1.3 = as.numeric(base.model1.3$index_variance_tuning_check$RMSE[1:10]),
  s1.4 = as.numeric(base.model1.4$index_variance_tuning_check$RMSE[1:10])
  )
#summary(dfrmse)
# t.test(dfrmse$s1.1, dfrmse$s1.2)  # Comparar s1.1 vs s1.2
# t.test(dfrmse$s1.1, dfrmse$s1.3)  # Comparar s1.1 vs s1.3
# t.test(dfrmse$s1.2, dfrmse$s1.3)
# t.test(dfrmse$s1.3, dfrmse$s1.4)
# anova_rmse <- aov(as.numeric(unlist(dfrmse)) ~ rep(1:4, each=nrow(dfrmse)))
```


```{r}
dfrmse_long <- reshape2::melt(dfrmse)

# # Calccculo
# 
# resumen <- dfrmse_long %>%
#   group_by(variable) %>%
#   summarise(
#     media = mean(value),
#     desviacion_estandar = sd(value)
#   )

rmse <-ggplot(dfrmse_long, aes(x = variable, 
                        y = value, 
                        fill= variable)) +
  geom_boxplot(width=0.2,
               alpha=0.8,
               outliers = FALSE) +
  geom_jitter(width = 0.01, alpha = 0.3) +
  theme_minimal() +
  scale_fill_manual(name= "Scenario",
                    values = c("s1.1" = "#ca0020", 
                               "s1.2" = "#f4a582", 
                               "s1.3" = "#bababa", 
                               "s1.4" = "#404040")) +
  labs(title = "", x = "", y = "RMSE")+
  theme(legend.position = "none")
```

The Figure \@ref(fig:rmse3) presents evaluation results for krill models across different scenarios (s1.1 to s1.4). The RMSE (Root Mean Square Error) values range from 0.5 to 1.5, with lower values indicating better model accuracy. The Residuals vary between -1.0 and 1.0, showing deviations between predicted and observed values. Smaller residuals suggest better model fit. Scenario s1.4 appears to have the lowest RMSE (0.5), indicating higher precision, while residuals near zero in some scenarios reflect balanced predictions.



```{r rmse3, fig.cap="RMSE and Residual values for krill model evaluation across scenarios (s1.1-s1.4), highlighting precision and prediction errors."}
ggarrange(rmse,
          pearson_plot,
          ncol=2)
```


This boxplot compares a summary of the Root Mean Square Error (RMSE) across four different models (s1.1, s1.2, s1.3, and s1.4). RMSE serves as an indicator of model accuracy, with lower values representing better predictive performance.

s1.1 exhibits the lowest median RMSE, suggesting it has the best overall fit among the four models. In contrast, Models 1.2, 1.3, and 1.4 show higher RMSE values, indicating comparatively lower predictive accuracy. The interquartile range (IQR) of these models is relatively similar, suggesting comparable variability in RMSE across models. Additionally, s1.1 has an outlier above 1.5 RMSE, which could indicate a case where the model's predictions deviated significantly from observed values.

Overall, this analysis highlights that incorporating different environmental or predator-related variables in the models impacts their predictive ability. The differences in RMSE suggest that some models may overfit or underfit the recruitment patterns of krill, emphasizing the need to refine model selection based on ecological and statistical considerations.





```{r eval=FALSE}
### Compara Fishing Mortality.
escenarios <- list(
  s1.1 = base.model1.1$exploitation[1:5],
  s1.2 = base.model1.2$exploitation[1:5],
  s1.3 = base.model1.3$exploitation[1:5],
  s1.4 = base.model1.4$exploitation[1:5]
)

# Calcula el cambio porcentual entre años para F_std y annual_F
# Calcula el cambio relativo entre años para F_std y annual_F
# Calcula el cambio relativo entre años para F_std y annual_F
resultados <- purrr::imap_dfr(escenarios, function(df, nombre) {
  df %>%
    mutate(
      Scenario = nombre,
      Relativo_Fstd = c(NA, diff(F_std) / head(F_std, -1)),  # Cambio relativo de F_std
      Relativo_annual_F = c(NA, diff(annual_F) / head(annual_F, -1))  # Cambio relativo de annual_F
    )
})


# Visualiza los resultados en un gráfico
ggplot(resultados, aes(x = Yr, y = Relativo_Fstd, color = Scenario)) +
  geom_line(size = 1.1) +
  labs(title = "Cambio porcentual en F_std entre años por escenario",
       x = "Año",
       y = "Cambio porcentual en F_std") +
  scale_color_manual(name= "Scenario",
                    values = c("s1.1" = "#ca0020", 
                               "s1.2" = "#f4a582", 
                               "s1.3" = "#bababa", 
                               "s1.4" = "#404040")) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "bottom")

# Gráfico para annual_F
ggplot(resultados, aes(x = Yr, y = Relativo_annual_F, color = Scenario)) +
  geom_line(size = 1.1) +
  labs(title = "Cambio porcentual en annual_F entre años por escenario",
       x = "Año",
       y = "Cambio porcentual en annual_F") +
  scale_color_manual(name= "Scenario",
                    values = c("s1.1" = "#ca0020", 
                               "s1.2" = "#f4a582", 
                               "s1.3" = "#bababa", 
                               "s1.4" = "#404040")) +
  theme_minimal(base_size = 13) +
  theme(legend.position = "bottom")

```

### Retrospective Analysis in Model Evaluation

Retrospective analyses provide insights into the differences in estimation patterns (underestimation or overestimation) among the models evaluated. These analyses assess the consistency and reliability of stock assessment models by systematically removing the most recent years of data and comparing the resulting estimates with the full dataset.  In this study, we conducted a retrospective analysis to examine the sensitivity of our recruitment and spawning stock biomass (SSB) estimates to the inclusion or exclusion of recent data. By applying this approach to multiple models, we identified potential biases and evaluated the stability of the recruitment estimates over time.  The retrospective patterns were assessed by calculating the relative error between the predictions of truncated datasets and the full dataset. These differences allowed us to detect trends in model performance, such as systematic overestimation or underestimation of key population parameters. 

```{r eval=FALSE}
#one by one
retro(
    dir = dir1.1,
    oldsubdir = "",
    newsubdir = "Retrospective",
    years = 0:-4,
    exe = "ss_osx",
    extras = "-nox",
    skipfinished = FALSE)
```


```{r eval=FALSE}
directorios <- c("s1.1",
                 "s1.2",
                 "s1.3",
                 "s1.4")  
for (dir in directorios) {
  retro(
    dir = dir,
    oldsubdir = "",
    newsubdir = "Retrospective",
    years = 0:-5,
    exe = "ss_osx",
    extras = "-nox",
    skipfinished = FALSE
  )
}
```

```{r message=FALSE, warning=FALSE}
#stest
retroModels1.1 <- SSgetoutput(dirvec=file.path(dir1.1,
                                            "Retrospective",
                                            paste("retro",0:-4,
                                                  sep="")))

retroSummary1.1 <- SSsummarize(retroModels1.1)
#stest
retroModels1.2 <- SSgetoutput(dirvec=file.path(dir1.2,
                                            "Retrospective",
                                            paste("retro",0:-4,
                                                  sep="")))

retroSummary1.2 <- SSsummarize(retroModels1.2)
#stest
retroModels1.3 <- SSgetoutput(dirvec=file.path(dir1.3,
                                            "Retrospective",
                                            paste("retro",0:-4,
                                                  sep="")))

retroSummary1.3 <- SSsummarize(retroModels1.3)
#stest
retroModels1.4 <- SSgetoutput(dirvec=file.path(dir1.4,
                                            "Retrospective",
                                            paste("retro",0:-4,
                                                  sep="")))

retroSummary1.4 <- SSsummarize(retroModels1.4)


```


Using `retro()` and `SSplotRetro()` functions, we obtain main results

Retrospective analysis for spawning biomass (Figure \@ref(fig:retrossb))

```{r retrossb, fig.cap="Retrospective analysis for spawning biomass by scenario in krill"}
par(mfrow=c(2,2), mar=c(5,4,1,1)) 
retro1.1 <- SSplotRetro(retroSummary1.1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro1.2 <- SSplotRetro(retroSummary1.2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro1.3 <- SSplotRetro(retroSummary1.3,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro1.4 <- SSplotRetro(retroSummary1.4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
```

Retrospective analysis for fishing mortality (Figure \@ref(fig:retrof))

```{r retrof, fig.cap="Retrospective analysis for fishing mortality by scenario in krill"}
par(mfrow=c(2,2), mar=c(5,4,1,1)) 
retro1.1 <- SSplotRetro(retroSummary1.1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro1.2 <- SSplotRetro(retroSummary1.2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro1.3 <- SSplotRetro(retroSummary1.3,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro1.4 <- SSplotRetro(retroSummary1.4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
```


```{r}
# model01
tablebias01 <- SShcbias(retroSummary1.1,quant="SSB",verbose=F)
tablebias01a <- SShcbias(retroSummary1.1,quant="F",verbose=F)

kbl(tablebias01, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s01")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias01a, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s01")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model2
tablebias2 <- SShcbias(retroSummary1.2,quant="SSB",verbose=F)
tablebias2a <- SShcbias(retroSummary1.2,quant="F",verbose=F)

kbl(tablebias2, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias2a, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model3
tablebias3 <- SShcbias(retroSummary1.3,quant="SSB",verbose=F)
tablebias3a <- SShcbias(retroSummary1.3,quant="F",verbose=F)

kbl(tablebias3, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s3")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias3a, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s3")  %>% 
    kable_styling(latex_options = "HOLD_position")


# model4
tablebias4 <- SShcbias(retroSummary1.4,quant="SSB",verbose=F)
tablebias4a <- SShcbias(retroSummary1.4,quant="F",verbose=F)

kbl(tablebias4, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s4")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias4a, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s4")  %>% 
    kable_styling(latex_options = "HOLD_position")


# Combine the results from all models into one table
tablebias_combined <- bind_rows(
  data.frame(Model = "s1.1", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary1.1, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s1.1", 
             Quant = "F", 
             Rho = SShcbias(retroSummary1.1, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s1.2", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary1.2, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s1.2", 
             Quant = "F", 
             Rho = SShcbias(retroSummary1.2, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s1.3", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary1.3, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s1.3", 
             Quant = "F", 
             Rho = SShcbias(retroSummary1.3, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s1.4", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary1.4, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s1.4",
             Quant = "F", 
             Rho = SShcbias(retroSummary1.4, 
                            quant = "F", verbose = F))
)
```

Figure \@ref(fig:bias) presents the retrospective bias (*Rho*) in Spawning Stock Biomass (SSB) and Fishing Mortality (F) across different peel years (2019–2016) and for the combined period under four model scenarios (s1.1 to s1.4). In the SSB panel, all models exhibit negative *Rho* values across the years, indicating a downward bias. The magnitude of the bias varies among models, with s1.3 and s1.4 showing the most pronounced deviations. In the F panel, *Rho* values are consistently positive, suggesting an upward bias. The combined *Rho* values for each metric confirm these trends, showing persistent differences among model scenarios.

```{r bias, fig.cap= "Summary of retrospective analisis by scenario in F and SSB"}
tablebias_combined <- tablebias_combined %>%
  mutate(Rho.peel = factor(Rho.peel, levels = unique(Rho.peel)))

ggplot(tablebias_combined, aes(x = Rho.peel, y = Rho.Rho, group = Model, fill = Model)) +
  geom_point(size = 3, shape = 21, color = "black") +  
  geom_hline(yintercept = 0, color = "grey") +
  facet_wrap(~Quant, scales = "free_y") + 
  scale_fill_manual(name = "Scenario",
                    values = c("s1.1" = "#ca0020", 
                               "s1.2" = "#f4a582", 
                               "s1.3" = "#bababa", 
                               "s1.4" = "#404040")) +
  scale_color_manual(name = "Scenario",
                     values = c("s1.1" = "#ca0020", 
                                "s1.2" = "#f4a582", 
                                "s1.3" = "#bababa", 
                                "s1.4" = "#404040")) +
  theme_minimal() +
  labs(title = "",
       x = "",
       y = "Rho Value") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "bottom")

```
See Table \@ref(tab:rho_parameters) for details.

```{r rho_parameters}
kbl(tablebias_combined, 
    booktabs = TRUE, 
    format = "html", 
    caption = "Rho parameter by model and quantity (SSB and F)" ) %>%
  kable_styling(latex_options = "HOLD_position")

```

### Hindcast Cross-Validation and Prediction Skill

The Hindcast Cross-Validation (HCxval) diagnostic in Stock Synthesis is implemented using the model outputs generated by the `r4ss::SS_doRetro()` and using `SSplotHCval()` function. This diagnostic evaluates the predictive performance of the model by comparing hindcast predictions with observed data. To assess prediction skill, we employ the Mean Absolute Scaled Error (MASE) as a robust metric. MASE is calculated by scaling the mean absolute error of the model predictions relative to the mean absolute error of a naïve baseline prediction. Specifically, the MASE score is computed as follows:

- A MASE score greater than 1 indicates that the model’s average forecasts are less accurate than a random walk model.
- A MASE score equal to 1 suggests that the model’s accuracy is similar to that of a random walk.
- A MASE score less than 1 indicates that the model performs better than a random walk.
- A MASE score of 0.5, for example, indicates that the model’s forecasts are twice as accurate as the naive baseline prediction, suggesting the model has predictive skill.


Hindcast validation for `s1.1` (Figure \@ref(fig:hcval1))

```{r hcval1, fig.cap="Hindcast validation for s1.1 by fleet"}
par(mfrow=c(3,3), mar=c(5,4,2,1))
hci1 = SSplotHCxval(retroSummary1.1, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```

Hindcast validation for `s1.2` (Figure \@ref(fig:hcval2))

```{r hcval2, fig.cap="Hindcast validation for s1.2 by fleet"}
par(mfrow=c(3,3), mar=c(5,4,2,1))
hci2 = SSplotHCxval(retroSummary1.2, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```


Hindcast validation for `s1.3` (Figure \@ref(fig:hcval3))

```{r hcval3, fig.cap="Hindcast validation for s1.3 by fleet"}
par(mfrow=c(3,3), mar=c(5,4,2,1))
hci3 = SSplotHCxval(retroSummary1.3, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```

Hindcast validation for `s1.4` (Figure \@ref(fig:hcval4))

```{r hcval4, fig.cap="Hindcast validation for s1.4 by fleet"}
par(mfrow=c(3,3), mar=c(5,4,2,1))
hci4 = SSplotHCxval(retroSummary1.4, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7) 
```


```{r eval=FALSE}
### Kobe (status) dont run
mvln = SSdeltaMVLN(base.model1.1,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)
mvln = SSdeltaMVLN(base.model1.2,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)
mvln = SSdeltaMVLN(base.model1.3,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)
mvln = SSdeltaMVLN(base.model1.4,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)

```

<!-- ### Likelihood Profile  -->

```{r eval=FALSE, echo = FALSE}
# 1. Identificar el directorio donde se encuentra el modelo base ----
dirname.model.run <- here("s1.1")
# 2. Crear un nuevo directorio para el "Perfil_Verosimilitud"  
dirname.R0.profile <- here("s1.1",
                           "Perfil_Verosimilitud")
dir.create(path=dirname.R0.profile, 
           showWarnings = TRUE, 
           recursive = TRUE)
# 3. Crear un subdirectorio llamado "plots_Verosimilitud" ----
plotdir=paste0(dirname.R0.profile, "/plots_Verosimilitud")
dir.create(path=plotdir,
           showWarnings = TRUE, 
           recursive = TRUE)
# 4. Crear un subdirectorio llamado "simple" ----
reference.dir <- paste0(dirname.R0.profile,'/simple') 
dir.create(path=reference.dir, showWarnings = TRUE, recursive = TRUE)
# 5. Copiar el resultado del modelo base completo en este directorio ----
file.copy(Sys.glob(paste(dirname.model.run, "*.*", sep="/"),
                   dirmark = FALSE),
                    reference.dir)
# 6. Leer la salida del modelo base ----
Base <- SS_output(dir=reference.dir,covar=T)
# 7. Copiar los archivos necesarios de "simple" al directorio "Perfil_Verosimilitud" ----
copy_SS_inputs(dir.old = reference.dir, 
               dir.new =  dirname.R0.profile,
               copy_exe = TRUE,
               verbose = FALSE)
# 8. Leer los archivos del modelo ----
inputs <- r4ss::SS_read(dir = dirname.R0.profile)
# 9. Editar el archivo control la fase de estimación recdev ----
inputs$ctl$recdev_phase <- 1
# 10. Editar el archivo starter para leer los valores de inicio ----
inputs$start$init_values_src <- 0
# 11. Vector de valores para el perfil ----
R0.vec <- seq(18,30,1)  
Nprof.R0 <- length(R0.vec)
# 12. Cambiar el nombre del archivo control en el archivo starter.ss ----
inputs$start$ctlfile <- "control_modified.ss" 
# 13. Incluir prior_like para parámetros no estimados ----
inputs$start$prior_like <- 1                                 
# 14. Escribir los modelos modificados ----
r4ss::SS_write(inputs, dir = dirname.R0.profile, overwrite = TRUE)
# 15. Ejecutar la función profile() ----
#?SS_profile()
profile <- profile(dir=dirname.R0.profile, # directory
                      exe="ss_osx",
                      oldctlfile ="control.ss",
                      newctlfile="control_modified.ss",
                      string="SR_LN(R0)",
                      profilevec=R0.vec)
# 16. Leer los archivos de salida ----
# (con nombres como Report1.sso, Report2.sso, etc.)
prof.R0.models <- SSgetoutput(dirvec=dirname.R0.profile, 
                              keyvec=1:Nprof.R0, 
                              getcovar = FALSE) 
# 17. Resumir las salidas con la función SSsummarize()  ----
prof.R0.summary <- SSsummarize(prof.R0.models)
# 18. Identificar los componentes de Verosimilitud ----
mainlike_components         <- c('TOTAL',
                                 "Survey", 
                                 'Length_comp',
                                 "Age_comp",
                                 "Catch",
                                 'Size_at_age',
                                 'Recruitment') 
mainlike_components_labels  <- c('Total likelihood',
                                 'Index likelihood',
                                 'Length likelihood',
                                 "Age likelihood",
                                 "Catch Likelihood",
                                 'Size_at_age likelihood',
                                 'Recruitment likelihood') 
```


```{r eval=FALSE, echo = FALSE}
png(file.path(plotdir,"R0_profile_plot.png"),
    width=7,
    height=4.5,
    res=300,
    units='in')
par(mar=c(5,4,1,1))
SSplotProfile(prof.R0.summary,           # summary object
              profile.string = "R0",     # substring of profile parameter
              profile.label=expression(log(italic(R)[0])), 
              ymax=2050,minfraction = 0.001,
              pheight=4.5, 
              print=FALSE, 
              plotdir=plotdir, 
              components = mainlike_components, 
              component.labels = mainlike_components_labels,
              add_cutoff = TRUE,
              cutoff_prob = 0.95)

Baseval <- round(Base$parameters$Value[grep("R0",Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
```


```{r eval=FALSE}
# Comparación de series de tiempo 
labs <- paste("SR_Ln(R0) = ",R0.vec)
labs[which(round(R0.vec,2)==Baseval)] <- paste("SR_Ln(R0) = ",
                                               Baseval,"(Base model)")

SSplotComparisons(prof.R0.summary,
                  legendlabels=labs,
                  pheight=4.5,png=TRUE,
                  plotdir=plotdir,
                  legendloc='bottomleft')


```


```{r eval = FALSE}
#piner Plot
#### R0_profile_plot_Length_like ----
png(file.path(plotdir,"R0_profile_plot_Length_like.png"),
    width=7,
    height=4.5,
    res=300,
    units='in')
par(mar=c(5,4,1,1))
PinerPlot(prof.R0.summary, 
          profile.string = "R0", 
          component = "Length_like",
          main = "Changes in length-composition likelihoods by fleet",
          add_cutoff = TRUE,
          cutoff_prob = 0.95)
Baseval <- round(Base$parameters$Value[grep("SR_LN",
                                      Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,
     label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
```


```{r eval=FALSE}
#### R0_profile_plot_Survey_like ----
png(file.path(plotdir,"R0_profile_plot_Survey_like.png"),
    width=7,
    height=4.5,
    res=300,
    units='in')
par(mar=c(5,4,1,1))
PinerPlot(prof.R0.summary, 
          profile.string = "R0", 
          component = "Surv_like",
          main = "Changes in Index likelihoods by fleet",
          add_cutoff = TRUE,
          cutoff_prob = 0.95, legendloc="topleft")
Baseval <- round(Base$parameters$Value[grep("SR_LN",
                                            Base$parameters$Label)],2)
Baselab <- paste(Baseval,sep="")
axis(1,at=Baseval,label=Baselab)
abline(v = Baseval, lty=2)
dev.off()
```

### Likelihood tables

```{r eval=FALSE}
like1 <- base.model1.1$likelihoods_used
like1$model <- rep("s1.1", nrow(like1))
like1 <- rownames_to_column(like1, var = "Description")
like2 <- base.model1.2$likelihoods_used
like2$model <- rep("s1.2", nrow(like2))
like2 <- rownames_to_column(like2, var = "Description")
like3 <- base.model1.3$likelihoods_used
like3$model <- rep("s1.3", nrow(like3))
like3 <- rownames_to_column(like3, var = "Description")
like4 <- base.model1.4$likelihoods_used
like4$model <- rep("s1.4", nrow(like4))
like4 <- rownames_to_column(like4, var = "Description")

totalike <- rbind(like1,
                   like2,
                   like3,
                   like4)

ggplot(totalike %>% 
         filter(values>1))+
  geom_bar( aes(y = reorder(Description, values), 
                x =log(values)),
            stat = "identity", position = "dodge") +
  theme_few() +
  facet_wrap(.~model, 
             ncol=4)+
  labs(y="",
       x="Log Likelihood")+
  theme(axis.text.x = element_text(angle = 90, 
                                   hjust = 1))+
  xlim(0,30)
```



```{r}
# Modelo s1.1
diag1.1 <- data.frame(
  Scenario = "s1.1",
  Convergency = base.model1.1$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model1.1$N_estimated_parameters)[1] + 2 * base.model1.1$likelihoods_used[1, 1]),
  Total_like = base.model1.1$likelihoods_used$values[rownames(base.model1.1$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model1.1$N_estimated_parameters[1]),
  Survey_like = base.model1.1$likelihoods_used$values[rownames(base.model1.1$likelihoods_used) == "Survey"],
  Length_comp_like = base.model1.1$likelihoods_used$values[rownames(base.model1.1$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse1c$RMSE.perc[rmse1c$indices == "Combined"],
  RMSE_length = rmse1l$RMSE.perc[rmse1l$indices == "Combined"],
  MASE = mean(hci1$MAE.base, na.rm = TRUE),
  Retro_Rho_ssb = tablebias01[5, 3],
  Forecast_Rho_ssb = tablebias01[5, 4],
  Forecast_Rho_f = tablebias01a[5, 3],
  Rho_f = tablebias01a[5, 4]
)

# Modelo s1.2
diag1.2 <- data.frame(
  Scenario = "s1.2",
  Convergency = base.model1.2$maximum_gradient_component,
  AIC = (2 * (base.model1.2$N_estimated_parameters)[1] + 2 * base.model1.2$likelihoods_used[1, 1]),
  Total_like = base.model1.2$likelihoods_used$values[rownames(base.model1.2$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model1.2$N_estimated_parameters[1]),
  Survey_like = base.model1.2$likelihoods_used$values[rownames(base.model1.2$likelihoods_used) == "Survey"],
  Length_comp_like = base.model1.2$likelihoods_used$values[rownames(base.model1.2$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse2c$RMSE.perc[rmse2c$indices == "Combined"],
  RMSE_length = rmse2l$RMSE.perc[rmse2l$indices == "Combined"],
  MASE = mean(hci2$MAE.base, na.rm = TRUE),
  Retro_Rho_ssb = tablebias2[5, 3],
  Forecast_Rho_ssb = tablebias2[5, 4],
  Forecast_Rho_f = tablebias2a[5, 3],
  Rho_f = tablebias2a[5, 4]
)

# Modelo s1.3
diag1.3 <- data.frame(
  Scenario = "s1.3",
  Convergency = base.model1.3$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model1.3$N_estimated_parameters)[1] + 2 * base.model1.3$likelihoods_used[1, 1]),
  Total_like = base.model1.3$likelihoods_used$values[rownames(base.model1.3$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model1.3$N_estimated_parameters[1]),
  Survey_like = base.model1.3$likelihoods_used$values[rownames(base.model1.3$likelihoods_used) == "Survey"],
  Length_comp_like = base.model1.3$likelihoods_used$values[rownames(base.model1.3$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse3c$RMSE.perc[rmse3c$indices == "Combined"],
  RMSE_length = rmse3l$RMSE.perc[rmse3l$indices == "Combined"],
  MASE = mean(hci3$MAE.base, na.rm = TRUE),
  Retro_Rho_ssb = tablebias3[5, 3],
  Forecast_Rho_ssb = tablebias3[5, 4],
  Forecast_Rho_f = tablebias3a[5, 3],
  Rho_f = tablebias3a[5, 4]
)

# Modelo s1.4
diag1.4 <- data.frame(
  Scenario = "s1.4",
  Convergency = base.model1.4$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model1.4$N_estimated_parameters)[1] + 
                     2 * base.model1.4$likelihoods_used[1, 1]),
  Total_like = base.model1.4$likelihoods_used$values[rownames(base.model1.4$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model1.4$N_estimated_parameters[1]),
  Survey_like = base.model1.4$likelihoods_used$values[rownames(base.model1.4$likelihoods_used) == "Survey"],
  Length_comp_like = base.model1.4$likelihoods_used$values[rownames(base.model1.4$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse4c$RMSE.perc[rmse4c$indices == "Combined"],
  RMSE_length = rmse4l$RMSE.perc[rmse4l$indices == "Combined"],
  MASE = mean(hci4$MAE.base, na.rm = TRUE),
  Retro_Rho_ssb = tablebias4[5, 3],
  Forecast_Rho_ssb = tablebias4[5, 4],
  Forecast_Rho_f = tablebias4a[5, 3],
  Rho_f = tablebias4a[5, 4]
)


diag_all <- rbind(diag1.1,
                  diag1.2, 
                  diag1.3, 
                  diag1.4)


diag_tidy <- diag_all |>
  pivot_longer(cols = -Scenario, names_to = "Description", values_to = "Value") |>
  pivot_wider(names_from = Scenario, values_from = Value)

diag_tidy[, 2:5] <- lapply(diag_tidy[, 2:5], function(x) as.numeric(format(round(x, 3), nsmall = 3)))
```

See Table \@ref(tab:likecom) for details. 

```{r likecom}
diag_tidy %>%
  kbl(digits = 3, 
      caption = "Model Diagnosis Results",
      align = "c",  # Centrar todas las columnas
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE,
                position = "center") %>%
  row_spec(0, bold = TRUE)  # Encabezados en negrita
```

As shown in Table \@ref(tab:parameter-comparison), the models differ substantially in key parameter estimates and likelihood contributions.


```{r parameter-comparison, warning=FALSE, message=FALSE}
#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL,
                       dirvec = c(dir1.1,
                                  dir1.2,
                                  dir1.3,
                                  dir1.4),
                       getcovar = F)
summaryoutputall <- SSsummarize(biglist)

legend.labels <- c('s1.1','s1.2','s1.3', 's1.4')

#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL, dirvec = c(dir1.1,
                                                 dir1.2,
                                                 dir1.3,
                                                 dir1.4),	getcovar = F)

#create summary of model runs from list above
summaryoutput <- SSsummarize(biglist)

# Crear tabla con SStableComparisons
tablelike <- SStableComparisons(
  summaryoutput,
  likenames = c("TOTAL", "Survey", "Length_comp", "Age_comp", "priors", "Size_at_age"), 
  names = c("Recr_Virgin", "R0", "SSB_Virg", "Bratio_2020", "SPRratio_2020"),
  digits = NULL,
  modelnames = legend.labels,
  csv = TRUE,
  csvdir = "/Users/mauriciomardones/DOCAS/SA_Krill",
  csvfile = "parameter_comparison_table.csv",
  verbose = TRUE,
  mcmc = FALSE
)

# Limpiar la tabla: eliminar columnas o filas con solo NAs y evitar notación científica
table_clean <- tablelike %>%
  mutate(across(where(is.numeric), ~ format(.x, scientific = FALSE, digits = 4))) %>%
  select(where(~ !all(is.na(.))))  # elimina columnas que son completamente NA

# Renderizar con kable
kbl(table_clean, booktabs = TRUE, format = "html", 
    caption = "Model parameter and likelihood comparison") %>%
  kable_styling(latex_options = "scale_down")

```

Total likelihood in Figure \@ref(fig:likecompo2)

```{r likecompo2, fig.width=7, fig.height=3, fig.cap="total likelihood composition by scenario"}
df1 <- base.model1.1$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model1.1$likelihoods_used), Modelo = "s1.1")
df2 <- base.model1.2$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model1.2$likelihoods_used), Modelo = "s1.2")
df3 <- base.model1.3$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model1.3$likelihoods_used), Modelo = "s1.3")
df4 <- base.model1.4$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model1.4$likelihoods_used), Modelo = "s1.4")

df <- bind_rows(df1, 
                df2,
                df3,
                df4)
ggplot(df %>% 
         filter(values > 1), aes(x = Componente, y = values, fill = Modelo)) +
  geom_col(position = position_dodge(), width = 0.7) +  
  theme_few() +
  coord_flip() +  
  scale_fill_manual(name= "Scenario",
                    values = c("s1.1" = '#ca0020',
                               "s1.2" = '#f4a582', 
                               "s1.3" = '#bababa',
                               "s1.4" = '#404040')) + 
  labs(x = "",
       y = "Log-Normal Likelihood", 
       title = "") 
```

This bar plot presents the log-normal likelihood contributions of different model components in an Antarctic krill stock assessment under four scenarios (s1.1, s1.2, s1.3, and s1.4).  

**TOTAL Likelihood:** The overall likelihood is highest for scenario s1.4 (black), followed by s1.2 (light orange). This suggests that s1.4 provides the best overall model fit, while s1.1 (dark red) has the lowest likelihood, indicating a poorer fit.  

**Survey Component:** The survey likelihood follows a similar pattern, with s1.4 and s1.2 showing better agreement with the data compared to s1.1.  

**Recruitment, Parameter Priors, and Parameter Deviations:** These components contribute minimally to the total likelihood, indicating that they do not heavily influence model fit differences.  

**Length Composition:** There is some variation in this component, with s1.2 showing a larger contribution than s1.1 and s1.3.  

Scenario s1.4 seems to fit the data best, followed closely by s1.2. Scenario s1.1 has the poorest likelihood, meaning it is the least supported by the data. If s1.4 includes both environmental and predator effects, this suggests that incorporating ecosystem variables significantly improves the stock assessment model for Antarctic krill.


### Statistics analisys differences bewteen models

To evaluate the residual behavior across model scenarios, we computed residuals as the difference between observed and expected values (`residual = Obs - Exp`). Basic statistics, including sample size (`n()`), mean (`mean()`), and standard deviation (`sd()`), were calculated for each combination of model and type. To test the normality of residuals, we applied the Shapiro-Wilk test (`shapiro.test()`) [@shapiro1965analysis], which is appropriate for small to moderate sample sizes. Temporal autocorrelation was assessed using the Ljung-Box test (`Box.test()` [@ljung1978measure] with `type = "Ljung-Box"` and `lag = 10`), evaluating the null hypothesis of independence across lags. To detect heteroscedasticity, we used the Breusch-Pagan test (`bptest()` from the `lmtest` package) [@breusch1979simple], fitting a linear model of residuals against year (`residual ~ Yr`) and testing for non-constant variance in the residuals. These diagnostics provide insight into the validity of model assumptions across different scenarios.


```{r message=FALSE, warning=FALSE}
resid_all <- resid_all %>%
  mutate(residual = Obs - Exp)

# Estadísticas básicas
resid_stats <- resid_all %>%
  group_by(type, model) %>%
  summarise(
    N = n(),
    Mean = mean(residual, na.rm = TRUE),
    SD = sd(residual, na.rm = TRUE),
    .groups = "drop"
  )

# Shapiro-Wilk (normalidad)
shapiro_p <- resid_all %>%
  group_by(type, model) %>%
  summarise(
    shapiro_p = ifelse(n() > 3, shapiro.test(residual)$p.value, NA),
    .groups = "drop"
  )

# Ljung-Box (autocorrelación temporal)
ljung_p <- resid_all %>%
  group_by(type, model) %>%
  summarise(
    ljung_p = ifelse(n() > 10, Box.test(residual, lag = 10, type = "Ljung-Box")$p.value, NA),
    .groups = "drop"
  )

# Breusch-Pagan (heterocedasticidad)
bp_p <- resid_all %>%
  group_by(type, model) %>%
  summarise(
    bp_p = ifelse(n() > 3, bptest(lm(residual ~ Yr, data = cur_data()))$p.value, NA),
    .groups = "drop"
  )

```

As shown in Table \@ref(tab:residual-summary), the residuals exhibit different statistical properties across model scenarios.


```{r residual-summary, message=FALSE, warning=FALSE}
tabla_resumen <- resid_stats %>%
  left_join(shapiro_p, by = c("type", "model")) %>%
  left_join(ljung_p, by = c("type", "model")) %>%
  left_join(bp_p, by = c("type", "model")) %>%
  mutate(across(where(is.numeric), ~ round(.x, 5)))

tabla_resumen %>%
  kbl(caption = "Summary statistics and residual diagnostic tests by type and model",
      digits = 5,  # Redondeo a 5 decimales
      align = "c",  # Centrado
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE,
                position = "center",
                latex_options = "HOLD_position") %>%
  row_spec(0, bold = TRUE) %>%  # Encabezados en negrita
  column_spec(1, bold = TRUE)   # Primera columna en negrita (opcional)
```

The residual analysis shows distinct patterns between the Index and Length-based models across all four scenarios (`s1.1` to `s1.4`). For Index models, the mean residuals are notably large (ranging from approximately 105,610 to 143,409), with high standard deviations exceeding 1 million units, indicating substantial variability. The Shapiro-Wilk test consistently returned p-values of 0, strongly rejecting the null hypothesis of normality. The Ljung-Box test yielded very low p-values (≤ 0.00080), suggesting significant temporal autocorrelation in the residuals. In terms of heteroscedasticity, the Breusch-Pagan test showed moderate evidence of non-constant variance, with p-values ranging from 0.27150 (s1.1) to 0.01052 (s1.3), the latter indicating strong evidence of heteroscedasticity.

In contrast, Length models present mean residuals near zero with low standard deviations (approximately 0.038–0.047), suggesting good overall model fit and low dispersion. However, despite the small residual magnitude, the Shapiro-Wilk and Ljung-Box tests consistently return p-values of 0, indicating violation of normality and presence of temporal autocorrelation. Furthermore, the Breusch-Pagan test returned extremely low p-values (≤ 0.00067), indicating strong evidence of heteroscedasticity across all Length-based scenarios.

These results suggest that while Length models achieve better central tendencies (mean near zero and low variance), they still suffer from violations of key assumptions—most notably autocorrelation and heteroscedasticity. Index models, on the other hand, display large-scale variability and systematic residual patterns that may require model refinement or transformation.

Another statistical analysis;

```{r}
# Extraer los datos
spawn_bio_1 <- base.model1.1$timeseries$SpawnBio
spawn_bio_4 <- base.model1.4$timeseries$SpawnBio

# Prueba de normalidad (Shapiro-Wilk)
shapiro.test(spawn_bio_1)
shapiro.test(spawn_bio_4)

# Prueba de igualdad de varianzas (Levene)
leveneTest(c(spawn_bio_1, spawn_bio_4), 
           group = rep(c("Model 1.1", "Model 1.4"), each = length(spawn_bio_1)))

# Prueba t de Student (si los datos son normales)
t.test(spawn_bio_1, spawn_bio_4, var.equal = TRUE)

# Prueba de Wilcoxon (si los datos no son normales)
wilcox.test(spawn_bio_1, spawn_bio_4)

```


**Two-Sample t-Test**  

- **t-value:** 4.2682  
- **Degrees of Freedom (df):** 72  
- **p-value:** 5.915e-05 (very small)  
- **95% Confidence Interval for the Mean Difference:** [1,387,011; 3,818,074]  
- **Sample Means:**  
  - Model 1.1: **4,600,304**  
  - Model 1.4: **1,997,762**  

Since the **p-value (5.915e-05) is much smaller than 0.05**, we reject the null hypothesis. This means there is **a statistically significant difference** between the spawning biomass predicted by Model 1.1 and Model 1.4. The confidence interval suggests that Model 1.1 tends to estimate a higher spawning biomass than Model 1.4, with an estimated difference between **1.39 and 3.82 million tons**.  

**Wilcoxon Rank Sum Test (Mann-Whitney U Test)**  

- **W-statistic:** 1256  
- **p-value:** 6.698e-10 (extremely small)  
- **Warning:** "Cannot compute exact p-value with ties" (indicates that some values are repeated)  

The **Wilcoxon test also rejects the null hypothesis** with an extremely small **p-value (6.698e-10)**. This confirms that the distribution of spawning biomass values is significantly different between the two models. Since the Wilcoxon test does not assume normality, it supports the conclusion from the **t-test**, reinforcing that 

Both tests strongly indicate that **Model 1.1 and Model 1.4 produce significantly different estimates of spawning biomass**. Specifically, **Model 1.1 predicts higher values**. This suggests that the factors or assumptions included in Model 1.4 result in **lower spawning biomass estimates**, which could have important implications for stock assessment and fisheries management.


\pagebreak

# References

