---
title: "![](IEO-logo2.png){width=10cm}"
output:
  bookdown::pdf_document2:
    includes:
      before_body: titulo.sty
    keep_tex: yes
    number_sections: no
    toc: true
    toc_depth: 3
bibliography: Donax.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
indent: no
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \lfoot[\thepage]{}
- \rfoot[]{\thepage}
- \fontsize{12}{22}
- \selectfont
---

\pagebreak


# 1. CONTEXTO

El objetivo de este documento es la implementación metodológica de la evaluación de stock de coquina *Donax trunculus* mediante un modelo integrado con datos en talla y dinamica en edad implemetnado en Stock Synthesis (SS3) (v.3.30.21) [@Methot2013; @Methot2023] para la zona del Golfo de Cádiz, España. Este trabajo está en el marco de la asesoría científica que lleva a cabo el Instituto Español de Oceanografía (IEO) realizado por el grupo de investigadores asociados al proyecto FEMP 04.

A su vez, se destaca la utilidad de los programas de monitoreo de la población y la pesquería que se ejecutan desde el año 2013 por parte del IEO Cádiz, y con el cual se ha levantado informacion biológica, pesquera y ambiental que ha sido vital para estea implementación metodológica, consitituyendo así el primer ejercicio de evaluación de stock de coquina.


# 2. METODOLOGÍA

El flujo de trabajo asociado a la modelación de stock, tanto componentes como fuentes de datos está representado de forma genérica en el siguiente diagrama de flujo (Figura \ref{fig:esq});


```{r esq, echo=FALSE, out.width = "100%", fig.align='center', fig.cap="\\label{fig:esq}Esquema de modelación de coquina"}
knitr::include_graphics("FIg/Diagrama_Modelo.png")
```

```{r setup1, echo=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.pos = "H",
                      dev = 'jpeg',
                      dpi = 300)
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```

```{r lib, eval=TRUE, message=FALSE,  include=FALSE, echo=FALSE, warning=FALSE}
# install.packages("devtools")
# install.packages("caTools")
# library("caTools")
# # install.packages("r4ss")
paquetes <- c("stringr", 
              "tidyverse", 
              "kableExtra","ggplot2",
              "ggthemes",
               "patchwork",
              "dplyr","reshape","here","r4ss",
              "zoo","ss3diags","pdftools",
              "forcats","ggpubr")
lapply(paquetes, require, character.only = TRUE)
```


```{r echo=FALSE}
dir01<-here("s01")# Modelo solo con 
dir1<-here("s1")# test 1
dir2<-here("s2") # test2 
dir3<-here("s3") # 
dir4<-here("s4") # 
dir5<-here("s5") # 
fig_path<-here("Fig")
```



```{r eval=FALSE, message=F, include=FALSE}
# Lista de directorios para correro tordos juntos
directorios <- c("s01", 
                 "s1", 
                 "s2",
                 "s3",
                 "s4",
                 "s5")  # Agrega aquí todos los nombres de las carpetas que deseas procesar

# Bucle para ejecutar el código en cada directorio
for (dir in directorios) {
  r4ss::run(
    dir = dir,
    exe = "ss_osx",
    skipfinished = FALSE,
    show_in_console = TRUE
  )
}
# Considerar que al correr el modelo dentro de cada `chunk` se cambia el directorio.
```

```{r eval= F, message=FALSE, warning=FALSE, include=FALSE}
# Corro escenario por separado 
r4ss::run(
  dir = dir1,
  exe = "ss_osx",
  skipfinished = FALSE, # TRUE will skip running if Report.sso present
  show_in_console = TRUE # change to true to watch the output go past
)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#Leo las salidas del modelo seleccionado. 

#dir1<-here("s1")
base.model1 <- SS_output(dir=dir1,
                         covar=T,
                         forecast=T)
#dir2<-here("s2")
base.model2 <- SS_output(dir=dir2,
                         covar=T,
                         forecast=T)
#dir3<-here("s3")
base.model3 <- SS_output(dir=dir3,
                         covar=T,
                         forecast=T)
#dir1<-here("s4")
base.model4 <- SS_output(dir=dir4,
                         covar=T,
                         forecast=T)
#dir1<-here("s5")
base.model5 <- SS_output(dir=dir5,
                         covar=T,
                         forecast=T)

```


```{r eval= F, message=FALSE, warning=FALSE, include=FALSE}
SS_plots(base.model1,
         uncertainty=T,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.40,
         minbthresh=0.20, 
         forecast=T)

```


```{r eval= F, message=FALSE, warning=FALSE, include=FALSE}
#Leo las salidas del modelo seleccionado. 

dir5<-here("s5")
base.model5 <- SS_output(dir=dir5,
                         covar=T,
                         forecast=T)

SS_plots(base.model5,
         uncertainty=T,
         datplot = T, 
         png=T, 
         aalresids = F,
         btarg=0.40,
         minbthresh=0.20, 
         forecast=T)

```

```{r}
# leo archivos para plotear y hacer tablas
start1 <- SS_readstarter(file = file.path(dir1,
                                               "starter.ss"),
                              verbose = FALSE)
# note the data and control file names can vary, so are determined from the 
# starter file.
dat1 <- SS_readdat(file = file.path(dir1, start1$datfile),
                        verbose = FALSE)
# Read in ctl file. Note that the data fileR object is needed so that SS_readctl
# assumes the correct data structure
ctl1 <-  r4ss::SS_readctl(file = file.path(dir1,
                                    start1$ctlfil),
                        verbose = FALSE,
                        use_datlist = TRUE, 
                   datlist = dat1)
fore1 <- r4ss::SS_readforecast(file = file.path(dir1, 
                                                "forecast.ss"),
                              verbose = FALSE)
# can also read in wtatage.ss for an empirical wt at age model using
# r4ss::SS_readwtatage()
```



\pagebreak

## 2.1. Datos utilizados

Los datos analizados que formaron parte de los inputs del modelo fueron clasificados de acuerdo a su origen. A saber;

a.  Desembarque  artesanal del período (2004-2024), provenientes de las estadisticas oficiales de [IDAPES](https://www.juntadeandalucia.es/agriculturaypesca/idapes/servlet/FrontController) asociados al sector de marisquería del Parque Doñana y cercanías. Cabe señalar que en esta pesquería aun no se realizan procesos de corrección de desembarques y que serán propuestos como escenarios de modelación.


b.  Información de los programas de monitoreo poblacional y comercial que lleva a cabo el IEO desee el año 2013. En este monitoreo se recopila información biológica, pesquera y ambiental. 

c . Información relativa a los parámetros de historia de vida de la coquina a nivel europeo y local. Esta información está contenida en artículos científicos y reportes que fueron compilados con el fin de parametrizar los modelos de evaluación.

Toda esta información, codigos fuente, bases de datos y Analisis Exploratorio de Datos puede ser encontrado en el siguiente enlace: [Data coquina](https://mauromardones.github.io/EDA_Donux_trunculus_2023/). La cobertura temporal de las fuentes de datos varia de acuerdo a la disponibilidad asociada al programa y fuente (Figura \ref{fig:data});



```{r data, echo=FALSE, out.width = "80%", fig.align='center', fig.cap="\\label{fig:data}Cobertura temporal de las distintas fuentes de datos usadas en el modelo implementado en SS3 para coquina"}
knitr::include_graphics("s1/plots/data_plot.png")
```

## 2.2. Modelo de la dinámica poblacional

El modelo de dinámica poblacional de la coquina, corresponde a un enfoque de evaluación del tipo estadístico con estructura de edad, donde la dinámica progresa avanzando en el tiempo t, y las capturas son causantes de la mortalidad por pesca F, la mortalidad natural es constante `M = 0.99` (Tabla \ref{Tab1}). La relación entre la población y las capturas responde a la base de la ecuación de Baranov, y se consideran para el modelo y estimaciones el rango de edad entre 1 a 5+ (años). Sin embargo, las estimaciones del modelo tienen su origen en la edad cero sobre la base de una condición inicial estado estable. La dinámica esta modelada por un reclutamiento tipo Beverton y Holt.


De manera sencilla, un modelo de evaluación reproduce la dinámica poblacional de coquina a lo largo del tiempo. Este modelo incorpora parámetros biológicos clave como tasas de crecimiento, tasas de mortalidad, reclutamiento y biomasa desovante. Normalmente, el modelo se formula utilizando ecuaciones matemáticas que describen cómo estos parámetros interactúan para determinar la abundancia y distribución de coquina en el área de estudio. La ecuación de estado de creciiento poblacional de coquina puede representarse como:

\[
N_t = N_{t-1} \cdot e^{(r - M)} + R
\]

Donde:
- \(N_t\) es abundancia de coquina en el tiempo \(t\).
- \(N_{t-1}\) abundancia de krill en pasos de tiempo previos.
- \(r\) es la tasa de crecimiento poblacional intrinseca.
- \(M\) es la tasa de mortalidad natural.
- \(R\) es el reclutamiento de nuevos individuos al stock.



## 2.3. Plataforma de Evaluacion de Stock 

La ecuación descrita en el punto `2.2` describe la dinámica básica de la población de coquina, con la abundancia cambiando con el tiempo debido al crecimiento, la mortalidad y el reclutamiento. Junto a esta ecuación, otros submodelos asociados como crecimiento individual, selectividad, madurez, captura a la edad entre otros estan configurados en SS3. Este plataforma de evaluación de stock está diseñada como un modelo estructurado con dinámica en edad y datos en talla, en la clase de modelo denominado *Modelo de análisis integrado*. SS3 tiene un sub-modelo poblacional de stock que simula crecimiento, madurez, fecundidad, reclutamiento, movimiento, y procesos de mortalidad, y sub-modelos de observation y valores esperados para diferentes tipos de datos. El modelo es codificado en C++ con parámetros de estimación activados por diferenciación automática (ADMB) [@Methot2013]. El análisis de resultados y salidas emplea herramientas de R e interfase gráfica de la librería `r4ss` (<https://github.com/r4ss/r4ss>) [@Taylor2019] y `ss3diags`  [@Henning2023].


Las rutinas y datos de este proceso metodologico de evaluaciónpueden ser encontrados en el repositorio de [SA_Donax_trunculus](https://github.com/MauroMardones/SA_Donax_trunculus)

## 2.4. Modelo Base (Condicionamiento)

La estimación de la biomasa desovante se realizó a inicios de año, mientras que el reclutamiento se consideró como un evento doble que ocurre hacia junio y fines de año.  En el proceso de estimación del reclutamiento, se incorporó una relación stock-recluta difusa (steepness 0.7), y las variaciones en el reclutamiento se modelaron como desviaciones del reclutamiento virginal `R0`, asumiendo 2004 como año inicial (Tabla \ref{Tab1}).

La mortalidad por pesca se estimó como el promedio simple de la `F` de las clases de edad 1 y 2, lo que en el modelo corresponde a la opción 5 del método `F híbrido` recomendado en SS3 [@Methot2013]. Se asume que la densidad es un proxi de las biomasas estimadas [@Caddy2004] obtenida desde los muestreos poblacionales y que son proporcionales a la biomasa vulnerable de la población, con la capturabilidad (`q`) estimada en el modelo. Los parámetros `q` fueron estimados a patir de parámetros iniciales especificados en la Tabla \ref{Tab1} para los datos del monitoreo poblacional , así como del comercial. Todos los patrones de selectividad, que relacionan las composiciones de tallas observadas de la flota comercial y poblacional con la dinámica, fueron estimados mediante una función logística. Los parámetros `p1` (talla en la inflexión de la curva) y `p2` (selección al 95%) son estimados por el modelo a partir de los valores iniciales especificados en la Tabla \ref{Tab1}.


```{r}
 parbio<-ctl1$MG_parms[1:10,c(1:3,7)]
 row.names( parbio)<-c("Nat M",
                       "Lmin", 
                       "Lmax",
                       "VonBert K",
                       "CV young",
                       "CV old", 
                       "Wt a", 
                       "Wt b",
                       "L50%", 
                       "Mat slope")

 SRpar<-ctl1$SR_parms[1:5,c(1:3,7)]
 Qpar<-ctl1$Q_parms[1:2,c(1:3,7)]
 Selpar<-ctl1$size_selex_parms[1:4,c(1:3,7)]
 parInit<-rbind(parbio,SRpar,Qpar,Selpar)

parInit %>%
  kbl(booktabs = T,
      format = "latex",
      position="ht!",
      align="c",
    caption = "\\label{Tab1}Parámetros de entrada al modelo inicial SS3 de coquina (S1). Cada línea de parámetro contiene un valor mínimo (LO), máximo (HI) e inicial (INIT). Si la fase (PHASE) para el parámetro es negativa, el parámetro es fijo de entrada") %>%
  kable_paper("hover", 
              full_width = F)%>%
  kable_styling(latex_options = c("striped",
                                  "condensed"),
                full_width = FALSE,
                font_size=9)%>% 
  pack_rows(index = c("Mortalidad natural" = 1,
                        "Crecimiento"= 5,
                        "Relación longitud-peso" = 2,
                        "Ojiva de madurez"=2,
                        "Relación stock-recluta"=5,
                        "Capturabilidad"=2,
                        "Selectividad"=4))

```

Respecto a los valores y parametros biologicos modelados, los siguientes graficos (Figura \ref{fig:bio}) identifican los estimadores puntuales del recurso

```{r bio, echo=FALSE, out.width = "80%",  fig.cap="\\label{fig:bio}Función de crecimiento asumida en el modelo. El área sombreada indica una distribución del 95% de la talla por edad alrededor de la curva de crecimiento estimada y Ojiva de madurez por talla para coquina"}
SSplotBiology(base.model1,  
              subplot=c(1, 6))
```


Por otro lado, y al existir dos tipos de muestreos, uno poblacional y otro comercial, se modelan las selectividades por separado como se identifica en la Figura \ref{fig:sel}

```{r sel, echo=FALSE, out.width = "80%",  fig.cap="\\label{fig:sel}selectivity at length in end year for all fleets shown together para coquina"}
SSplotSelex(base.model1, 
            subplots = 1)
```
## 2.5. Modelos alternativos (Escenarios)

Para avanzar en la implementación metodológica, y considerando las fuentes de incertidumbre asociadas a la modelación de stock de coquina, se establecen una serie de modelos alternativo. Estos escenarios dicen relación con el subreporte de este tipo de pesquerias (Galicia paper ref) en particular, con la coquina (ref). Esto dado los niveles de furtivismo que no son reflejados en las cifras oficiales. Por ello, este ejercicio contempló una corrección al alza de los desembarques oficiales provistos por la Junta a traves de IDEASPA. Esto tiene como objetivo identificar el impacto del subreporte en la estimación de variables poblacionales, así como en el status del recurso.  Estos escenarios estan descritos en la Tabla \ref{Tab2}.


```{r}
esc<-c("S01","S1","S2","S3","S4","S5")

descripcion<-c("Solo Desembarque e Índice",
               "Flota comercial y poblacional, Desembarque, Índice, Composiciones de Tallas",
               "S1 + Vector Desembarques desde 1990 asumido en 250 por año",
               "S1 + Vector desembarques ponderado por 1.5",
               "S1 + Vector desembarques ponderado por 2",
               "S1 + Vector desembarques ponderado por 2.5")

ESC1<-cbind(esc,descripcion)

ESC1 %>% kbl(booktabs = T,
             format = "latex",
             position="h!",
             align="l",
        col.names = linebreak(c('Escenarios',
                                "Descripción"),
                              align="c"),
        caption = "\\label{Tab2}Descripción de los escenarios alternativos al modelo base inicial (S1).") %>%
  kable_paper("hover", 
              full_width = F) %>% 
    kable_styling(latex_options = c("striped", 
                                    "condensed"),
                  full_width = FALSE,
                  font_size=10)
```

\pagebreak

# 3. RESULTADOS (Modelo Base `s1`)

## 3.1 Ajustes y residuos

En relación a los análisis de bondad de ajuste más clásicos, los ajustes a las tallas muestran un adecuado desempeño, siguiento las modas anuales de la estructura de tallas poblacional (Figura \ref{fig:fitpob}) y comercial (Figura \ref{fig:fitcom}).


```{r fitpob, echo=FALSE, out.width = "80%", fig.align='center', fig.cap="\\label{fig:fitpob}Fits Length comps, whole catch, POBLACIONAL para coquina"}
knitr::include_graphics("s1/plots/comp_lenfit_flt2mkt0.png")
```


```{r fitcom, echo=FALSE, out.width = "80%", fig.align='center', fig.cap="\\label{fig:fitcom}Fits Length comps, whole catch, COMERCIAL para coquina"}
knitr::include_graphics("s1/plots/comp_lenfit_flt1mkt0.png")
```



\pagebreak

## 3.2.  Variables poblacionales


```{r message=FALSE, include=FALSE}
replist <- SS_output(dir=dir1,verbose=TRUE,printstats=TRUE)
summary <- read.table(here(dir1,
                           "ss_summary.sso"),
                      header=F,sep="",
                      na="NA",fill=T) 

#Saco los vectores requeridos. Pueden ser otros pero esto son los principales
years<-seq(2004,2023,1)
ssb<-replist$derived_quants[3:22,1:3]
recr<-replist$derived_quants[30:49,1:3]
ft<-replist$derived_quants[79:98,1:3]
catch<-summary[281:300,2]
data<-data.frame(yrs=years,
                 Rt=round(as.numeric(recr$Value),2),
                 BD=round(as.numeric(ssb$Value),2),
                 Catch=round(as.numeric(catch),2),
                 Ft=round(as.numeric(ft$Value),2))
```


```{r}
data%>% 
kbl(booktabs = T,format = "latex",position="ht!",align="c",escape = FALSE,
        col.names = linebreak(c('Año',
                                "Reclutamientos",
                                "Biomasa\ndesovante",
                                "Captura",
                                "Mortalidad\npor pesca"),
                              align="c"),
    caption = "\\label{Tab4}Series de tiempo estimados por el modelo inicial (S1). Reclutamiento (millones de ind.),  biomasa desovante (en toneladas), Captura (t) y mortalidad por pesca (año-1).") %>%
  kable_paper("hover", 
              full_width = F)%>%
  kable_styling(latex_options = c("striped",
                                  "condensed"),
                full_width = FALSE,
                font_size=9)

```

Los componentes de verosimilitud, además de los análisis de residuales permiten identificar entre los bloques de modelos cuales de las configuraciones presenta un desempeño adecuado en términos estadísticos de ajuste a la información.  Este modelo es el seleccionado como caso base y sirve para desplegar sus principales salidas para fines informativos de indicadores; como biomasa desovante y pronóstico y biomasa desovante relativa (Figura \ref{fig:ssb}).

```{r ssb, echo=FALSE, out.width="80%", fig.cap="\\label{fig:ssb}Spawning output with forecast with ~95% asymptotic intervals and relative spawining biomass to coquina"}
SSplotTimeseries(base.model1,
                 subplot = 7)
SSplotTimeseries(base.model1,
                 subplot = 9)

```



## 3.3. Análisis Retrospectivo

Se siguieron los procedimientos explicados en el objetivo 1 de este reporte, para evaluar la idoneidad
del modelo y dichos procedimientos se han probado en 6 implementaciones (escenarios) diferentes del
modelo inicial (S1). 

```{r eval=F}
# corro po r separado para no tener todo el rato el compu corriendo
#do retrospective model runs
retro(dir=dir5, 
      oldsubdir="", 
      newsubdir="Retrospective", 
      years= 0:-5,
      exe="ss_osx",
      extras = "-nox", 
      skipfinished = F)

```


```{r echo=FALSE, message=FALSE, warning=FALSE}
#s01
# retroModels01 <- SSgetoutput(dirvec=file.path(dir01,
#                                             "Retrospective",
#                                             paste("retro",0:-5,
#                                                   sep="")))

#retroSummary01 <- SSsummarize(retroModels01)
# s1
retroModels1 <- SSgetoutput(dirvec=file.path(dir1,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary1 <- SSsummarize(retroModels1)
#s2
retroModels2 <- SSgetoutput(dirvec=file.path(dir2,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary2 <- SSsummarize(retroModels2)
#s3
retroModels3 <- SSgetoutput(dirvec=file.path(dir3,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary3 <- SSsummarize(retroModels3)
#s4
retroModels4 <- SSgetoutput(dirvec=file.path(dir4,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary4 <- SSsummarize(retroModels4)
#s5
retroModels5 <- SSgetoutput(dirvec=file.path(dir5,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary5 <- SSsummarize(retroModels5)
```

Dado que la variabilidad del índice rho de Mohn depende de la historia de vida (usualmente
mayor para especies de vida corta) y que el estadístico parece insensible a F, @Hurtado2014
propusieron que el patrón retrospectivo de alguna de las variables biológico-pesqueras indicadas es
preocupante si los valores del índice Mohn’s rho son superiores a 0,20 o inferiores a -0,15 para especies
de vida larga, o superiores a 0,30 o inferiores a -0,22 para especies de vida corta. Esto es un factor relevante al momento de hacer diagnosis con recursos como la coquina. Los resultados de el análisis de sesgo para cada escenario son represetados por el parámetro de Rho en la Figura \ref{fig:retro}.
```{r retro ,echo=FALSE, message=FALSE, warning=FALSE, fig.keep='all', fig.show="hold", fig.cap="\\label{fig:retro}Patrón restrospectivo para cada esnario modelado en coquina"}
#save(retroSummary, retroModels, file="retro5.Rdata")

# retro01 <- SSplotRetro(retroSummary01,
#             add=T,
#             forecast = F,
#             legend = T,
#             verbose=F)
par(mfrow=c(3,2), mar=c(1.5,5,3,2) + 0.1)
retro1 <- SSplotRetro(retroSummary1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE,
            legendloc="left")
retro2 <- SSplotRetro(retroSummary2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F")
retro3 <- SSplotRetro(retroSummary3,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE)
retro4 <- SSplotRetro(retroSummary4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE)
retro5 <- SSplotRetro(retroSummary5,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = "F",
            tickEndYr=TRUE)
```


```{r eval=FALSE, message=FALSE, warning=FALSE}
#En bulcle
# Definir el número de iteraciones
num_iteraciones <- 5

# Crear una lista para almacenar los resultados
retros <- list()

# Ejecutar el bucle for
for (i in 1:num_iteraciones) {
  # Llamar a la función con los diferentes resúmenes (retroSummary1, retroSummary2, ..., retroSummary7)
  retros[[i]] <- SSplotRetro(get(paste0("retroSummary", i)),
                              add = TRUE,
                              forecast = FALSE,
                              legend = TRUE,
                              verbose = FALSE)
}
```



## 3.4. Hindcast Cross-Validation and prediction skill

Implementing the Hindcast Cross-Validation (HCxval) diagnostic in Stock Synthesis requires the same model outputs generated by `r4ss:SS_doRetro()`. As a robust measure of prediction skill, we implemented the mean absolute scaled error (MASE). In brief, the MASE score scales the mean absolute. Regarding (A MASE score > 1 indicates that the average model forecasts are worse than a random walk. Conversely, a MASE score of 0.5 indicates that the model forecasts twice as
accurately as a naïve baseline prediction; thus, the model has prediction skill.



```{r}
hci = SSplotHCxval(retroSummary1, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```

```{r echo=FALSE}
# model01
tablebias1 <- SShcbias(retroSummary1,quant="SSB",verbose=F)
tablebias1b <- SShcbias(retroSummary1,quant="F",verbose=F)

kbl(tablebias1, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s01")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias1b, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s01")  %>% 
    kable_styling(latex_options = "HOLD_position")

# model2
tablebias2 <- SShcbias(retroSummary2,quant="SSB",verbose=F)
tablebias2b <- SShcbias(retroSummary2,quant="F",verbose=F)

kbl(tablebias2, booktabs = T,format = "latex",
    caption = "Rho parameter in SSB model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")

kbl(tablebias2b, booktabs = T,format = "latex",
    caption = "Rho parameter in F model s2")  %>% 
    kable_styling(latex_options = "HOLD_position")
```


\pagebreak

## 3.5. Comparación de resultados entre modelos

```{r echo=FALSE, message=FALSE}
#PLOT labels, name of each model run
legend.labels <- c( #"s01",
                  "s1",
                 "s2",
                 "s3",
                 "s4",
                 "s5")

#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist <- SSgetoutput(keyvec = NULL,
                       dirvec = c(#dir01,
                                  dir1,
                                  dir2,
                                  dir3,
                                  dir4,
                                  dir5),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput <- SSsummarize(biglist)

comp <- SSplotComparisons(summaryoutput,
                  legendlabels = c(#"s01",
                                   "s1",
                                   "s2",
                 "s3",
                 "s4",
                 "s5"),
                 pheight=4.5,
                 png=TRUE,
                 plotdir=fig_path)
comp
```


```{r eval=FALSE}
comtable <- SStableComparisons(summaryoutput,
                   likenames = c("TOTAL", 
                                 "Survey", 
                                 "Length_comp",
                                 "Age_comp", 
                                 "priors",
                                 "Size_at_age"), 
                   names = c("Recr_Virgin",
                             "R0", 
                             "steep",
                             "NatM",
                             "L_at_Amax", 
                             "VonBert_K", 
                             "SSB_Virg", 
                             "Bratio_2017",
                             "SPRratio_2016"),
                   digits = NULL,
                   modelnames = c("s01", "s1","s2",
                 "s3",
                 "s4",
                 "s5",
                 "s6",
                 "s7"),
                   csv = FALSE,
                   csvdir =~"/IEO/SA_Donax_trunculus",
                   csvfile = "parameter_comparison_table.csv",
                 verbose = TRUE,
                   mcmc = FALSE)
kbl(comtable, booktabs = T,format = "latex",
    caption = "Comparacion likelihood y parámetros s01, s1, s2, s3, s4, s5, s6 y s7")  %>% 
    kable_styling(latex_options = "scale_down")

```

Lo analisis comparados, muestran las estimaciones de cada escenario propuesto para los casos de fraccion de biomasa virginal (Figura \ref{fig:biov}), desvio de los reclutamientos (Figura \ref{fig:devrec}) y mortalidad por pesca (Figura \ref{fig:ftotal}).


```{r biov, echo=FALSE, out.width = "80%", fig.align='center', fig.cap="\\label{fig:biov}Comparación escenario de razon de Biomasa"}
knitr::include_graphics("Fig/compare4_Bratio_uncertainty.png")
```


```{r debrec, echo=FALSE,  fig.align='center', fig.cap="\\label{fig:devrec}Comparación escenarios de desvios de reclutamiento"}
knitr::include_graphics("Fig/compare12_recdevs_uncertainty.png")
```


```{r ftotal, echo=FALSE, out.width = "80%", fig.align='center', fig.cap="\\label{fig:ftotal}Comparación escenarios de Mortalidad por Pesca"}
knitr::include_graphics("Fig/compare8_Fvalue_uncertainty.png")
```

# 4. STATUS



```{r message=F}
mvln1 <- SSdeltaMVLN(base.model1,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100,
                   years=seq(2004,2023,1))

mvln2 <-  SSdeltaMVLN(base.model2,
                   Fref = "MSY", 
                   plot = TRUE,
                   addprj=TRUE,
                   virgin = TRUE,
                   mc=100)

```


\pagebreak

# 5. PROGRESO

- explicar PBR

- Definir estatus

- `S01` falta implementar modelo

- Falta mirar perfiles de verosimilitud

\pagebreak

# 6. REFERENCIAS
