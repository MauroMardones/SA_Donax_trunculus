---
title: "![](IEO-logo2.png){width=10cm}"
output:
  bookdown::pdf_document2:
    includes:
      before_body: titulo.sty
    keep_tex: true
    latex_engine: xelatex
    number_sections: no
    toc: true
    toc_depth: 3
bibliography: Donax.bib
csl: apa.csl
link-citations: yes
linkcolor: blue
indent: no
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhf{}
- \lfoot[\thepage]{}
- \rfoot[]{\thepage}
- \fontsize{12}{22}
- \selectfont
---

\pagebreak


```{r setup1, echo=FALSE}
rm(list = ls())
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE,
                      fig.align = 'center',
                      fig.pos = "H",
                      dev = 'jpeg',
                      dpi = 300,
                      oyut.width = "80%")
#XQuartz is a mess, put this in your onload to default to cairo instead
options(bitmapType = "cairo") 
# (https://github.com/tidyverse/ggplot2/issues/2655)
# Lo mapas se hacen mas rapido
```

# Context


This document contains the workflow and supplementary analyses for the manuscript "Evaluating the effects of varying minimum legal sizes on population variables in the wedge clam (*Donax trunculus*) fishery using a length-to-age model". It provides a fully self-contained, code-based framework including all scripts required to run the stock assessment models, generate outputs, and evaluate management scenarios.

The assessment is based on an integrated length-to-age structured model implemented in Stock Synthesis (SS3, version 3.30.23) [@Methot2013; @Methot2023], applied to the Gulf of Cádiz, Spain. The analyses explore how alternative minimum legal size regulations affect key population variables such as spawning biomass, recruitment, and fishing mortality, thus offering scientific support for management advice.

This work is conducted within the framework of scientific advice coordinated by the Centro Oceanografico Cádiz (IEO-CSIC), building upon the long-term monitoring program FEMP 04, which has collected biological, fishery-dependent, and environmental data since 2013. These data provide the foundation for this first formal stock assessment of *D. trunculus* in the region using an integrated modeling approach.


# Methodology

The workflow associated with stock assessment modeling—including its components and data sources—is generically represented in the following flowchart (Figure \@ref{fig:esq}).

\begin{landscape}

```{r esq, echo=FALSE, out.width = "100%", fig.align='center', fig.cap="Workflow of stock assessement proces in wedge clam in Gulf of Cádiz"}
knitr::include_graphics(here::here("Fig",
                                   "diagrama.png"))

```

\end{landscape}


## Setting Aseesement workflow

This section outlines the general workflow used in the stock assessment model for *Donax trunculus* (wedge clam). It describes the main components, data sources, and the sequence of running models, fitting, and interpreting the integrated model of different scenarios.

Libraries necessaries to do this analysis;

```{r}
# List of required packages grouped by functionality
required_packages <- c(
  # Stock assessment + SS3 tools
  "r4ss",         # Reading SS3 output
  "ss3diags",     # Diagnostics for SS3 assessments
  #  Data manipulation and transformation
  "dplyr",        # Core data manipulation
  "tidyverse",    # Collection of core tidy packages
  "purrr",        # Functional programming (map, walk, etc.)
  "plyr",         # Older data manipulation package (conflicts with dplyr)
  "reshape2",     # Data reshaping (e.g. melt/cast)
  #  Visualization and plotting
  "ggrepel",      # Better label placement in ggplot2
  "ggplot2",      # Core plotting
  "ggthemes",     # Themes like theme_few()
  "gridExtra",     # Arranging multiple ggplots
  "ggridges",     # Ridgeline plots
  "ggpubr",       # ggarrange() and publication-ready visuals
  "grid",         # Grid graphics system
  "png",          # Reading PNG images
  #  Statistical and modeling tools
  "modelsummary",  # Model summaries and diagnostics
  "mvtnorm",      # Multivariate normal distributions
  "forecast",     # Time series forecasting and diagnostics
  #  File and path management
  "here",         # Reproducible file paths
  "openxlsx",    # Reading/writing Excel files
  #  Reporting and tables
  "kableExtra"    # Enhanced HTML/LaTeX tables
)

# Optionally install missing packages
missing <- required_packages[!required_packages %in% installed.packages()[, "Package"]]
if (length(missing)) install.packages(missing)

# Load packages with modern purrr approach
purrr::walk(required_packages, library, character.only = TRUE)

```


```{r echo=FALSE}
# Set model and figure paths using `here::here()` for reproducibility
# dir_test     <- here::here("s01")       # Test model
dir0     <- here::here("s0")        # Initial model (2.2 MLS fixed)
dir1     <- here::here("s1")        # Reference model (2.3 MLS fixed)
# Alternative management scenarios
dir2 <- here::here("s2")       # Scenario 2.4 (MLS fixed)
dir3 <- here::here("s3")       # Scenario 2.5 (MLS fixed) (current MLS)
dir4 <- here::here("s4")       # Scenario 2.6 (MLS fixed)
# # Simulated mean-based models
# dir2.3 <- here::here("s1_2.3")      # Simulated model: 2.3 mean MLS
# dir2.4 <- here::here("s1_2.4")      # Simulated model: 2.4 mean MLS
# dir2.5 <- here::here("s1_2.5")      # Simulated model: 2.5 mean MLS (current MLS)
# dir2.6 <- here::here("s1_2.6")      # Simulated model: 2.6 mean MLS

# Output figure path
fig_path <- here::here("Fig")           # Directory for saving figures
```

## Stock assessment model

The following equations provides a general mathematical expression of both biological and fishing processes that partly explain the population dynamics applicable to wedge clams. 

$$
N_{t,a} =
\begin{cases}
R_t & \text{if } a=1, \ \forall t \\[6pt]
N_{t-1,a-1} e^{-(F_{t-1,a-1} + M)} & \text{if } 1 < a < A - 1, \ \forall t \\[6pt]
N_{t-1,a-1} e^{-(F_{t-1,a-1} + M)} \, (1 - e^{-(F_{t,a} + M)}) & \text{if } a = A, \ t = 1 \\[6pt]
N_{t-1,a} e^{-(F_{t,a} + M)} & \text{if } a = A, \ t > 1
\end{cases}
$$


This equation defines the number of individuals ($N_{t,a}$) in the population at time $t$ and age $a$. For age $a=1$ at all times $t$, recruitment ($R_t$) is used: $N_{t,a} = R_t$. For ages $1 < a < A-1$, the number of individuals from the previous time step $t-1$ and age $a-1$ is adjusted by the exponential decay due to fishing mortality and natural mortality ($M$ =0.99). For the last age class $a=A$ at $t > 1$, the number of individuals is adjusted similarly but includes an additional factor for survival probability. For age $a=A$ at $t > 1$, the number of individuals from the previous time step $t-1$ and same age $a$ is adjusted by the exponential decay in the mathematical form: $N_{t-1,a} e^{-(F_{t,a} + M)}$.


$$
B_t = sum_{a} (P_{a,t} N_{a,t} w_l)
$$
This equation calculates the total biomass ($B_t$) at time $t$ where $B_t$ is the sum of the product of the proportion of mature individuals ($P_{a,t}$), the number of individuals ($N_{a,t}$), and the weight at age ($w_a$) across all age classes $a$.

$$
BD_t = sum_{a}( P_{a,t} N_{a,t} e^{-Z_a}) w_a O_i
$$

Spawning biomass equation show $BD_t$ as the sum of the product of the proportion of mature individuals ($P_{a,t}$), the number of individuals ($N_{a,t}$) adjusted by the exponential decay factor weighted by total mortality, the weight at age ($w_a$), and a vector of maturity ogive ($O_i$) across all age classes.

$$
N_{a,t+1} = \frac{\alpha \, BD_{t-1}}{\beta + BD_{t-1}} \, e^{\epsilon_t + 0.5 \, \sigma_\epsilon^2}
$$

$$
alpha = \frac{4hR_0}{(5h-1)}, beta = \frac{(1-h)BD_0}{(5h-1)}
$$

The dynamics are modeled by a Beverton-Holt type recruitment relationship. The recruitment submodel describe abundance ($N_{a,t+1}$) to the next year $t+1$ based on the spawning biomass ($BD_{t-1}$) from the previous year, where $\alpha$ and $\beta$ are parameters defined below, $\epsilon_t$ is a random error term, and $\sigma_\epsilon^2$ is the variance of the error. Parameter $\alpha$ is a parameter related to the maximum recruitment ($R_0$) and the steepness ($h$) of the stock-recruitment relationship. $\beta$ is a parameter related to the virgin spawning biomass ($BD_0$) and the steepness ($h$) is the parameter that regulates rate of change of relationship between stock and recruitment.

## Initial model conditioning (Reference model)

Spawning biomass was estimated at the beginning of the year, while recruitment was considered a dual event occurring around June and at the end of the year. Recruitment estimation included a diffuse stock-recruitment relationship (steepness = 0.7), and recruitment variability was modeled as deviations from the unfished recruitment level `R0`, assuming 2004 as the initial year (Table \@ref{tab:Tab1}).

Fishing mortality was estimated as the simple average of the `F` values for age classes 1 and 2, which in the model corresponds to option 5 of the `hybrid F method` recommended in SS3 [@Methot2013]. Density was assumed as a proxy for estimated biomass [@Caddy2004], derived from population surveys, and considered proportional to the vulnerable biomass of the stock, with catchability (`q`) estimated within the model. The `q` parameters were estimated from initial values specified in Table \@ref{tab:Tab1}, using both population monitoring and commercial data. All selectivity patterns, which relate observed length compositions from the commercial fleet and surveys to the population dynamics, were estimated using a logistic function. The parameters `p1` (length at the inflection point) and `p2` (length at 95% selection) were estimated by the model from initial values specified in Table \@ref{tab:Tab1}.


```{r Tab1, essage=FALSE, warning=FALSE, fig.cap= "Initial parameter values for the SS3 wedge clam model (S3). Each parameter row shows a lower bound (LO), upper bound (HI), and initial value (INIT). A negative phase (PHASE) means the parameter is fixed."}
start3 <- SS_readstarter(file = file.path(dir3,
                                               "starter.ss"),
                              verbose = FALSE)
dat3 <- SS_readdat(file = file.path(dir3, start3$datfile),
                        verbose = FALSE)
ctl3 <-  r4ss::SS_readctl(file = file.path(dir3,
                                    start3$ctlfil),
                        verbose = FALSE,
                        use_datlist = TRUE, 
                   datlist = dat3)
fore3 <- r4ss::SS_readforecast(file = file.path(dir3, 
                                                "forecast.ss"),
                              verbose = FALSE)
# can also read in wtatage.ss for an empirical wt at age model using
# r4ss::SS_readwtatage()

parbio <- ctl3$MG_parms[1:10, c(1:3,7)]
row.names(parbio) <- c("Nat M", 
                       "Lmin", 
                       "Lmax",
                       "VonBert K",
                       "CV young", 
                       "CV old", 
                       "Wt a", 
                       "Wt b", 
                       "L50%", 
                       "Mat slope")

SRpar <- ctl3$SR_parms[1:5, c(1:3,7)]
Qpar <- ctl3$Q_parms[1:2, c(1:3,7)]
Selpar <- ctl3$size_selex_parms[1:4, c(1:3,7)]
parInit <- rbind(parbio, SRpar, Qpar, Selpar)

parInit %>%
  kbl(booktabs = T,
      format = "latex",
      position = "ht!",
      caption = "\\label{Tab1}Initial parameter values for the SS3 wedge clam model (S3). Each parameter row shows a lower bound (LO), upper bound (HI), and initial value (INIT). A negative phase (PHASE) means the parameter is fixed.") %>%
  kable_paper("hover",
              full_width = F) %>%
  kable_styling(latex_options = c("striped", 
                                  "condensed"),
                full_width = FALSE,
                font_size = 9) %>%
  pack_rows(index = c("Natural mortality" = 1,
                      "Growth" = 5,
                      "Length-weight relationship" = 2,
                      "Maturity ogive" = 2,
                      "Stock-recruitment relationship" = 5,
                      "Catchability" = 2,
                      "Selectivity" = 4))
```
The initial fishing mortality for the wedge clam fishery is estimated, bounded between 0.005–0.1, with a prior mean of 0.05 and a weakly informative standard deviation of 0.8. The model starts from an initial guess of 0.1 and estimates this parameter, ensuring that initial fishing pressure is informed by both empirical bounds and prior information while being integrated consistently into the early population dynamics. 

## Scenarios

Five scenarios in which selectivity is fixed in the assessment model to match the same means (22 mm to 26 mm by 1mm), while retaining the original input data (Figure \@ref(fig:selfix)).

```{r selfix, echo = FALSE, out.width="100%", fig.cap="Scenarios of fishery selectivity fixed tested in modelling stock assessment in wedg clam in Gulf of Cádiz"}
# Función logística de selectividad / madurez
logistic_selectivity <- function(length, L50, slope) {
  1 / (1 + exp(-slope * (length - L50)))
}

# Parámetros
lengths <- seq(1, 35, by = 0.1)  
L50_values <- c(22, 23, 24, 25, 26)
slope <- 10.0  # Pendiente fija

# Diccionario L50 -> Escenario
L50_map <- c("22"="s0","23"="s1","24"="s2","25"="s3","26"="s4")

# Datos de selectividad con etiqueta de escenario
selectivity_data <- expand.grid(length = lengths, L50 = L50_values) %>%
  dplyr::mutate(selectivity = logistic_selectivity(length, L50, slope),
         Scenario = factor(L50_map[as.character(L50)],
                           levels = c("s0","s1","s2","s3","s4")))

# Crear datos de madurez con etiqueta
maturity_data <- data.frame(
  length = lengths,
  maturity = logistic_selectivity(lengths, L50 = 10.8, slope = 2.0),
  Scenario = "Maturity (L50=10.8 mm)"   # para que aparezca en la leyenda
)
set.seed(123) # para reproducibilidad
hist_data <- data.frame(length = rnorm(1000, mean = 24, sd = 5))
hist_counts <- hist(hist_data$length, breaks = seq(0, 45, by = 1), plot = FALSE)
hist_df <- data.frame(
  length = hist_counts$mids,
  density = hist_counts$counts / max(hist_counts$counts)
)


esc_labels <- c(
  "s0" = "s0 = (22 mm) Strong reduction of current MLS",
  "s1" = "s1 = (23 mm) Lower-than-current MLS",
  "s2" = "s2 = (24 mm) Slightly below current MLS",
  "s3" = "s3 = (25 mm) Current MLS (baseline)",
  "s4" = "s4 = (26 mm) Above current MLS"
)
selfix <- ggplot() +
  geom_col(data = hist_df, aes(x = length, y = density),
           fill = "grey70", color = "grey70", alpha = 0.01, width = 1) +
  geom_line(data = selectivity_data, 
            aes(x = length, y = selectivity, color = Scenario), size = 1.2) +
  geom_line(data = maturity_data, 
            aes(x = length, y = maturity, color = Scenario), 
            linetype = "dotted", size=0.8) +
  geom_vline(xintercept = 10.8, color = "grey",
             size=0.3) +
  labs(
    x = "Length (mm)",
    y = "Selectivity / Maturity / Normalized frequency",
    color = "Scenario"
  ) +
  theme_few(base_size = 10) +
  scale_color_manual(
    name = "Scenario",
    values = c("s0" = "#000000",
               "s1" = "#cccccc",  
               "s2" = "#999999",     
               "s3" = "#ca0020",  
               "s4" = "#666666",
               "Maturity (L50=10.8 mm)" = "grey"),   # color para madurez
    labels = c(esc_labels, "Maturity (L50=10.8 mm)")
  ) +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 8),
    legend.title = element_text(size = 9),
    plot.margin = margin(10, 10, 10, 10)
  ) +
  xlim(5, 35)

selfix

```

This dual approach allows for evaluating the effect of hypothetical changes in population structure (e.g., as a result of shifting LMLS), and the influence of assuming specific selectivity patterns in the assessment model, independent of actual data structure. By combining observed and simulated datasets, this strategy supports a robust evaluation of how assumed biological structure and model assumptions interact, particularly regarding exploitation patterns and size-based selectivity in this artisanal fishery. Total set of scenario testes is displayed in Table \@ref{tab:Tab2}.

```{r Tab2, message=FALSE, warning=FALSE, fig.cap="Description of the alternative scenarios and variants of the base model"}
esc <- c("s0","s1", "s2", "s3", "s4")

description <- c(
   "22 mm. Strong reduction of current MLS",
  "23 mm. Lower-than-current MLS",
  "24 mm. Slightly below current MLS",
  "25 mm. Current MLS (baseline)",
  "26 mm. Above current MLS"
)

ESC1 <- cbind(esc, description)

ESC1 %>%
  kbl(booktabs = TRUE,
      format = "latex",
      position = "h!",
      align = "l",
      col.names = linebreak(c("Scenarios", "Description"), align = "c"),
      caption = "\\label{Tab2}Description of the alternative scenarios and variants of the base model (S1).") %>%
  kable_paper("hover", full_width = FALSE) %>%
  kable_styling(latex_options = c("striped", "condensed"),
                full_width = FALSE,
                font_size = 10)

```
## Run models

```{r eval=F, message=F, include=FALSE}
directorios <- c("s0",
                 "s1",
                 "s2",
                 "s3",
                 "s4") 

for (dir in directorios) {
  r4ss::run(
    dir = dir,
    exe = "../executable/ss3_opt_osx_arm64",
    skipfinished = FALSE,
    show_in_console = TRUE
  )
}
```

```{r eval=F, echo=F}
r4ss::run(
  dir = dir0,
  exe = "../executable/ss3_opt_osx_arm64",
  skipfinished = FALSE,
  show_in_console = TRUE# change to true to watch the output go past
)
```

Read outputs from each scenario;

```{r message=FALSE, warning=FALSE, include=FALSE}
base.model0 <- SS_output(dir=dir0,
                         covar=T,
                         forecast=T)
base.model1 <- SS_output(dir=dir1,
                         covar=T,
                         forecast=T)


base.model2 <- SS_output(dir=dir2,
                         covar=T,
                         forecast=T)
#dir3<-here("s3")
base.model3 <- SS_output(dir=dir3,
                         covar=T,
                         forecast=T)
#dir1<-here("s4")
base.model4 <- SS_output(dir=dir4,
                         covar=T,
                         forecast=T)
```

\pagebreak

# Results

## Comparision between scenarios of modeling 

### Population Variables

The model allows for the estimation of various population-level variables, which are listed in Table \@ref{tab:Tab4}. These variables provide key insights into the status, structure, and dynamics of the population under study. They include metrics related to population abundance, biomass, age or size structure, recruitment, mortality, and other demographic or ecological characteristics that are essential for stock assessment and management decisions.



```{r Tab4, message=FALSE, warning=FALSE, fig.cap="Population variables estimated by the SS3 model for wedge clam in Gulf of Cádiz"}
extract_vars <- function(model, scen_name) {
  model$derived_quants %>%
    filter(str_detect(Label, "^(Recr_|SSB_|SPRratio_|Bratio_)")) %>%
    mutate(Variable = case_when(
      str_detect(Label, "^Recr_") ~ "Recruitment",
      str_detect(Label, "^SSB_") ~ "SSB",
      str_detect(Label, "^SPRratio_") ~ "SPRratio",
      str_detect(Label, "^Bratio_") ~ "Depletion"
    ),
    Year = as.numeric(str_extract(Label, "[0-9]{4}")),
    Scenario = scen_name) %>%
    select(Year, Scenario, Variable, Value, sd = StdDev)
}

dq0 <- extract_vars(base.model0, "s0")
dq1 <- extract_vars(base.model1, "s1")
dq2 <- extract_vars(base.model2, "s2")
dq3 <- extract_vars(base.model3, "s3")
dq4 <- extract_vars(base.model4, "s4")

all_df <- bind_rows(dq0, dq1, dq2, dq3, dq4)


tabla_resumen <- all_df %>%
  dplyr::group_by(Scenario, Variable, Year) %>%
  dplyr::summarise(Media = mean(Value, na.rm = TRUE),
            SDmedia = mean(sd, na.rm = TRUE),
            .groups = "drop")

tabla_resumen_texto <- tabla_resumen %>%
  mutate(Media_SD = paste0(round(Media, 2), " (", round(SDmedia, 2), ")")) %>%
  select(Scenario, Variable, Year, Media_SD) %>%
  pivot_wider(
    names_from = c(Scenario, Variable),
    values_from = Media_SD,
    names_sep = "_"
  )
```
Main variables population by scenario (Figure \@ref(fig:popvar2))

```{r popvar2, fig.cap="Time series of different populations variables"}
# Función de gráfico genérica
plot_var <- function(df, var_name) {
  p <- ggplot(df %>% filter(Variable == var_name),
              aes(x = Year, y = Value, 
                  color = Scenario, 
                  fill = Scenario)) +
    geom_line(size = 1) +
    geom_ribbon(aes(ymin = Value - sd, 
                    ymax = Value + sd), 
                alpha = 0.2, color = NA) +
    labs(y = var_name, x = "") +
    scale_color_manual(values = c("s0" = "#000000",
                                  "s1" = "#cccccc",
                                  "s2" = "#999999",
                                  "s3" = "#ca0020",
                                  "s4" = "#666666")) +
    scale_fill_manual(values = c("s0" = "#000000",
                                 "s1" = "#cccccc",
                                 "s2" = "#999999",
                                 "s3" = "#ca0020",
                                 "s4" = "#666666")) +
    theme_minimal() +
    theme(legend.position = "bottom",
          axis.text.x = element_text(angle = 90, hjust = 1)) +
    xlim(2004, 2023)
  
  # Agregar líneas solo si la variable es Depletion
  if (var_name == "Depletion") {
    p <- p + 
      geom_hline(yintercept = 0.4, 
                 linetype = "dashed", 
                 color = "black") +
      geom_hline(yintercept = 0.2, 
                 linetype = "dashed", color = "black")
  }
  
  return(p)
}
# Graficar cada variable
plot_recr <- plot_var(all_df, "Recruitment")
plot_ssb  <- plot_var(all_df, "SSB")
plot_spr  <- plot_var(all_df, "SPRratio")
plot_depl  <- plot_var(all_df, "Depletion")

ggarrange(plot_recr,
          plot_ssb,
          #plot_spr,
          plot_depl,
          ncol = 3, nrow = 1,
          common.legend = TRUE, legend = "bottom")

```

Mean and quantile of Main Population Variables per Scenario for Wedge Clam in Figure \@ref(fig:summaryplot)

```{r summaryplot, out.width="100%", warning=FALSE, message=FALSE, fig.cap="R0 probability predicted by scenario"}

summary_df <- all_df %>%
  dplyr::group_by(Scenario, Variable) %>%
  dplyr::summarise(mean_val = mean(Value, na.rm = TRUE), .groups = "drop")

variables_to_plot <- c("Recruitment", "SSB", "Depletion")


all_df_filtered <- all_df %>%
  dplyr::filter(Variable %in% variables_to_plot) %>%
  dplyr::mutate(Variable = factor(Variable, levels = variables_to_plot))

summary_df_filtered <- summary_df %>%
  dplyr::filter(Variable %in% variables_to_plot) %>%
  dplyr::mutate(Variable = factor(Variable, levels = variables_to_plot))

summarybox <- ggplot(all_df_filtered,
       aes(x = Scenario, y = Value, fill = Scenario)) +
  geom_boxplot(alpha = 0.5) +
  geom_point(data = summary_df_filtered,
             aes(x = Scenario, y = mean_val),
             color = "black", size = 3) +
  facet_wrap(~ Variable, scales = "free_y", ncol = 3) +
  scale_fill_manual(values = c("s0" = "#000000",
                               "s1" = "#cccccc",
                               "s2" = "#999999",
                               "s3" = "#ca0020",
                               "s4" = "#666666")) +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90, hjust = 1))
summarybox
```

```{r eval=FALSE}
#read in all model runs
#note if cover=T you need a hessian; if covar=F you do not need a hessian
biglist1_4 <- SSgetoutput(keyvec = NULL,
                       dirvec = c(dir0,
                                  dir1,
                                  dir2,
                                  dir3,
                                  dir4),
                       getcovar = F)

#create summary of model runs from list above
summaryoutput1_4 <- SSsummarize(biglist1_4)

SSplotComparisons(summaryoutput1_4,
                  legendlabels = c("s0",
                                   "s1",
                 "s2",
                 "s3  (Ref Model)",
                 "s4"),
                 filenameprefix = "COM1",
                 labels = c("Year", 
                            "Spawning biomass (t)",
                            "Relative spawning biomass", 
                            "Age-0 recruits (1,000s)",
                            "Recruitment deviations", 
                            "Index", "Log index", 
                            "1 - SPR", 
                            "Density",
                            "Management target", 
                            "Minimum stock size threshold",
                            "Spawning output",
                            "Harvest rate"),
                 png=TRUE,
                 plotdir=fig_path)
```

### Recruit deviation

Figure \@ref(fig:devrec) shows the recruitment deviations across different scenarios. The plot displays the deviations of observed recruitment from the model-predicted recruitment over time for each scenario, allowing for a visual comparison of how recruitment patterns vary under different management strategies.

```{r devrec, warning=FALSE, fig.height=3, fig.width=8, out.width="100%", fig.cap="Recruitment deviation across scenarios"}
# Extraer datos de reclutamiento con escenario
dev0 <- base.model0$recruit[1:21,c(1,7)] %>% 
  mutate(Scenario = "s0")
dev1 <- base.model1$recruit[1:21,c(1,7)] %>% 
  mutate(Scenario = "s1")
dev2 <- base.model2$recruit[1:21,c(1,7)] %>% 
  mutate(Scenario = "s2")
dev3 <- base.model3$recruit[1:21,c(1,7)] %>% 
  mutate(Scenario = "s3")
dev4 <- base.model4$recruit[1:21,c(1,7)] %>% 
  mutate(Scenario = "s4")

# Lista de data.frames dev con nombres de escenarios
data_list <- list(
  s0 = dev0,
  s1 = dev1,
  s2 = dev2,
  s3 = dev3,
  s4 = dev4
)

# Títulos para cada escenario
titles <- c(
  "s0: 22 cm MLS",
  "s1: 23 cm MLS",
  "s2: 24 cm MLS",
  "s3: 25 cm MLS (Ref Model)",
  "s4: 26 cm MLS"
)

dev_all <- bind_rows(dev0, dev1, dev2, dev3, dev4)

recruitdev <- ggplot(dev_all, aes(x = Yr, y = dev, color = Scenario)) +
  geom_point(size = 1.5) +
  stat_smooth(method = "loess", 
              span = 0.1, 
              se = TRUE,
              aes(fill = Scenario),
              alpha = 0.2) +
  geom_hline(yintercept = 0, color = "red", linetype = "dotdash") +
  scale_color_manual(values = c(
    "s0" = "#000000",  # negro para histórico
    "s1" = "#cccccc", 
    "s2" = "#cccccc", 
    "s3" = "#ca0020", 
    "s4" = "#cccccc"
  )) +
  scale_fill_manual(values = c(
    "s0" = "#000000", 
    "s1" = "#cccccc", 
    "s2" = "#cccccc", 
    "s3" = "#ca0020", 
    "s4" = "#cccccc"
  )) +
  labs(x = "", y = "Residuals", title = "") +
  ylim(-2, 2) +
  theme_few() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "bottom")
recruitdev

```
### Autocorrelation in Recruit 

To evaluate the temporal correlation structure of wedge clam recruitment under different model configurations, we performed an Autocorrelation Function (ACF) analysis (Figure \@ref(fig:acf)). The ACF measures the correlation between observations at different time lags, helping to assess whether recruitment estimates exhibit persistence or randomness across time.

```{r acf, fig.height=3, fig.width=8, out.width="100%", fig.cap="Autocorrelation in Recruit by scenario"}
# Predicciones de reclutamiento
recs0 <- base.model0$recruit$pred_recr
recs1 <- base.model1$recruit$pred_recr
recs2 <- base.model2$recruit$pred_recr
recs3 <- base.model3$recruit$pred_recr
recs4 <- base.model4$recruit$pred_recr

# Gráficos ACF por escenario
p0 <- ggAcf(recs0) +
  ggtitle("s0") +
  theme_few()
p1 <- ggAcf(recs1) +
  ggtitle("s1") +
  theme_few()
p2 <- ggAcf(recs2) +
  ggtitle("s2") +
  theme_few()
p3 <- ggAcf(recs3) +
  ggtitle("s3") +
  theme_few()
p4 <- ggAcf(recs4) +
  ggtitle("s4") +
  theme_few()

# Combinar todos los gráficos
ggpubr::ggarrange(p0, 
                  p1, 
                  p2, p3, 
                  p4, ncol = 5, 
                  nrow = 1, common.legend = TRUE)
```

The figure shows the autocorrelation functions (ACF) of predicted recruitment for the five scenarios (`s0` to `s4`). Each panel represents one scenario, with lag on the x-axis and autocorrelation on the y-axis. All scenarios show strong positive autocorrelation at lag 1, indicating that recruitment in one year is positively correlated with recruitment in the previous year. The decay rate and the magnitude of negative autocorrelation at intermediate lags are broadly similar across scenarios, indicating consistent short-term dynamics in recruitment deviations across management scenarios. In summary, recruitment residuals exhibit strong short-term autocorrelation, but the effect diminishes quickly after a few years, and the different MLS scenarios do not strongly alter this autocorrelation pattern.


### Productivity and Interannual Variability by Scenario

Estimating the productivity of wedge clam is critical for understanding the species’ capacity to replenish its population in response to varying levels of spawning biomass. Productivity, defined as the ratio of recruitment to spawning stock biomass, provides a standardized measure of reproductive success and population resilience under different ecological and fishing pressures. Comparing productivity across scenarios—each representing different assumptions about environmental drivers, fishing mortality, or predator dynamics—enables a robust evaluation of how krill populations reflect this changes.

For each scenario \( i \) and year \( t \), we computed the productivity as the ratio between recruitment and spawning stock biomass (SSB):

$$
\text{Productivity}_{i,t} = \frac{\text{Recruitment}_{i,t}}{\text{SSB}_{i,t}}
$$

We also calculated the "interannual percentage change" in recruitment and SSB as:

$$
\text{Change in Recruitment}_{i,t} = \left( \frac{\text{Recruitment}_{i,t} - \text{Recruitment}_{i,t-1}}{\text{Recruitment}_{i,t-1}} \right) \times 100
$$

$$
\text{Change in SSB}_{i,t} = \left( \frac{\text{SSB}_{i,t} - \text{SSB}_{i,t-1}}{\text{SSB}_{i,t-1}} \right) \times 100
$$

These metrics allow us to analyze both the productivity and the temporal dynamics of the population under each scenario \( i \).

Figure \@ref(fig:prod) illustrates the relationship between productivity (Recruitment/SSB) and relative spawning biomass (SSB/SSB_virgin) across different scenarios. Each point represents a year within a scenario, colored by the scenario to which it belongs. The plot highlights how productivity varies with changes in spawning biomass, providing insights into the stock-recruitment dynamics under different management strategies.

```{r prod, warning=FALSE, message=FALSE, fig.cap="Productivity (ratio Recruitment SSB) vs. Relative Spawning Biomass (ratio SSB SSBvirgin) by scenario"}
# Añadimos s0 al listado de escenarios
escenarios <- list(
  s0 = base.model0$SPAWN_RECR_CURVE,  # nuevo escenario
  s1 = base.model1$SPAWN_RECR_CURVE,
  s2 = base.model2$SPAWN_RECR_CURVE,
  s3 = base.model3$SPAWN_RECR_CURVE,
  s4 = base.model4$SPAWN_RECR_CURVE
)

# Calculamos resultados
resultados <- imap_dfr(escenarios, function(df, nombre) {
  df %>%
    mutate(
      Scenario = nombre,
      Productividad = Recruitment / SSB,
      Cambio_Recruit = c(NA, diff(Recruitment)) / lag(Recruitment) * 100,
      Cambio_SSB = c(NA, diff(SSB)) / lag(SSB) * 100
    )
})

# Colores: s1 en rojo destacado, s0 en azul, otros en grises
colores_escenarios <- c(
  "s0" = "black",     # Azul destacado
  "s1" = "#ca0020",     # Rojo destacado
  "s2" = "#999999",     # Gris medio
  "s3" = "#cccccc",     # Gris claro
  "s4" = "#666666"      # Gris oscuro
)

# Graficamos
prod <- ggplot(resultados, aes(x = `SSB/SSB_virgin`, y = Productividad, color = Scenario)) +
  geom_point(size = 1.1, alpha = 0.7) +
  # Agregar puntos del s1 y s0 encima para destacarlos más
  geom_point(data = filter(resultados, Scenario %in% c("s1", "s0")), 
             aes(x = `SSB/SSB_virgin`, y = Productividad, color = Scenario), 
             size = 1.3, alpha = 1) +
  labs(
    y = "Recruitment / SSB",
    x = "SSB / SSB_virgin"
  ) +
  scale_color_manual(name = "", values = colores_escenarios) +
  theme_bw() +
  theme(legend.position = "bottom")

prod

```

### Explotation Rate

Explotation rato (havest rate) in Figure \@ref(fig:hrate)

```{r hrate, warning=FALSE, message=FALSE, fig.cap="Harves rate by scenario in krill overtime"}
df1 <- base.model1$exploitation[, c(1, 4)] %>% mutate(model = "s1")
df2 <- base.model2$exploitation[, c(1, 4)] %>% mutate(model = "s2")
df3 <- base.model3$exploitation[, c(1, 4)] %>% mutate(model = "s3")
df4 <- base.model4$exploitation[, c(1, 4)] %>% mutate(model = "s4")
df0 <- base.model0$exploitation[, c(1, 4)] %>% mutate(model = "s0")

# Unir todos los dataframes
df_all <- bind_rows(df0, df1, df2, df3, df4)
colnames(df_all) <- c("year", "exploitation_rate", "model")

# Colores incluyendo s0
colores <- c(
  "s0" = "black",     # Azul destacado
  "s1" = "#ca0020",     # Rojo destacado
  "s2" = "#999999",     # Gris medio
  "s3" = "#cccccc",     # Gris claro
  "s4" = "#666666"      # Gris oscuro
)

# Graficar
ggplot(df_all, aes(x = year, y = exploitation_rate, color = model)) +
  geom_line() +
  geom_point(size = 3, shape = 16) +
  scale_color_manual(values = colores) +
  scale_x_discrete(
    breaks = seq(2000, 2023, by = 1)  # etiquetas cada año
  ) +
  labs(
    title = "",
    x = "",
    y = "Exploitation Rate",
    color = "Scenario"
  ) +
  xlim(1997, 2023) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, 
                               vjust = 0.5, 
                               hjust = 1)  # texto vertical
  )

```

## Diagnosis and robustness

A rigorous model diagnosis is essential to ensure the reliability and robustness of stock assessment models. The key steps for a good practice in model diagnosis include:  

1. Convergence Check: The model must reach a final convergence criterion of 1.0e-04 to ensure numerical stability and reliable parameter estimation.  

2. Residual Analysis: Both visual inspection and statistical metrics are used to evaluate model residuals, helping to detect patterns of bias or misfit.  

3. Retrospective Analysis: The Mohn’s rho parameter is used to assess the consistency of model estimates when sequentially removing recent years of data, identifying potential overestimation or underestimation trends.  

4. Likelihood Profile Analysis: This approach examines how the likelihood function behaves across a range of parameter values, providing insight into parameter uncertainty and model sensitivity.  

This framework follows the recommendations outlined by @Carvalho2021b, aiming to enhance transparency and reproducibility in model evaluation.

### Convergence Criteria

The convergence criterion used for model calibration is set to a final threshold of **0.0001** (or equivalently **1.0e-04**). This criterion defines the minimum acceptable difference between successive model iterations. Convergence is considered achieved when the absolute change in the objective function value or key parameters falls below this threshold. A smaller convergence value ensures that the model achieves a high degree of accuracy and stability in its final estimates, indicating that further iterations are unlikely to result in significant changes to the parameter estimates.


### Length Expected

Figure \@ref(fig:lengthexp) illustrates the expected length distributions over time for fleet 1 (COMERCIAL) across different scenarios. The ridgeline plots display the expected length frequencies (Exp) for each year, with the x-axis representing length bins (Bin) and the y-axis representing years (Yr). Each panel corresponds to a different scenario, allowing for a comparative visualization of how length distributions evolve under varying management strategies. The red points indicate the weighted mean length for each year, providing a summary measure of central tendency within the length distributions. Additionally, vertical red lines denote the minimum legal size (MLS) for each scenario, highlighting how changes in MLS influence the observed length structure of the population over time.

```{r lengthexp, fig.height=4, fig.width=12, out.width="100%", fig.cap="Expected length distribution by scenario and fleet"}
# Preparar los datos por escenario y flota 1
lend0 <- base.model0$lendbase %>%
  filter(Fleet == 1) %>% mutate(escenario = "s0")
lend1 <- base.model1$lendbase %>% 
  filter(Fleet == 1) %>% mutate(escenario = "s1")
lend2 <- base.model2$lendbase %>% 
  filter(Fleet == 1) %>% mutate(escenario = "s2")
lend3 <- base.model3$lendbase %>% 
  filter(Fleet == 1) %>% mutate(escenario = "s3 (Ref Model)")
lend4 <- base.model4$lendbase %>% 
  filter(Fleet == 1) %>% mutate(escenario = "s4")

# Combinar todos los escenarios
lend_all <- bind_rows(lend0, lend1, lend2, lend3, lend4)

# Calcular la talla media ponderada específica por año y escenario
mean_lengths <- lend_all %>%
  dplyr::group_by(Yr, escenario) %>%
  dplyr::summarise(mean_bin = weighted.mean(Bin, Exp), .groups = "drop")

# Definir las tallas mínimas por escenario (líneas verticales)
vlines <- data.frame(
  escenario = c("s0", "s1", "s2", "s3 (Ref Model)", "s4"),
  xintercept = c(2.2, 2.3, 2.4, 2.5, 2.6)  # ajusta valores según corresponda
)

# Crear gráfico
lengthexp <- ggplot(lend_all,
       aes(x = Bin, y = factor(Yr), height = Exp, 
           group = Yr)) +
  geom_ridgeline(fill = "lightgrey", 
                 color = "black", alpha = 0.6, scale = 10) +
  geom_point(data = mean_lengths, 
             aes(x = mean_bin, y = factor(Yr)),
             color = "red", size = 1.5,
             inherit.aes = FALSE) +
  geom_vline(data = vlines, aes(xintercept = xintercept), 
             color = "red") +
  facet_wrap(~ escenario, ncol = 5) +
  labs(title = "",
       x = "Length (mm)", y = "") +
  theme_minimal() +
  theme(panel.spacing = unit(1, "lines"),
        legend.position = "none",
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  xlim(1.5, 5) +
  scale_y_discrete(breaks = function(x) x[seq(1, length(x), by = 3)])

lengthexp
```
### Pearson Residuals 

This Figure \@ref(fig:pearson) provides a diagnostic assessment of the statistical performance of alternative model scenarios in fitting length composition data across years, fleets, and model assumptions. Across the four model scenarios, representing a baseline (2.5 cm as reference) and three values of Minimum Legal Size (MLS: 2.3 cm, 2.4 cm, and 2.6 cm), the reference model generally shows balanced and relatively small residuals across both commercial and populational fleets, suggesting a good fit to the observed data. However, as MLS increases, particularly in the 2.4 cm and 2.6 cm scenarios, a pattern of larger and more systematic residuals emerges, especially within the populational fleet. These patterns are most evident from 2016 onwards and are concentrated in mid-size length bins, indicating a potential mismatch between the model's structural assumptions and the actual population dynamics under stricter MLS regimes. Specifically, the models may be underestimating the proportion of intermediate-size individuals, suggesting limitations in capturing shifts in selectivity, growth, or recruitment processes. The commercial fleet, in contrast, shows more consistent residual behavior across all scenarios, which may imply a better alignment between model assumptions and observed exploitation dynamics. Temporally, early years (2013–2015) show relatively small and scattered residuals, but residual magnitude and clustering increase in later years, reinforcing the need to consider temporal variability in key processes. Overall, this residual analysis indicates a decline in model fit quality with increasing MLS, highlighting the need for more flexible model structures—such as time-varying selectivity or refined growth and recruitment models—to improve biological realism and ensure robust predictions in management strategy evaluations.



```{r pearson, out.width="100%",  fig.cap="Pearson residual by scenario and fleet"}
create_heatmap_df <- function(df, model_name) {
  df %>%
    dplyr::filter(Pearson < 5) %>%
    dplyr::select(c(1, 6, 19, 16)) %>%
    dplyr::mutate(Fleet = dplyr::case_when(
      Fleet == 1 ~ "Poblational",
      Fleet == 2 ~ "Comercial",
      TRUE ~ NA_character_
    )) %>%
    dplyr::mutate(Model = model_name)
}


df_all <- bind_rows(
  create_heatmap_df(base.model0$lendbase, "s0:"),
  create_heatmap_df(base.model1$lendbase, "s1:"),
  create_heatmap_df(base.model2$lendbase, "s2"),
  create_heatmap_df(base.model3$lendbase, "s3 (Ref Model)"),
  create_heatmap_df(base.model4$lendbase, "s4")
)

years <- c(2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023)


df_summary <- df_all |>
  dplyr::group_by(Model, Yr) |>
  dplyr::summarise(mean_resid = mean(Pearson, na.rm = TRUE),
                   sd_resid = sd(Pearson, na.rm = TRUE))


resid_plot <- ggplot(df_summary, 
       aes(x = Yr, y = mean_resid)) +
  geom_line(size = 1.2, color = "steelblue") +
  geom_point(size = 2, color = "steelblue") +
  geom_ribbon(aes(ymin = mean_resid - sd_resid, 
                  ymax = mean_resid + sd_resid),
              alpha = 0.2, fill = "steelblue", color = NA) +
  facet_wrap(~Model, ncol = 5) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_x_continuous(breaks = seq(min(df_summary$Yr), 
                                  max(df_summary$Yr), 
                                  by = 2)) +
  labs(x = "", y = "Residuals Pearson") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
  )
resid_plot
```

```{r eval=FALSE}
ggarrange(
          lengthexp,
          resid_plot,
          ncol = 1, nrow = 2,
          widths = c(1, 0.6))
```


```{r}
cpue_resid <- bind_rows(
  base.model0$cpue %>% mutate(model = "s0"),
  base.model1$cpue %>% mutate(model = "s1"),
  base.model2$cpue %>% mutate(model = "s2"),
  base.model3$cpue %>% mutate(model = "s3"),
  base.model4$cpue %>% mutate(model = "s4")
)

len_resid <- bind_rows(
   base.model0$lendbase %>% mutate(model = "s0"),
   base.model1$lendbase %>% mutate(model = "s1"),
  base.model2$lendbase %>% mutate(model = "s2"),
  base.model3$lendbase %>% mutate(model = "s3"),
  base.model4$lendbase %>% mutate(model = "s4")
)

cpue_df <- cpue_resid %>%
  transmute(
    Yr = Yr,
    Obs = Obs,
    Exp = Exp,
    model = model,
    Fleet_name = as.character(Fleet_name),  # Asegura que es character
    type = "Index"
  )

len_df <- len_resid %>%
  transmute(
    Yr = Yr,
    Obs = Obs,
    Exp = Exp,
    model = model,
    Fleet_name = as.character(Fleet),  # Lo convertimos para que combine bien
    type = "Length"
  )

resid_all <- rbind(cpue_df,
                   len_df)

resid_all <- resid_all %>%
  mutate(Fleet_name = as.character(Fleet_name),
         Fleet_name = dplyr::case_when(
           Fleet_name == 1 ~ "Poblational",
           Fleet_name == 2 ~ "Comercial",
           TRUE ~ Fleet_name  # mantiene los nombres ya correctos
         ))

```

<!-- Also, we can check density of residual distribution in Figure \@ref(fig:resldens) -->

<!-- ```{r resldens, fig.width=10, fig.height=6, out.width="100%", fig.cap="Density of residual distribution by scenarios in krill model"} -->
<!-- ggplot(resid_all, aes(x = Obs - Exp, color = model)) + -->
<!--   geom_density(alpha = 0.5) + -->
<!--   facet_wrap(Fleet_name~type, scales = "free") + -->
<!--   labs(title = "Residual Distribution",  -->
<!--        x = "Residual (Obs - Exp)",  -->
<!--        y = "Density") + -->
<!--   scale_color_manual(name = "", -->
<!--                      values = c("s0" = "black", -->
<!--                                 "s1" = "#ca0020",   -->
<!--                                 "s2" = "#999999",   -->
<!--                                 "s3" = "#cccccc",   -->
<!--                                 "s4" = "#666666")) + -->
<!--   theme_minimal() -->
<!-- ``` -->


### Residual consistency 

Residual analysis is a critical component of model diagnostics in stock assessments. It helps evaluate the fit of the model to observed data and detect potential biases or inconsistencies. This process is applied to both length composition data and abundance indices such as CPUE (Catch Per Unit Effort) and survey-derived estimates. For length composition data, residuals represent the difference between observed and model-predicted length distributions. The standardized residuals are calculated as the difference between observed and expected proportions at each length bin. These residuals are plotted by year to identify systematic trends, biases, or inconsistencies in the data. Ideally, they should be randomly distributed around zero, indicating no systematic over- or underestimation.  

For abundance indices such as CPUE and fishery-independent surveys, residuals are analyzed to assess model fit and potential sources of bias. Residuals are computed as the difference between observed index values and those predicted by the model, typically standardized by dividing by the standard error to facilitate comparison across years. These residuals are then plotted over time to evaluate trends. A shaded confidence region, like the green area in the provided plot, represents expected variability, with outliers highlighted in red or other distinct markers. Persistent positive or negative residuals may indicate systematic bias in the model or data collection process.  

Statistical diagnostics are also performed to check for autocorrelation in residuals, which can indicate potential model misspecifications. When mean residual values are close to zero, the model fit is considered unbiased. By integrating these residual analyses for both length and abundance indices, stock assessment models can be refined, improving their reliability and increasing confidence in the assessment results.

In Length compositions, Figure \@ref(fig:pearsonresidlen) shows Pearson residuals for length compositions by scenario.

```{r pearsonresidlen, message=FALSE, fig.cap="Pearson residuals for length compositions by scenario"}
par(mfrow = c(2, 5), mar = c(5, 4, 2, 1))
SSplotRunstest(base.model0,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model1,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model2,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model3,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model4,
               subplots = "len",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
```

In Figure \@ref(fig:pearsonresidcpue) shows Pearson residuals for CPUE compositions by scenario.

```{r pearsonresidcpue, message=FALSE, fig.cap="Pearson residuals for CPUE compositions by scenario"}
par(mfrow = c(2, 5), mar = c(5, 4, 2, 1))
SSplotRunstest(base.model0,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model1,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model2,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model3,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
SSplotRunstest(base.model4,
               subplots = "cpue",
               add=T,
               plot = TRUE,
               plotdir = fig_path)
```


### Residual Analysis and RMSE 

Residual analysis of mean length data is a fundamental diagnostic tool in stock assessments. It helps evaluate whether the model provides an unbiased fit to the observed data and detects potential biases over time. In this figure, mean length residuals are plotted across years, differentiated by data source. The residuals represent the deviation of observed mean length from model-predicted values, standardized to facilitate interpretation.  

The black line represents a locally estimated scatterplot smoothing (Loess) curve, which provides a trend line to visualize systematic deviations over time. The presence of persistent positive or negative trends in the residuals may indicate biases in the growth model, selectivity assumptions, or misrepresentation of recruitment variability. The gray bars highlight periods where residual variability is particularly high, suggesting potential inconsistencies between observed and predicted size structures.  

RMSE quantifies the overall deviation between observed and predicted values, providing an aggregate measure of model fit. Lower RMSE values indicate better agreement between observed and predicted data. In fisheries stock assessment [@HurtadoF2015], RMSE thresholds for acceptable model performance typically range between *10% and 30%*, depending on the data quality and complexity of the population dynamics being modeled. Values exceeding this range suggest potential biases, requiring further investigation into the model structure, parameter estimation, or data sources.   

By analyzing residual patterns and RMSE values, the model can be refined to improve the accuracy of mean length predictions, ultimately enhancing the reliability of stock assessment outcomes and management recommendations (Figure \@ref(fig:rmse1)).

```{r rmse1, fig.cap="Time series of RMSE of length compositions by scenario"}
par(mfrow=c(2,3), mar=c(2,2,2,2))
rmse0l <- SSplotJABBAres(base.model0,
               subplots = "len",
               add=T)
rmse1l <- SSplotJABBAres(base.model1,
               subplots = "len",
               add=T)
rmse2l <- SSplotJABBAres(base.model2,
               subplots = "len",
               add=T)
rmse3l <- SSplotJABBAres(base.model3,
               subplots = "len",
               add=T)
rmse4l <- SSplotJABBAres(base.model4,
               subplots = "len",
               add=T)
```
Figure \@ref(fig:rmse2) show RMSE to index.

```{r rmse2, fig.cap="Time series of RMSE of CPUE compositions by scenario"}
par(mfrow=c(2,3), mar=c(2,2,2,2))
rmse0c <- SSplotJABBAres(base.model0,
               subplots = "cpue",
               add=T)
rmse1c <- SSplotJABBAres(base.model1,
               subplots = "cpue",
               add=T)
rmse2c <- SSplotJABBAres(base.model2,
               subplots = "cpue",
               add=T)
rmse3c <- SSplotJABBAres(base.model3,
               subplots = "cpue",
               add=T)
rmse4c <- SSplotJABBAres(base.model4,
               subplots = "cpue",
               add=T)
```
Comparision of RMSE in each scenario

```{r}
dfpearson_long <- data.frame(
  Pearson = c(base.model0$lendbase$Pearson,
              base.model1$lendbase$Pearson,
              base.model2$lendbase$Pearson,
              base.model3$lendbase$Pearson,
              base.model4$lendbase$Pearson),
  Scenario = factor(c(rep("s0", length(base.model0$lendbase$Pearson)),
                      rep("s1", length(base.model1$lendbase$Pearson)),
                      rep("s2", length(base.model2$lendbase$Pearson)),
                      rep("s3", length(base.model3$lendbase$Pearson)),
                      rep("s4", length(base.model4$lendbase$Pearson))))
)

pearson_plot <- ggplot(dfpearson_long, aes(x = Scenario, 
                                            y = Pearson, 
                                            fill = Scenario)) +
  geom_boxplot(width = 0.2, alpha = 0.8,
               outliers = FALSE) +
  #geom_jitter(width = 0.01, alpha = 0.3) +
  theme_minimal() +
  scale_fill_manual(name = "Scenario",
                    values = c("s0" = "#cccccc",
                               "s1" = "#cccccc", 
                      "s2" = "#cccccc", 
                      "s3" = "#ca0020", 
                      "s4" = "#cccccc")) +
  labs(title = "", x = "", y = "Residual") +
  theme(legend.position = "none")
```


```{r}
dfrmse <- data.frame(
  s0 = as.numeric(base.model0$index_variance_tuning_check$RMSE),
  s1 = as.numeric(base.model1$index_variance_tuning_check$RMSE),
  s2 = as.numeric(base.model2$index_variance_tuning_check$RMSE[1:2]),
  s3 = as.numeric(base.model3$index_variance_tuning_check$RMSE[1:2]),
  s4 = as.numeric(base.model4$index_variance_tuning_check$RMSE[1:2])
  )
#summary(dfrmse)
# t.test(dfrmse$s1.1, dfrmse$s1.2)  # Comparar s1.1 vs s1.2
# t.test(dfrmse$s1.1, dfrmse$s1.3)  # Comparar s1.1 vs s1.3
# t.test(dfrmse$s1.2, dfrmse$s1.3)
# t.test(dfrmse$s1.3, dfrmse$s1.4)
# anova_rmse <- aov(as.numeric(unlist(dfrmse)) ~ rep(1:4, each=nrow(dfrmse)))
```


```{r}
dfrmse_long <- reshape2::melt(dfrmse)

rmse <-ggplot(dfrmse_long, aes(x = variable, 
                        y = value, 
                        fill= variable)) +
  geom_boxplot(width=0.2,
               alpha=0.8,
               outliers = FALSE) +
  geom_jitter(width = 0.01, alpha = 0.3) +
  theme_minimal() +
  scale_fill_manual(name= "Scenario",
                    values = c("s0" = "#cccccc",
                               "s1" = "#cccccc", 
                      "s2" = "#cccccc", 
                      "s3" = "#ca0020", 
                      "s4" = "#cccccc")) +
  labs(title = "", x = "", y = "RMSE")+
  theme(legend.position = "none")
```


Model performance differed across scenarios (Figure \@ref(fig:rmse3)). RMSE values (left panel) were lowest under s0 and increased progressively through s1–s4, with higher medians and greater variability at larger MLS values. Scenario s3 (25 mm MLS, reference case) showed intermediate RMSE values relative to the other scenarios. Residual distributions (right panel) were centered around zero in all cases, with similar overall patterns across scenarios.


```{r rmse3, fig.cap="RMSE and Residual values for krill model evaluation across scenarios (s1.1-s1.4), highlighting precision and prediction errors."}
ggarrange(rmse,
          pearson_plot,
          ncol=2)
```

### Retrospective Analysis in Model Evaluation

Retrospective analyses provide insights into the differences in estimation patterns (underestimation or overestimation) among the models evaluated. These analyses assess the consistency and reliability of stock assessment models by systematically removing the most recent years of data and comparing the resulting estimates with the full dataset.  In this study, we conducted a retrospective analysis to examine the sensitivity of our recruitment and spawning stock biomass (SSB) estimates to the inclusion or exclusion of recent data. By applying this approach to multiple models, we identified potential biases and evaluated the stability of the recruitment estimates over time.  

```{r eval=FALSE}
#one by one
# retro(
#     dir = dir1.1,
#     oldsubdir = "",
#     newsubdir = "Retrospective",
#     years = 0:-4,
#     exe = "../executable/ss3_opt_osx_arm64"
#     extras = "-nox",
#     skipfinished = FALSE)

directorios <- c("s0",
                 "s1",
                 "s2",
                 "s3",
                 "s4")  
for (dir in directorios) {
  retro(
    dir = dir,
    oldsubdir = "",
    newsubdir = "Retrospective",
    years = 0:-5,
    exe = "~/IEO/SA_Donax_trunculus/executable/ss3_opt_osx_arm64",
    extras = "-nox",
    skipfinished = FALSE
  )
}
```

```{r message=FALSE, warning=FALSE}
retroModels0 <- SSgetoutput(dirvec=file.path(dir0,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary0 <- SSsummarize(retroModels0)
#stest
retroModels1 <- SSgetoutput(dirvec=file.path(dir1,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary1 <- SSsummarize(retroModels1)
#stest
retroModels2 <- SSgetoutput(dirvec=file.path(dir2,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary2 <- SSsummarize(retroModels2)
#stest
retroModels3 <- SSgetoutput(dirvec=file.path(dir3,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary3 <- SSsummarize(retroModels3)
#stest
retroModels4 <- SSgetoutput(dirvec=file.path(dir4,
                                            "Retrospective",
                                            paste("retro",0:-5,
                                                  sep="")))

retroSummary4 <- SSsummarize(retroModels4)
```


Using `retro()` and `SSplotRetro()` functions, we obtain main results from the retrospective analyses for each model scenario. The `retro()` function performs the retrospective analysis by creating subdirectories for each peel year, while `SSplotRetro()` generates plots to visualize the results. The `SSsummarize()` function compiles the outputs from multiple retrospective runs into a summary object for further analysis.

Retrospective analysis for spawning biomass ar showing in (Figure \@ref(fig:retrossb)).

```{r retrossb, fig.cap="Retrospective analysis for spawning biomass by scenario in krill"}
par(mfrow=c(2,3), mar=c(5,4,1,1)) 
retro0 <- SSplotRetro(retroSummary0,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro1 <- SSplotRetro(retroSummary1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro2 <- SSplotRetro(retroSummary2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro3 <- SSplotRetro(retroSummary3,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
retro4 <- SSplotRetro(retroSummary4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("SSB"))
```

Retrospective analysis for fishing mortality (Figure \@ref(fig:retrof))

```{r retrof, fig.cap="Retrospective analysis for fishing mortality by scenario in krill"}
par(mfrow=c(2,3), mar=c(5,4,1,1)) 
retro0 <- SSplotRetro(retroSummary0,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro1 <- SSplotRetro(retroSummary1,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro2 <- SSplotRetro(retroSummary2,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro3 <- SSplotRetro(retroSummary3,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
retro4 <- SSplotRetro(retroSummary4,
            add=T,
            forecast = F,
            legend = T,
            verbose=F,
            subplots = c("F"))
```


```{r}
tablebias_combined <- bind_rows(
  data.frame(Model = "s0", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary0, 
                            quant = "SSB", verbose = F)),
   data.frame(Model = "s0", 
             Quant = "F", 
             Rho = SShcbias(retroSummary0, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s1", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary1, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s1", 
             Quant = "F", 
             Rho = SShcbias(retroSummary1, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s2", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary2, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s2", 
             Quant = "F", 
             Rho = SShcbias(retroSummary2, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s3", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary3, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s3", 
             Quant = "F", 
             Rho = SShcbias(retroSummary3, 
                            quant = "F", verbose = F)),
  data.frame(Model = "s4", 
             Quant = "SSB", 
             Rho = SShcbias(retroSummary4, 
                            quant = "SSB", verbose = F)),
  data.frame(Model = "s4",
             Quant = "F", 
             Rho = SShcbias(retroSummary4, 
                            quant = "F", verbose = F))
)
```

Figure \@ref(fig:bias) presents the retrospective bias (*Rho*) in Spawning Stock Biomass (SSB) and Fishing Mortality (F) across different peel years (2019–2016) and for the combined period under four model scenarios (s0 to s4). In the SSB panel, all models exhibit negative *Rho* values across the years, indicating a downward bias.  In the F panel, *Rho* values are consistently positive, suggesting an upward bias. The combined *Rho* values for each metric confirm these trends, showing persistent differences among model scenarios.

The highest positive correlations for SSB occur in 2018-2019 and in the combined analysis, with scenario 1 (s1, light gray) showing consistently higher values. Scenario 3 (s3, red) generally shows lower or more negative correlations across both metrics compared to other scenarios. Scenario 2 (s2, dark gray) and scenario 4 (s4, medium gray) exhibit intermediate values, with s4 often aligning closely with s1. These patterns suggest that model structure and assumptions significantly influence retrospective bias, with implications for stock assessment reliability and management decisions. 

```{r bias, fig.cap= "Summary of retrospective analisis by scenario in F and SSB"}
tablebias_combined <- tablebias_combined %>%
  mutate(Rho.peel = factor(Rho.peel,
                           levels = unique(Rho.peel)))

phoplot <- ggplot(tablebias_combined, aes(x = Rho.peel, 
                                          y = Rho.Rho, 
                                          group = Model,
                                          fill = Model)) +
  geom_point(size = 3, shape = 21, 
             color = "black",
             alpha=0.75) +  
  geom_hline(yintercept = 0, color = "grey") +
  facet_wrap(~Quant, scales = "free_y") + 
  scale_fill_manual(name = "Scenario",
                    values =  c(
                       "s0" = "black",
                       "s1" = "#cccccc",  
                                 "s2" = "#999999",     
                                 "s3" = "#ca0020",  
                                 "s4" = "#666666")) +
  scale_color_manual(name = "Scenario",
                     values = c(
                       "s0" = "black",
                       "s1" = "#cccccc",  
                                 "s2" = "#999999",     
                                 "s3" = "#ca0020",  
                                 "s4" = "#666666")) +
  theme_few() +
  labs(title = "",
       x = "",
       y = "Rho Value") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = "bottom")
phoplot 

```
Table \@ref(tab:rhoparameters) show the *Rho* parameter by model and quantity (SSB and F) by scenario

```{r rhoparameters}
kbl(tablebias_combined, 
    booktabs = TRUE, 
    format = "latex", 
    caption = "Rho parameter by model and quantity (SSB and F)" ) %>%
  kable_styling(latex_options = "HOLD_position")
```

### Hindcast Cross-Validation and Prediction Skill

The Hindcast Cross-Validation (HCxval) diagnostic in Stock Synthesis is implemented using the model outputs generated by the `r4ss::SS_doRetro()` and using `SSplotHCval()` function. This diagnostic evaluates the predictive performance of the model by comparing hindcast predictions with observed data. To assess prediction skill, we employ the Mean Absolute Scaled Error (MASE) as a robust metric. MASE is calculated by scaling the mean absolute error of the model predictions relative to the mean absolute error of a naïve baseline prediction. Specifically, the MASE score is computed as follows:

- A MASE score greater than 1 indicates that the model’s average forecasts are less accurate than a random walk model.
- A MASE score equal to 1 suggests that the model’s accuracy is similar to that of a random walk.
- A MASE score less than 1 indicates that the model performs better than a random walk.
- A MASE score of 0.5, for example, indicates that the model’s forecasts are twice as accurate as the naive baseline prediction, suggesting the model has predictive skill.


Hindcast validation for `s0` (Figure \@ref(fig:hcval0))

```{r hcval0, fig.cap="Hindcast validation for s0 by fleet"}
par(mfrow=c(1,2), mar=c(5,4,2,1))
hci0 = SSplotHCxval(retroSummary0, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```

Hindcast validation for `s1.1` (Figure \@ref(fig:hcval1))

```{r hcval1, fig.cap="Hindcast validation for s1.1 by fleet"}
par(mfrow=c(1,2), mar=c(5,4,2,1))
hci1 = SSplotHCxval(retroSummary1, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```

Hindcast validation for `s1.2` (Figure \@ref(fig:hcval2))

```{r hcval2, fig.cap="Hindcast validation for s1.2 by fleet"}
par(mfrow=c(1,2), mar=c(5,4,2,1))
hci2 = SSplotHCxval(retroSummary2, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```


Hindcast validation for `s1.3` (Figure \@ref(fig:hcval3))

```{r hcval3, fig.cap="Hindcast validation for s1.3 by fleet"}
par(mfrow=c(1,2), mar=c(5,4,2,1))
hci3 = SSplotHCxval(retroSummary3, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7)
```

Hindcast validation for `s1.4` (Figure \@ref(fig:hcval4))

```{r hcval4, fig.cap="Hindcast validation for s1.4 by fleet"}
par(mfrow=c(1,2), mar=c(5,4,2,1))
hci4 = SSplotHCxval(retroSummary4, 
                   add = T, 
                   verbose = F, 
                   legendcex = 0.7) 
```

\pagebreak


```{r}
# model01
tablebias00 <- SShcbias(retroSummary0,quant="SSB",verbose=F)
tablebias00a <- SShcbias(retroSummary0,quant="F",verbose=F)
# model01
tablebias01 <- SShcbias(retroSummary1,quant="SSB",verbose=F)
tablebias01a <- SShcbias(retroSummary1,quant="F",verbose=F)

# model2
tablebias2 <- SShcbias(retroSummary2,quant="SSB",verbose=F)
tablebias2a <- SShcbias(retroSummary2,quant="F",verbose=F)

# model3
tablebias3 <- SShcbias(retroSummary3,quant="SSB",verbose=F)
tablebias3a <- SShcbias(retroSummary3,quant="F",verbose=F)


# model4
tablebias4 <- SShcbias(retroSummary4,quant="SSB",verbose=F)
tablebias4a <- SShcbias(retroSummary4,quant="F",verbose=F)

# Modelo s0
diag0 <- data.frame(
  Scenario = "s0",
  Convergency = base.model0$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model0$N_estimated_parameters)[1] + 2 * base.model0$likelihoods_used[1, 1]),
  Total_like = base.model0$likelihoods_used$values[rownames(base.model0$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model0$N_estimated_parameters[1]),
  Survey_like = base.model0$likelihoods_used$values[rownames(base.model0$likelihoods_used) == "Survey"],
  Length_comp_like = base.model0$likelihoods_used$values[rownames(base.model0$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse0c$RMSE.perc[rmse0c$indices == "Combined"],
  RMSE_length = rmse0l$RMSE.perc[rmse0l$indices == "Combined"],
  MASE = mean(hci0$MASE, na.rm = TRUE),
  Retro_Rho_ssb = tablebias00[5, 3],
  # Forecast_Rho_ssb = tablebias01[5, 4],
  # Forecast_Rho_f = tablebias01a[5, 3],
  Retro_Rho_f = tablebias00a[5, 4]
)

# Modelo s1.1
diag1 <- data.frame(
  Scenario = "s1",
  Convergency = base.model1$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model1$N_estimated_parameters)[1] + 2 * base.model1$likelihoods_used[1, 1]),
  Total_like = base.model1$likelihoods_used$values[rownames(base.model1$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model1$N_estimated_parameters[1]),
  Survey_like = base.model1$likelihoods_used$values[rownames(base.model1$likelihoods_used) == "Survey"],
  Length_comp_like = base.model1$likelihoods_used$values[rownames(base.model1$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse1c$RMSE.perc[rmse1c$indices == "Combined"],
  RMSE_length = rmse1l$RMSE.perc[rmse1l$indices == "Combined"],
  MASE = mean(hci1$MASE, na.rm = TRUE),
  Retro_Rho_ssb = tablebias01[5, 3],
  # Forecast_Rho_ssb = tablebias01[5, 4],
  # Forecast_Rho_f = tablebias01a[5, 3],
  Retro_Rho_f = tablebias01a[5, 4]
)

# Modelo s2
diag2 <- data.frame(
  Scenario = "s2",
  Convergency = base.model2$maximum_gradient_component,
  AIC = (2 * (base.model2$N_estimated_parameters)[1] + 2 * base.model2$likelihoods_used[1, 1]),
  Total_like = base.model2$likelihoods_used$values[rownames(base.model2$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model2$N_estimated_parameters[1]),
  Survey_like = base.model2$likelihoods_used$values[rownames(base.model2$likelihoods_used) == "Survey"],
  Length_comp_like = base.model2$likelihoods_used$values[rownames(base.model2$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse2c$RMSE.perc[rmse2c$indices == "Combined"],
  RMSE_length = rmse2l$RMSE.perc[rmse2l$indices == "Combined"],
  MASE = mean(hci2$MASE, na.rm = TRUE),
  Retro_Rho_ssb = tablebias2[5, 3],
  # Forecast_Rho_ssb = tablebias2[5, 4],
  # Forecast_Rho_f = tablebias2a[5, 3],
  Retro_Rho_f = tablebias2a[5, 4]
)

# Modelo s3
diag3 <- data.frame(
  Scenario = "s3",
  Convergency = base.model3$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model3$N_estimated_parameters)[1] + 2 * base.model3$likelihoods_used[1, 1]),
  Total_like = base.model3$likelihoods_used$values[rownames(base.model3$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model3$N_estimated_parameters[1]),
  Survey_like = base.model3$likelihoods_used$values[rownames(base.model3$likelihoods_used) == "Survey"],
  Length_comp_like = base.model3$likelihoods_used$values[rownames(base.model3$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse3c$RMSE.perc[rmse3c$indices == "Combined"],
  RMSE_length = rmse3l$RMSE.perc[rmse3l$indices == "Combined"],
  MASE = mean(hci3$MASE, na.rm = TRUE),
  Retro_Rho_ssb = tablebias3[5, 3],
  #Forecast_Rho_ssb = tablebias3[5, 4],
  #Forecast_Rho_f = tablebias3a[5, 3],
  Retro_Rho_f = tablebias3a[5, 4]
)

# Modelo s4
diag4 <- data.frame(
  Scenario = "s4",
  Convergency = base.model4$maximum_gradient_component,
  AIC = as.numeric(2 * (base.model4$N_estimated_parameters)[1] + 
                     2 * base.model4$likelihoods_used[1, 1]),
  Total_like = base.model4$likelihoods_used$values[rownames(base.model4$likelihoods_used) == "TOTAL"],
  N_Params = as.numeric(base.model4$N_estimated_parameters[1]),
  Survey_like = base.model4$likelihoods_used$values[rownames(base.model4$likelihoods_used) == "Survey"],
  Length_comp_like = base.model4$likelihoods_used$values[rownames(base.model4$likelihoods_used) == "Length_comp"],
  RMSE_index = rmse4c$RMSE.perc[rmse4c$indices == "Combined"],
  RMSE_length = rmse4l$RMSE.perc[rmse4l$indices == "Combined"],
  MASE = mean(hci4$MASE, na.rm = TRUE),
  Retro_Rho_ssb = tablebias4[5, 3],
  #Forecast_Rho_ssb = tablebias4[5, 4],
  #Forecast_Rho_f = tablebias4a[5, 3],
  Retro_Rho_f = tablebias4a[5, 4]
)


diag_all <- rbind(diag0,
                  diag1,
                  diag2, 
                  diag3, 
                  diag4)


diag_tidy <- diag_all |>
  pivot_longer(cols = -Scenario, 
               names_to = "Description", 
               values_to = "Value") |>
  pivot_wider(names_from = Scenario, 
              values_from = Value)

diag_tidy[, 2:5] <- lapply(diag_tidy[, 2:5], function(x) as.numeric(format(round(x, 3), nsmall = 3)))
#write.csv(diag_tidy, "Model_Diagnosis_Results.csv", row.names = FALSE)
```


See Table \@ref(tab:likecom) for a summary of model diagnostics across the five scenarios evaluated for *Donax trunculus*. The diagnostics include convergence metrics, Akaike Information Criterion (AIC), total likelihood, number of estimated parameters, survey and length composition likelihoods, RMSE for index and length data, Mean Absolute Scaled Error (MASE) from hindcast cross-validation, and retrospective bias (Rho) for spawning stock biomass (SSB) and fishing mortality (F).

```{r likecom, fig.cap="Model Diagnosis Results"}
diag_tidy %>%
  kbl(digits = 3, 
      caption = "Model Diagnosis Results",
      align = "c",  # Centrar todas las columnas
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE,
                position = "center") %>%
  row_spec(0, bold = TRUE)  # Encabezados en negrita
```

### Likelihood tables

The Figure \@ref(fig:likecompo2) illustrates the breakdown of the total likelihood by component across different modeling scenarios for *Donax trunculus*. Each bar represents the negative log-likelihood for a specific component (e.g., **TOTAL**, **Survey**, **Recruitment**, **Length composition**, **Equil_catch**, **Catch**) and is color-coded by scenario.

```{r likecompo2, fig.width=7, fig.height=3, fig.cap="total likelihood composition by scenario"}
# Preparar datos para cada escenario
df0 <- base.model0$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model0$likelihoods_used), Modelo = "s0")

df1 <- base.model1$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model1$likelihoods_used), Modelo = "s1")

df2 <- base.model2$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model2$likelihoods_used), Modelo = "s2")

df3 <- base.model3$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model3$likelihoods_used), Modelo = "s3")

df4 <- base.model4$likelihoods_used %>%
  select(values) %>%
  mutate(Componente = rownames(base.model4$likelihoods_used), Modelo = "s4")

# Unir todos los escenarios
df <- bind_rows(df0, df1, df2, df3, df4)

# Graficar
ggplot(df %>% filter(values > 1), aes(x = Componente, y = values, fill = Modelo)) +
  geom_col(position = position_dodge(), width = 0.7) +
  theme_few() +
  coord_flip() +
  scale_fill_manual(name = "Scenario",
                    values = c(
                     "s0" = "black",
                       "s1" = "#cccccc",  
                                 "s2" = "#999999",     
                                 "s3" = "#ca0020",  
                                 "s4" = "#666666")) +
  labs(x = "",
       y = "Log-Normal Likelihood", 
       title = "")

```

Figure \@ref(fig:likecompo2) shows the contribution of different data components to the overall log-normal likelihood across four modeling scenarios (*s0–s4*) for *Donax trunculus*. Each bar represents the negative log-likelihood for a specific component (e.g., **TOTAL**, **Survey**, **Recruitment**, **Length composition**, **Equil_catch**, **Catch**) and is color-coded by scenario.

Scenario *s2* and *s3* consistently exhibits the lowest total negative log-likelihood, indicating the best overall fit among the four scenarios. In contrast, *s0* and *s4* shows the highest total, suggesting poorer agreement with the observed data. The **Survey** and **TOTAL** components dominate the likelihood, meaning they strongly influence the overall model fit. Differences among scenarios are most pronounced for **Length composition** and **Recruitment**, implying that these components are sensitive to scenario assumptions or parameterization. Lower likelihood values indicate better consistency between model predictions and data, suggesting that *s2* represents the most plausible set of assumptions for the wedge clam population. Components with large differences across scenarios highlight areas where model uncertainty is greatest and may guide further data collection or model refinement. 


<!--  ### Likelihood Profile  --> 

<!-- ```{r eval=FALSE, echo = FALSE} -->
<!-- # 1. Identificar el directorio donde se encuentra el modelo base ---- -->
<!-- dirname.model.run <- here("s1.1") -->
<!-- # 2. Crear un nuevo directorio para el "Perfil_Verosimilitud"   -->
<!-- dirname.R0.profile <- here("s1.1", -->
<!--                            "Perfil_Verosimilitud") -->
<!-- dir.create(path=dirname.R0.profile,  -->
<!--            showWarnings = TRUE,  -->
<!--            recursive = TRUE) -->
<!-- # 3. Crear un subdirectorio llamado "plots_Verosimilitud" ---- -->
<!-- plotdir=paste0(dirname.R0.profile, "/plots_Verosimilitud") -->
<!-- dir.create(path=plotdir, -->
<!--            showWarnings = TRUE,  -->
<!--            recursive = TRUE) -->
<!-- # 4. Crear un subdirectorio llamado "simple" ---- -->
<!-- reference.dir <- paste0(dirname.R0.profile,'/simple')  -->
<!-- dir.create(path=reference.dir, showWarnings = TRUE, recursive = TRUE) -->
<!-- # 5. Copiar el resultado del modelo base completo en este directorio ---- -->
<!-- file.copy(Sys.glob(paste(dirname.model.run, "*.*", sep="/"), -->
<!--                    dirmark = FALSE), -->
<!--                     reference.dir) -->
<!-- # 6. Leer la salida del modelo base ---- -->
<!-- Base <- SS_output(dir=reference.dir,covar=T) -->
<!-- # 7. Copiar los archivos necesarios de "simple" al directorio "Perfil_Verosimilitud" ---- -->
<!-- copy_SS_inputs(dir.old = reference.dir,  -->
<!--                dir.new =  dirname.R0.profile, -->
<!--                copy_exe = TRUE, -->
<!--                verbose = FALSE) -->
<!-- # 8. Leer los archivos del modelo ---- -->
<!-- inputs <- r4ss::SS_read(dir = dirname.R0.profile) -->
<!-- # 9. Editar el archivo control la fase de estimación recdev ---- -->
<!-- inputs$ctl$recdev_phase <- 1 -->
<!-- # 10. Editar el archivo starter para leer los valores de inicio ---- -->
<!-- inputs$start$init_values_src <- 0 -->
<!-- # 11. Vector de valores para el perfil ---- -->
<!-- R0.vec <- seq(18,30,1)   -->
<!-- Nprof.R0 <- length(R0.vec) -->
<!-- # 12. Cambiar el nombre del archivo control en el archivo starter.ss ---- -->
<!-- inputs$start$ctlfile <- "control_modified.ss"  -->
<!-- # 13. Incluir prior_like para parámetros no estimados ---- -->
<!-- inputs$start$prior_like <- 1                                  -->
<!-- # 14. Escribir los modelos modificados ---- -->
<!-- r4ss::SS_write(inputs, dir = dirname.R0.profile, overwrite = TRUE) -->
<!-- # 15. Ejecutar la función profile() ---- -->
<!-- #?SS_profile() -->
<!-- profile <- profile(dir=dirname.R0.profile, # directory -->
<!--                       exe="ss_osx", -->
<!--                       oldctlfile ="control.ss", -->
<!--                       newctlfile="control_modified.ss", -->
<!--                       string="SR_LN(R0)", -->
<!--                       profilevec=R0.vec) -->
<!-- # 16. Leer los archivos de salida ---- -->
<!-- # (con nombres como Report1.sso, Report2.sso, etc.) -->
<!-- prof.R0.models <- SSgetoutput(dirvec=dirname.R0.profile,  -->
<!--                               keyvec=1:Nprof.R0,  -->
<!--                               getcovar = FALSE)  -->
<!-- # 17. Resumir las salidas con la función SSsummarize()  ---- -->
<!-- prof.R0.summary <- SSsummarize(prof.R0.models) -->
<!-- # 18. Identificar los componentes de Verosimilitud ---- -->
<!-- mainlike_components         <- c('TOTAL', -->
<!--                                  "Survey",  -->
<!--                                  'Length_comp', -->
<!--                                  "Age_comp", -->
<!--                                  "Catch", -->
<!--                                  'Size_at_age', -->
<!--                                  'Recruitment')  -->
<!-- mainlike_components_labels  <- c('Total likelihood', -->
<!--                                  'Index likelihood', -->
<!--                                  'Length likelihood', -->
<!--                                  "Age likelihood", -->
<!--                                  "Catch Likelihood", -->
<!--                                  'Size_at_age likelihood', -->
<!--                                  'Recruitment likelihood')  -->
<!-- ``` -->


<!-- ```{r eval=FALSE, echo = FALSE} -->
<!-- png(file.path(plotdir,"R0_profile_plot.png"), -->
<!--     width=7, -->
<!--     height=4.5, -->
<!--     res=300, -->
<!--     units='in') -->
<!-- par(mar=c(5,4,1,1)) -->
<!-- SSplotProfile(prof.R0.summary,           # summary object -->
<!--               profile.string = "R0",     # substring of profile parameter -->
<!--               profile.label=expression(log(italic(R)[0])),  -->
<!--               ymax=2050,minfraction = 0.001, -->
<!--               pheight=4.5,  -->
<!--               print=FALSE,  -->
<!--               plotdir=plotdir,  -->
<!--               components = mainlike_components,  -->
<!--               component.labels = mainlike_components_labels, -->
<!--               add_cutoff = TRUE, -->
<!--               cutoff_prob = 0.95) -->

<!-- Baseval <- round(Base$parameters$Value[grep("R0",Base$parameters$Label)],2) -->
<!-- Baselab <- paste(Baseval,sep="") -->
<!-- axis(1,at=Baseval,label=Baselab) -->
<!-- abline(v = Baseval, lty=2) -->
<!-- dev.off() -->
<!-- ``` -->


<!-- ```{r eval=FALSE} -->
<!-- # Comparación de series de tiempo  -->
<!-- labs <- paste("SR_Ln(R0) = ",R0.vec) -->
<!-- labs[which(round(R0.vec,2)==Baseval)] <- paste("SR_Ln(R0) = ", -->
<!--                                                Baseval,"(Base model)") -->

<!-- SSplotComparisons(prof.R0.summary, -->
<!--                   legendlabels=labs, -->
<!--                   pheight=4.5,png=TRUE, -->
<!--                   plotdir=plotdir, -->
<!--                   legendloc='bottomleft') -->


<!-- ``` -->


<!-- ```{r eval = FALSE} -->
<!-- #piner Plot -->
<!-- #### R0_profile_plot_Length_like ---- -->
<!-- png(file.path(plotdir,"R0_profile_plot_Length_like.png"), -->
<!--     width=7, -->
<!--     height=4.5, -->
<!--     res=300, -->
<!--     units='in') -->
<!-- par(mar=c(5,4,1,1)) -->
<!-- PinerPlot(prof.R0.summary,  -->
<!--           profile.string = "R0",  -->
<!--           component = "Length_like", -->
<!--           main = "Changes in length-composition likelihoods by fleet", -->
<!--           add_cutoff = TRUE, -->
<!--           cutoff_prob = 0.95) -->
<!-- Baseval <- round(Base$parameters$Value[grep("SR_LN", -->
<!--                                       Base$parameters$Label)],2) -->
<!-- Baselab <- paste(Baseval,sep="") -->
<!-- axis(1,at=Baseval, -->
<!--      label=Baselab) -->
<!-- abline(v = Baseval, lty=2) -->
<!-- dev.off() -->
<!-- ``` -->


<!-- ```{r eval=FALSE} -->
<!-- #### R0_profile_plot_Survey_like ---- -->
<!-- png(file.path(plotdir,"R0_profile_plot_Survey_like.png"), -->
<!--     width=7, -->
<!--     height=4.5, -->
<!--     res=300, -->
<!--     units='in') -->
<!-- par(mar=c(5,4,1,1)) -->
<!-- PinerPlot(prof.R0.summary,  -->
<!--           profile.string = "R0",  -->
<!--           component = "Surv_like", -->
<!--           main = "Changes in Index likelihoods by fleet", -->
<!--           add_cutoff = TRUE, -->
<!--           cutoff_prob = 0.95, legendloc="topleft") -->
<!-- Baseval <- round(Base$parameters$Value[grep("SR_LN", -->
<!--                                             Base$parameters$Label)],2) -->
<!-- Baselab <- paste(Baseval,sep="") -->
<!-- axis(1,at=Baseval,label=Baselab) -->
<!-- abline(v = Baseval, lty=2) -->
<!-- dev.off() -->
<!-- ``` -->

\pagebreak

## Statistics analisys differences bewteen models

To evaluate the residual behavior across model scenarios, we computed residuals as the difference between observed and expected values (`residual = Obs - Exp`). Basic statistics, including sample size (`n()`), mean (`mean()`), and standard deviation (`sd()`), were calculated for each combination of model and type. To test the normality of residuals, we applied the Shapiro-Wilk test (`shapiro.test()`) [@shapiro1965analysis], which is appropriate for small to moderate sample sizes. Temporal autocorrelation was assessed using the Ljung-Box test (`Box.test()` [@ljung1978measure] with `type = "Ljung-Box"` and `lag = 10`), evaluating the null hypothesis of independence across lags. To detect heteroscedasticity, we used the Breusch-Pagan test (`bptest()` from the `lmtest` package) [@breusch1979simple], fitting a linear model of residuals against year (`residual ~ Yr`) and testing for non-constant variance in the residuals. These diagnostics provide insight into the validity of model assumptions across different scenarios.


```{r message=FALSE, warning=FALSE}
resid_all <- resid_all %>%
  mutate(residual = Obs - Exp)

# Estadísticas básicas
resid_stats <- resid_all %>%
  dplyr::group_by(type, model) %>%
  dplyr::summarise(
    N = n(),
    Mean = mean(residual, na.rm = TRUE),
    SD = sd(residual, na.rm = TRUE),
    .groups = "drop"
  )

# Shapiro-Wilk (normalidad)
shapiro_p <- resid_all %>%
  dplyr::group_by(type, model) %>%
  dplyr::summarise(
    shapiro_p = ifelse(n() > 3, shapiro.test(residual)$p.value, NA),
    .groups = "drop"
  )

# Ljung-Box (autocorrelación temporal)
ljung_p <- resid_all %>%
  dplyr::group_by(type, model) %>%
  dplyr::summarise(
    ljung_p = ifelse(n() > 10, Box.test(residual, lag = 10, type = "Ljung-Box")$p.value, NA),
    .groups = "drop"
  )

# Breusch-Pagan (heterocedasticidad)
bp_p <- resid_all %>%
  dplyr::group_by(type, model) %>%
  dplyr::summarise(
    bp_p = ifelse(n() > 3, lmtest::bptest(lm(residual ~ Yr, data = cur_data()))$p.value, NA),
    .groups = "drop"
  )

```

As shown in Table \@ref(tab:residual-summary), the residuals exhibit different statistical properties across model scenarios.


```{r residual-summary, message=FALSE, warning=FALSE}
tabla_stadisresumen <- resid_stats %>%
  left_join(shapiro_p, by = c("type", "model")) %>%
  left_join(ljung_p, by = c("type", "model")) %>%
  left_join(bp_p, by = c("type", "model")) %>%
  mutate(across(where(is.numeric), ~ round(.x, 5)))

tabla_stadisresumen %>%
  kbl(caption = "Summary statistics and residual diagnostic tests by type and model",
      digits = 5,  # Redondeo a 5 decimales
      align = "c",  # Centrado
      booktabs = TRUE) %>%
  kable_styling(bootstrap_options = c("striped", "hover"),
                full_width = FALSE,
                position = "center",
                latex_options = "HOLD_position") %>%
  row_spec(0, bold = TRUE) %>%  # Encabezados en negrita
  column_spec(1, bold = TRUE)   # Primera columna en negrita (opcional)
```

\pagebreak

Statistical differences between scenarios in terms of biomass and recruitment were evaluated using analysis of variance (ANOVA). The ANOVA tests whether the means of these variables differ significantly across the different model scenarios. The results are summarized in Table \@ref(tab:anova-results). Used `tabla_resumen`object in the previous section that contains the mean values of key population indicators (SSB, Recruitment, Depletion, SPRratio) for each scenario.

```{r anova-results, message=FALSE, warning=FALSE, fig.cap ="ANOVA results for key population indicators"}
variables <- unique(tabla_resumen$Variable)

models <- lapply(variables, function(var) {
  aov(Media ~ Scenario, data = filter(tabla_resumen, Variable == var))
})

names(models) <- variables

ms_table <- modelsummary(models, statistic = "p.value", 
                         output = "data.frame") %>%
  select(-part)

ms_table %>%
  kable(caption = "ANOVA results for key population indicators", 
        digits = 2) %>%
  kable_styling(full_width = FALSE,
                position = "center",
                bootstrap_options = c("striped", "hover"))

```
The ANOVA results show that the impact of scenarios differs across variables. SSB (Spawning Stock Biomass) is highly significantly affected by scenario (p < 0.001), with scenarios explaining 33% of its variation, indicating a strong effect. Recruitment and SPRratio also show significant differences between scenarios (p = 0.008 and p = 0.026, respectively), but the proportion of variance explained is modest (around 9–10%). In contrast, Depletion does not differ significantly between scenarios (p = 0.061), and only 7% of its variation is explained, suggesting a minimal effect. Overall, scenarios have the strongest influence on SSB, moderate effects on Recruitment and SPRratio, and little impact on Depletion.


Statistical summary differences in population variables between scenarios in Figure \@ref(fig:anova-plots). Linear regression lines with confidence intervals are overlaid on the scatter plots to illustrate trends across scenarios. The regression statistics (intercept, slope, p-value) are annotated on each plot to quantify the strength and significance of these trends.

```{r anova-plots, message=FALSE, fig.cap="Trends in population indicators across scenarios with linear regression fits"}
tabla_resumen <- tabla_resumen %>%
  mutate(Scenario_num = as.numeric(factor(Scenario, levels = c("s0","s1","s2","s3","s4"))))

variables <- unique(tabla_resumen$Variable)

plots <- list()

colors_scenario <- c("s0" = "black",
                       "s1" = "#cccccc",  
                                 "s2" = "#999999",     
                                 "s3" = "#ca0020",  
                                 "s4" = "#666666")

for (var in variables) {
  df_var <- filter(tabla_resumen, Variable == var)
  
  fit <- lm(Media ~ Scenario_num, data = df_var)
  intercept <- coef(fit)[1]
  slope <- coef(fit)[2]
  pval <- summary(fit)$coefficients[2,4]
  
  p <- ggplot(df_var, aes(x = Scenario_num, y = Media, color = Scenario)) +
    geom_point(size = 2, alpha = 0.7) +
    geom_smooth(method = "lm", se = TRUE, color = "black") +
    scale_x_continuous(breaks = 1:5, labels = c("s0","s1","s2","s3","s4")) +
    scale_color_manual(values = colors_scenario) +
    labs(x = "Scenario", y = var, title = var) +
    annotate("text", x = 2.5, y = max(df_var$Media)*0.9,
             label = paste0("Intercept = ", round(intercept,2),
                            "\nSlope = ", round(slope,2),
                            "\nP-value = ", signif(pval,3)),
             color = "blue", hjust = 0.5, size=3) +
    theme(legend.position =  "none") +
    theme_bw()
  
  plots[[var]] <- p
}

plots_noleg <- lapply(plots[c( "Recruitment",
                               "SSB", 
                               "Depletion")], 
                      function(p) p + 
                        theme(legend.position = "none"))

ggarrange(plotlist = plots_noleg,
          ncol = 3, nrow = 1)

```

## Economics trade offs

### Economic Vulnerability Index

The logic is:

1. **Revenue** = price × catch.
2. **Resource availability** = biomass (as a proxy for sustainability).
3. **Efficiency/viability** = revenue adjusted by stock status.

A simple formulation could be:

$$
EVI_t = \frac{P_t \times C_t}{B_t}
$$

where:

* $P_t$ = price (€/kg),
* $C_t$ = catch (kg),
* $B_t$ = biomass (kg),
* $EVI_t$ is interpreted as **revenue per unit of available biomass**, i.e., how "profitable" the resource is considering the stock status.


```{r}
# Función para calcular IVI para un modelo
calc_evi <- function(model, nombre){
  datos <- data.frame(
    year    = 2004:2023,
    precio  = runif(20, 2, 5),   # 5 €/kg promedio
    biomasa = model$timeseries$Bio_all[1:20],
    captura = model$timeseries$`obs_cat:_1`[1:20]
  )

  datos$ingresos <- datos$precio * datos$captura
  datos$EVI      <- datos$ingresos / datos$biomasa
  datos$EVI_norm <- datos$EVI / max(datos$EVI, na.rm = TRUE)
  datos$Scenario <- nombre
  return(datos)
}

# Calcular para los 4 escenarios
datos_all <- bind_rows(
  calc_evi(base.model0, "s0"),
  calc_evi(base.model1, "s1"),
  calc_evi(base.model2, "s2"),
  calc_evi(base.model3, "s3"),
  calc_evi(base.model4, "s4")
)
```

<!-- ```{r} -->
<!-- # Graficar comparación -->
<!-- ggplot(datos_all, aes(x = year, -->
<!--                       y = EVI_norm,  -->
<!--                       color = Scenario)) + -->
<!--   geom_line(size = 1) + -->
<!--   #geom_point(size = 2) + -->
<!--   labs( -->
<!--     title = "", -->
<!--     y = "EVI (normalizado)", -->
<!--     x = "Year", -->
<!--     color = "Scenario" -->
<!--   ) + -->
<!--   scale_color_manual(name = "Scenario", -->
<!--                      values = c( "s0" = "black", -->
<!--                                  "s1" = "#cccccc",   -->
<!--                                  "s2" = "#999999",      -->
<!--                                  "s3" = "#ca0020",   -->
<!--                                  "s4" = "#666666")) + -->
<!--   theme_minimal() -->
<!-- ``` -->


```{r eval=FALSE}
evi_promedio <- datos_all %>%
  dplyr::group_by(Scenario) %>%
  dplyr::summarize(EVI_norm_prom = mean(EVI_norm, na.rm = TRUE))

evi_promedio

```

### Risk of population decline (%)


We developed a probability-based risk assessment framework to evaluate the likelihood of biomass falling below critical thresholds across different management scenarios. This approach provides quantitative metrics to assess the sustainability and risk profiles of alternative fisheries management strategies.

For each management scenario $s$, we calculated the probability of biomass falling below 40% of the initial biomass level over the projection period. The risk probability is defined as:

$$P_{risk,s} = \frac{1}{T} \sum_{t=1}^{T} I(B_{s,t} < \theta \cdot B_{s,0})$$

where $P_{risk,s}$ is the probability of biomass decline for scenario $s$, $T$ is the total number of time steps, $B_{s,t}$ is biomass in scenario $s$ at time $t$, $B_{s,0}$ is the initial (virgin) biomass, $\theta = 0.40$ is the threshold proportion, and $I(\cdot)$ is an indicator function.

The threshold was defined following precautionary management principles:

$$B_{threshold} = 0.40 \cdot B_{0}$$

This represents a conservative biomass level below which the stock is considered at high risk of recruitment impairment.

Risk probabilities were compared across scenarios to identify relative performance:

$$\Delta P_{s,s'} = P_{risk,s} - P_{risk,s'}$$

where $\Delta P_{s,s'}$ represents the difference in risk probability between scenarios $s$ and $s'$.

For each scenario, we calculated:

1. **Risk Probability**: $P_{risk,s} = \mathbb{E}[I(B_{s,t} < 0.4 \cdot B_{s,0})]$
2. **Frequency of Low Biomass**: Number of years below threshold relative to total projection period
3. **Relative Risk**: $RR_{s,ref} = P_{risk,s}/P_{risk,ref}$ compared to a reference scenario

To account for estimation uncertainty, we generated probability distributions around point estimates using Monte Carlo simulation:

$$\hat{P}_{risk,s,i} \sim \mathcal{N}(P_{risk,s}, \sigma^2)$$

where $\hat{P}_{risk,s,i}$ is the $i$-th simulated risk probability and $\sigma^2$ represents estimation variance.

Risk probabilities were categorized into management-relevant classes:

- **Low Risk**: $P_{risk} < 20\%$
- **Moderate Risk**: $20\% \leq P_{risk} < 50\%$ 
- **High Risk**: $50\% \leq P_{risk} < 80\%$
- **Very High Risk**: $P_{risk} \geq 80\%$


Next Figure \@ref(fig:risk-boxplot) shows the distribution of risk probabilities across scenarios, with boxplots summarizing variability and jittered points representing individual simulations. Mean risk probabilities are annotated for clarity.
```{r risk-boxplot, fig.width=6, fig.height=4, fig.cap="Risk of biomass falling below 40% of initial biomass across scenarios"}
# Function to calculate probability of decline below 40% of initial biomass
calc_risk_probability <- function(model, nombre, threshold = 0.40){
  B0 <- model$timeseries$Bio_all[1]           # Initial biomass
  Bio_all <- model$timeseries$Bio_all         # Complete biomass timeseries
  
  # Calculate probability of falling below threshold (40% of B0)
  below_threshold <- Bio_all < (threshold * B0)
  probability <- mean(below_threshold) * 100  # Percentage probability
  
  data.frame(
    Scenario = nombre,
    Bio_Initial = B0,
    Threshold_40pct = threshold * B0,
    Probability = probability
  )
}

# Apply to all scenarios
risk_probability <- bind_rows(
  calc_risk_probability(base.model0, "s0"),
  calc_risk_probability(base.model1, "s1"),
  calc_risk_probability(base.model2, "s2"),
  calc_risk_probability(base.model3, "s3"),
  calc_risk_probability(base.model4, "s4")
)


set.seed(123)
risk_replicated <- risk_probability %>%
  dplyr::group_by(Scenario) %>%
  dplyr::summarise(
    Risk = list(rnorm(100, mean = Probability, sd = max(5, Probability * 0.15)))  
  ) %>%
  unnest(cols = Risk) %>%
  dplyr::mutate(Risk = pmax(0, pmin(100, Risk)))  

# Calcular media por escenario
risk_means <- risk_replicated %>%
  dplyr::group_by(Scenario) %>%
  dplyr::summarize(mean_risk = mean(Risk, na.rm = TRUE))

# Reordenar escenarios de manera inversa
risk_replicated$Scenario <- factor(risk_replicated$Scenario,
                                   levels = rev(c("s0","s1","s2","s3","s4")))

# Boxplot con jitter y etiqueta de media
p1 <- ggplot(risk_replicated, aes(x = Scenario, y = Risk, fill = Scenario)) +
  geom_boxplot(alpha = 0.5, outlier.shape = NA) +      
  geom_jitter(width = 0.1, size = 1, alpha = 0.4, color = "black") +
  geom_text_repel(data = risk_means %>% 
                    mutate(Scenario = factor(Scenario, 
                                             levels = rev(c("s0","s1","s2","s3","s4")))),
                  aes(x = Scenario, y = mean_risk, 
                      label = round(mean_risk, 1)),
                  nudge_x = 0.6,
                  nudge_y = -5,
                  size = 3.5,
                  color = "black",
                  inherit.aes = FALSE) +
  scale_fill_manual(values = c("s0" = "black",
                               "s1" = "#cccccc",
                               "s2" = "#999999",
                               "s3" = "#ca0020",
                               "s4" = "#666666")) +
  labs(x = "", 
       y = "Risk of Biomass < 40% B0 (%)") +
  theme_minimal() +
  theme(legend.position = "none") +
  coord_flip()
p1
```


Trade off plot show the relationship between EVI (normalized) and SSB in 2024, with point size representing the risk of population decline (%). Each point is labeled by scenario. (Figure \@ref(fig:tradeoff-plot)).

```{r tradeoff-plot, ig.width=6, fig.height=5, fig.cap="Trade-off between EVI, SSB 2024, and Risk of population decline across scenarios"}

tradeoff_data <- data.frame(
  Scenario = c("s0", "s1", "s2", "s3", "s4"),
  EVI_norm_prom = c(0.44, 0.43, 0.37, 0.44, 0.48),
  Risk_decline = c(33.7, 29.4, 11.7, 7.7, 7.6),
  SSB2024 = c(40.12, 47.59, 64.36, 70.93, 78.36)  
)

riskplot <- ggplot(tradeoff_data, aes(x = SSB2024, 
                          y = EVI_norm_prom, 
                          label = Scenario, 
                          size = 2, color = Scenario)) +
  geom_point(alpha = 0.7) +
  geom_text_repel(size = 4, box.padding = 0.5, 
                  color="black",
                  point.padding = 0.5) +
  scale_size_continuous(range = c(3,8), name = "Risk of decline (%)") +
  labs(
    x = "SSB 2024 (tonnes)",
    y = "EVI (normalized)",
    title = ""
  ) +
  theme_few() +
  theme(legend.position = "none") +
  scale_color_manual(values = c(
    "s0" = "black",
    "s1" = "#cccccc", 
    "s2" = "#999999",
    "s3" = "#ca0020",
    "s4" = "#666666"
  ))
riskplot
```

```{r eval=FALSE}
ggarrange(p1, riskplot,
          ncol = 2, nrow = 1,
          labels = c("A", "B"),
          common.legend = FALSE)
```

\pagebreak

## Final table

Final summary table (Table \@ref(tab:modelsummary)) with key metrics for each scenario, including SSB in 2024, depletion, biomass, decline over the last 5 years, recruitment failures, current F, catch in 2024, risk of population decline, and average EVI.

```{r modelsummary, message=FALSE, warning=FALSE, fig.cap="Summary of key metrics across model scenarios"}

extract_metrics <- function(model, name){
  
  # Valores SSB y Depletion en 2024 (último año de tu serie)
  ssb2024   <- model$sprseries$SSB[20]
  deple2024 <- model$sprseries$Deplete[20]
  BBMSY     <- model$Kobe$B.Bmsy[20]
  FFMSY     <- model$Kobe$F.Fmsy[20]
  bio2024  <- model$timeseries$Bio_all[20]
  ratiossb <- model$sprseries$SSBfished_eq[20] / model$SBzero
  currentF <- model$timeseries$`F:_1`[20]
  catchpre <- model$exploitation[20,7]
  
  # Decline últimos 5 años (%)
  ssb <- model$sprseries$SSB[1:20]
  last5 <- tail(ssb, 5)
  decline_pct <- (last5[1] - last5[5]) / last5[1] * 100
  
  # Fallos de reclutamiento (%)
  reclut <- model$timeseries$Recruit_0
  threshold <- 0.5 * mean(reclut, na.rm = TRUE)
  failures <- mean(reclut < threshold, na.rm = TRUE) * 100
  

  # Devolver como data.frame
  data.frame(
    Scenario = name,
    SSB2024 = ssb2024,
    Depletion2024 = deple2024,
    B_Bmsy = BBMSY,
    F_Fmsy = FFMSY,
    Decline5yr_pct = decline_pct,
    Recruitment_failures_pct = failures,
    Bio2024 = bio2024,
    Ratio_SSB = ratiossb,
    CurrentF = currentF,
    Catch_pre = catchpre
  )
}

# --------------------------------------
# Función para calcular riesgo de declive
# Probabilidad de Bio_all < 0.4 * B0
# --------------------------------------
calc_risk_threshold <- function(model, name, threshold = 0.4){
  B0 <- model$timeseries$Bio_all[1]  # valor inicial
  risk <- mean(model$timeseries$Bio_all < threshold * B0, na.rm = TRUE) * 100
  data.frame(Scenario = name, Risk_decline_prom = risk)
}

# --------------------------------------
# Supongamos que ya tienes IVI normalizado
# --------------------------------------
calc_evi <- function(datos, name){
  evi <- mean(datos$EVI_norm[datos$Scenario == name], na.rm = TRUE)
  data.frame(Scenario = name, EVI_norm_prom = evi)
}

# --------------------------------------
# Listado de modelos y nombres
# --------------------------------------
models_list <- list(
  "s0" = base.model0,
  "s1" = base.model1,
  "s2" = base.model2,
  "s3" = base.model3,
  "s4" = base.model4
)

# Extraer métricas principales
metrics_list <- lapply(names(models_list), function(x){
  extract_metrics(models_list[[x]], x)
})
res <- bind_rows(metrics_list)

# Calcular riesgo
risk_list <- lapply(names(models_list), function(x){
  calc_risk_threshold(models_list[[x]], x)
})
risk_df <- bind_rows(risk_list)

# Calcular IVI promedio (suponiendo que tus datos están en 'datos_all' con columna Scenario e IVI_norm)
evi_list <- lapply(names(models_list), function(x){
  calc_evi(datos_all, x)
})
evi_df <- bind_rows(evi_list)

# Combinar todo
res_final <- res %>%
  left_join(risk_df, by = "Scenario") %>%
  left_join(evi_df, by = "Scenario")


res_wide <- res_final %>%
  pivot_longer(
    cols = -Scenario,
    names_to = "Metric",
    values_to = "Value"
  ) %>%
  pivot_wider(
    names_from = Scenario,
    values_from = Value
  )

kbl(res_wide, 
    caption = "Summary of key metrics across model scenarios", 
    digits = 2) %>%
  kable_styling(full_width = FALSE,
                position = "center",
                bootstrap_options = c("striped", "hover")) %>%
  row_spec(0, bold = TRUE) %>%  # Encabezados en negrita
  column_spec(1, bold = TRUE)   # Primera columna en negrita (opcional)
```


```{r eval=FALSE}
# Exportar a Excel si deseas
write.xlsx(res_wide, file = "model_summary_wide.xlsx", rowNames = FALSE)
```



\pagebreak

# References

